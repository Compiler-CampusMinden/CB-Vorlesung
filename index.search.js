var relearn_search_index = [
  {
    "breadcrumb": "",
    "content": "Kursbeschreibung Der Compiler ist das wichtigste Werkzeug in der Informatik. In der Königsdisziplin der Informatik schließt sich der Kreis, hier kommen die unterschiedlichen Algorithmen und Datenstrukturen und Programmiersprachenkonzepte zur Anwendung.\nIn diesem Modul geht es um ein grundlegendes Verständnis für die wichtigsten Konzepte im Compilerbau. Wir schauen uns dazu relevante aktuelle Tools und Frameworks an und setzen diese bei der Erstellung eines kleinen Compiler-Frontends für C++ ein.\nÜberblick Modulinhalte Lexikalische Analyse: Scanner/Lexer Reguläre Sprachen Generierung mit ANTLR Syntaxanalyse: Parser Kontextfreie Grammatiken (CFG) LL-Parser (Top-Down-Parser) Generierung mit ANTLR Semantische Analyse: Attributierte Grammatiken und Symboltabellen Namen und Scopes Typen, Klassen, Polymorphie Zwischencode: Intermediate Representation (IR), LLVM-IR Backend: LLVM Interpreter: AST-Traversierung C++ als zu verarbeitende Programmiersprache Team BC George Carsten Gips (Sprechstunde nach Vereinbarung) Kursformat ​ IFM 3.1 CB (PO23, 3. Semester) IFM 5.21 CB (PO18, 5. Semester) Vorlesung (2 SWS) Praktikum (2 SWS) Mi, 08:00 - 09:30 Uhr (online) S3, G1: Di, 11:30 - 13:00 Uhr (online/Präsenz J101) (Carsten: Flipped Classroom, BC: Vorlesung) S3, G2: Fr, 14:00 - 15:30 Uhr (online/Präsenz J101) S3, G3: Mo, 09:15 - 10:45 Uhr (online/Präsenz J101) (Carsten: online, BC: Präsenz) Online-Sitzungen per Zoom (Zugangsdaten siehe ILIAS IFM 3.1 CB (PO23, 3. Semester)). Sie können hierzu den Raum J101 (siehe Stundenplan) nutzen.\nVorlesung (2 SWS) Praktikum (2 SWS) Mi, 08:00 - 09:30 Uhr (online) S5, G1: Mi, 09:45 - 11:15 Uhr (online) (Carsten: Flipped Classroom, BC: Vorlesung) S5, G2: Mi, 09:45 - 11:15 Uhr (online) S5, G3: Mi, 09:45 - 11:15 Uhr (online) (Carsten: online, BC: online) Online-Sitzungen per Zoom (Zugangsdaten siehe IFM 5.21 CB (PO18, 5. Semester)). Sie können hierzu den Raum J101 (siehe Stundenplan) nutzen.\nFahrplan ​ IFM 3.1 CB (PO23, 3. Semester) IFM 5.21 CB (PO18, 5. Semester) News 17.02.25 Planung nächste Prüfung Compilerbau (PO23) (27.03.25)\nDie nächste Prüfung in Compilerbau (PO23) wird am Donnerstag, den 27.03.25 zwischen 08:00 bis 18:00 Uhr stattfinden. Die Prüfung wird aus einer Station bestehen (mündliche Prüfung mit je ca. 45 Minuten, per Zoom). Die genaue Verteilung der Startzeiten erfolgt per Mail über das LSF ca. eine Woche vorher.\n09.01.25 Parcoursprüfung: Feedbackgespräche am Do, 30.01., 15:30-18:00 Uhr Wir bieten am Donnerstag, 30.01.25, von 15:30 bis 18:00 Uhr Feedbackgespräche zur Bewertung der Ergebnisse von B07 (Parcoursprüfung, Station 2) an.\nEs ist eine vorherige eine Anmeldung im ILIAS notwendig.\n08.01.25 Planung Parcoursprüfung Station 2: Bitte tragt euch als Team im Etherpad ein Wie bereits angekündigt, finden KW4 (Mo. 20.01., Di. 21.01., Fr. 24.01.) die Vorstellungen von B07 im Rahmen der Parcoursprüfung statt (Station 2). Jedes Team hat 20 Minuten für die Vorstellung der wichtigsten Aspekte zum Projekt, danach sind 10 Minuten für Fragen und Diskussion eingeplant.\nBitte tragt euch bis zum 12. Januar als Team jeweils zu einem der Zeitslots im Etherpad ein. Ihr findet den Link im ILIAS.\nWenn die vorgeschlagenen Termine nicht reichen sollten, meldet euch bitte zeitnah per E-Mail!\n16.12.24 Nachtrag zur Anpassung der Gewichtung der beiden Stationen der Parcoursprüfung (war 29.11.) Es war ursprünglich vorgesehen, die Gesamtnote als Mittelwert der Noten der beiden Parcours-Stationen zu berechnen: Gewichtung 50% (Station I) und 50% (Station II).\nAm 29.11. haben wir auf vielfachen Wunsch hin die Gewichtung der Stationen der Parcoursprüfung angepasst: Gewichtung 33 Punkte (Station I) und 50 Punkte (Station II).\nUm eine potentielle Benachteiligung zu vermeiden, werden wir eine individuelle Günstigerprüfung vornehmen: Wir werden für jede Person jeweils beide Verhältnisse berechnen und automatisch die bessere Note werten.\nZusätzlich werden für Station I 3 Punkte Überhang gewährt. Von den 33 maximal erreichbaren Punkten werden 30 Punkte als 100% gewertet, darüber hinausgehende Punkte bleiben als Bonuspunkte erhalten.\nDies gilt für die Prüfung im ersten Zeitraum.\n04.12.24 Da die Projektwoche (16.-20.12.2024) mangels Interesse nicht stattfinden wird, biete ich eine zusätzliche Sprechstunde im Vorlesungsslot am 18.12. an.\n29.11.24 Anpassung der Gewichtung der Parcours-Stationen Auf vielfachen Wunsch passen wir die Gewichtung der Stationen der Parcoursprüfung an:\nStation I: 33 Punkte Station II: 50 Punkte 29.11.24 Ergebnisse und Einsicht Parcoursprüfung: Station 1 ILIAS Die erste Station der Parcoursprüfung vom 20.11. ist korrigiert.\nDie Einsicht findet von Montag, 02.12., 08:00 Uhr bis Donnerstag, 05.12., 16:00 Uhr online statt. Gehen Sie dazu bitte selbstständig auf den E-Assessment-Server (https://eassessment.hsbi.de/goto.php?target=crs_7284, via VPN) und schauen sich unter \"Ergebnisse\" die Bewertung Ihrer Antworten an. Wenn dabei Fragen auftreten, schicken Sie bitte bis Donnerstag, 05.12., 16:00 Uhr eine kurze Mail an Carsten Gips mit Ihren konkreten Fragen. Wir werden dann mit Ihnen für Freitag (06.12., zw. 15 und 17 Uhr) einen kurzen Gesprächstermin vereinbaren.\n12.11.24 Organisation Parcoursprüfung: Station 1 ILIAS Die erste Station der Parcoursprüfung findet wie im Fahrplan beschrieben am Mittwoch, den 20. November im B40 statt. Wir schreiben in zwei Durchgängen:\n09:45 - 10:30 Uhr: alle Studierenden, deren Nachname mit den Buchstaben \"A\" bis \"L\" beginnt, 10:45 - 11:30 Uhr: alle Studierenden, deren Nachname mit den Buchstaben \"M\" bis \"Z\" beginnt. Thematisch geht es um die Themen der Wochen 41 bis 45, also insbesondere Lexer, CFG, LL-Parser und ANTLR.\nDie Prüfung wird auf einem ILIAS-System durchgeführt. Bitte denkt an euren Usernamen und das Passwort.\nErlaubtes Hilfsmittel: Ein handschriftlich beschriebenes DIN-A4-Blatt (Vorder- und Rückseite können genutzt werden).\n29.10.24 Verschiebung Praktikum zu B02 für Gruppe 3: Do, 07.11., 08:00 Uhr Wie bereits in der Vorlesung angekündigt, muss das Praktikum für Blatt 02 für Gruppe 3 aus gesundheitlichen Gründen leider von Montag, 04.11. auf Donnerstag, 07.11. verschoben werden. Start ist um 08:00 Uhr.\n28.10.24 Info zum ANTLR-Meeting mit Edmonton am Di, 29.10. Am Dienstag, den 29.10., treffen wir uns wie angekündigt um 18 Uhr zum ersten Meeting mit den Studis und Kollegen von der University of Alberta (Edmonton, Kanada). Dazu nutzen wir unseren Zoom (vgl. ILIAS IFM 3.1 CB (PO23, 3. Semester)).\nBitte fügt eurem im Zoom angezeigten Namen ein \" (DE)\" hinten an.\nBeispiel: Euer angezeigter Name wäre normalerweise Vorname Nachname. Für die Sitzung am Dienstag hängt ihr bitte ein \"(DE)\" hinten dran und habt entsprechend den Anzeigenamen Vorname Nachname (DE).\nWir freuen uns auf eine spannende Einführung in ANTLR und ein lustiges Meeting!\n21.10.24 Zeitänderung Gruppe 2 am 24.01.2025 Das letzte Praktikum von Gruppe 2 (am Fr, 24.01.2025) findet eine Stunde später statt als sonst: 15:00 - 16:30 Uhr.\n16.10.24 Update B01 Bitte beachten Sie die Aktualisierung von B01.\nDie bisherigen Aufgaben 5 und 6 kamen versehentlich doppelt vor. Dies wurde korrigiert, d.h. es gibt jetzt eine Aufgabe weniger und Aufgabe 2 hat einen dritten Punkt neu dazu bekommen.\n09.10.24 Teams Bitte bearbeiten Sie die Aufgaben in 3er Teams.\nEs ist empfehlenswert, wenn alle Personen im Team in der selben Stundenplangruppe (Praktikumsgruppe) sind. Sie können aber auch Teams über verschiedene Gruppen hinweg bilden. Geben Sie individuell im ILIAS ab und stellen Sie die Lösung dann individuell in Ihrer jeweiligen Praktikumsgruppe vor.\nSie können Ihre Teams jederzeit selbstständig im Semester ändern/wechseln.\nAchtung: Den Vortrag zu B07 müssen Sie aber gemeinsam als Team halten. Wenn Ihre Teammitglieder aus verschiedenen Stundenplangruppen kommen sollten, findet der Vortrag in der Gruppe statt, aus der die meisten der Teammitglieder kommen. Bitte beachten Sie das bei der Teamwahl!\nAbgabe ILIAS Das Abgabeverfahren im ILIAS wurde deutlich vereinfacht: Jede Person gibt für jedes Blatt individuell direkt im ILIAS an, welche Aufgaben das Team bearbeitet hat (also keine Teambildung und keine Textdatei mehr im ILIAS).\nBitte darauf achten, dass Sie das die angegebenen Aufgaben auch vorstellen können müssen! Achten Sie bitte auch auf die mind. 60% für das Testat.\nPraktikum Sie gehen einfach in das Praktikum, welches Ihrer Stundenplangruppe zugeordnet ist und stellen dort individuell die Lösungen Ihres Teams vor.\nDen Vortrag zu B07 (letzte VL-Woche) halten Sie dann in die Praktikumsgruppe, in der die meisten Teammitglieder sind. Bitte prüfen Sie, ob das für Sie passt (vom Stundenplan her möglich ist) und wählen Sie ggf. ein anderes Team. Wir werden rechtzeitig eine entsprechende Planung organisieren. Einige Vorträge werden wir aber auch im Vorlesungsslot machen müssen, d.h. hier besteht bei Bedarf eine Ausweichmöglichkeit.\nHier finden Sie einen abonnierbaren Google Kalender IFM 3.1 CB (PO23, 3. Semester) mit allen Terminen der Veranstaltung zum Einbinden in Ihre Kalender-App.\nAbgabe der Übungsblätter jeweils Montag bis 09:00 Uhr im ILIAS. Vorstellung der Lösung im jeweiligen Praktikum in der Abgabewoche.\nMonat Woche Vorlesung Lead Abgabe Aufgabenblatt Vorstellung Praktikum Oktober 41 09.: Orga (Zoom); Überblick, Sprachen, Anwendungen Carsten, BC 42 16.: Reguläre Sprachen BC 43 23.: CFG BC 21.: B01 Reguläre Sprachen 21. / 22. / 25. (BC, Präsenz) 44 29.: 18:00 - 19:30 Uhr (online): Edmonton I: ANTLR + Live-Coding Edmonton 44 30.: Lexer mit ANTLR, Parser mit ANTLR Carsten November 45 06.: Dienstbesprechung 04.: B02 CFG 04. 07. 08:00 / 05. / 08. (BC, Präsenz) 46 13.: Überblick Symboltabellen, Symboltabellen: Scopes, Symboltabellen: Funktionen, Symboltabellen: Klassen Carsten 11.: B03 ANTLR 11. / 12. / 15. (Carsten, online) 47 20.: A-L: 09:45 - 10:30 Uhr, M-Z: 10:45 - 11:30 Uhr (B40): Parcoursprüfung: Station 1 ILIAS (Grammar, Lexing, Parsing), siehe Ankündigung 18.: B04 Semantische Analyse 18. / 19. / 22. (Carsten, online) 48 26.: 18:00 - 19:30 Uhr (online): Edmonton II: Vorträge Mindener Projekte Minden 48 27.: Überblick Zwischencode, Überblick Backend (LLVM) BC, Carsten Dezember 49 03.: 18:00 - 19:30 Uhr (online): Edmonton III: Vorträge Edmontoner Projekte Edmonton 49 04.: AST-basierte Interpreter 1, AST-basierte Interpreter 2 Carsten 50 11.: C++ I: Basics, Pointer \u0026 Referenzen, Klassen, Big 3 Carsten 09.: B05 Interpreter 09. / 10. / 13. (Carsten, online) 51 18.: Projektwoche Semester 1+3 C++ II: Operatoren, Vererbung \u0026 Polymorphie, Templates 52 25.: Weihnachtspause Januar 01 01.: Weihnachtspause 02 08.: Sprechstunde/Freies Arbeiten Carsten 06.: B06 C++ 06. / 07. / 10. (Carsten, online) 03 15.: Freies Arbeiten/Puffer 04 22.: Parcoursprüfung: Station 2 B07 (VL- und Praktika-Slots, siehe Ankündigung) Carsten, BC 20.: B07 Mini-Projekt 20. / 21. / 24. (15:00-16:30) (Carsten/BC, online) (Prüfungsphase I) 05 30.: Feedback-Gespräche (15:30 - 18:00 Uhr, online) (Prüfungsphase II) Parcoursprüfung: Do, 27. Mar 2025, 08-18 Uhr, mdl. Prüfung (alle Themen) (je Prüfung ca. 45', Vergabe ca. 2 Wochen vorher) News 17.02.25 Planung nächste Prüfung Compilerbau (PO18) (27.03.25)\nDie nächste Prüfung in Compilerbau (PO18) wird am Donnerstag, den 27.03.25 zwischen 08:00 bis 18:00 Uhr stattfinden. Die Prüfung wird aus einer Station bestehen (mündliche Prüfung mit je ca. 45 Minuten, per Zoom). Die genaue Verteilung der Startzeiten erfolgt per Mail über das LSF ca. eine Woche vorher.\n09.01.25 Parcoursprüfung: Feedbackgespräche am Do, 30.01., 14:00-15:30 Uhr Wir bieten am Donnerstag, 30.01.25, von 14:00 bis 15:30 Uhr Feedbackgespräche zur Bewertung der Ergebnisse von B07x (Parcoursprüfung, Station 2) an.\nEs ist eine vorherige eine Anmeldung im ILIAS notwendig.\n08.01.25 Planung Parcoursprüfung Station 2: Bitte tragt euch als Team im Etherpad ein Wie bereits angekündigt, finden am Mittwoch, den 22. Januar die Vorstellungen von B07x im Rahmen der Parcoursprüfung statt (Station 2). Jedes Team hat 20 Minuten für die Vorstellung der wichtigsten Aspekte zum Projekt, danach sind 10 Minuten für Fragen und Diskussion eingeplant.\nBitte tragt euch bis zum 12. Januar als Team jeweils zu einem der Zeitslots im Etherpad ein. Ihr findet den Link im ILIAS.\n16.12.24 Anpassung der Gewichtung der beiden Stationen der Parcoursprüfung Es war ursprünglich vorgesehen, die Gesamtnote als Mittelwert der Noten der beiden Parcours-Stationen zu berechnen: Gewichtung 50% (Station 1) und 50% (Station 2).\nIn Anlehnung an die Anpassung der Notenberechnung für das dritte Semester bieten wir an, die Gesamtnote alternativ mit der Gewichtung 40% (Station 1) und 60% (Station 2) zu berechnen.\nWir werden für jede Person jeweils beide Verhältnisse berechnen und automatisch die bessere Note werten (individuelle Günstigerprüfung).\nDies gilt für die Prüfung im ersten Zeitraum.\n16.12.24 Feedback zu den Ergebnissen der Station 1 der Parcoursprüfung Wir möchten Ihnen im Praktikum am 18.12. ein Feedback zu den Ergebnissen der Station 1 der Parcoursprüfung geben.\n09.11.24 Umplanung der Vorträge zur ersten Station der Parcoursprüfung Die Vorträge zur Station 1 der Parcoursprüfung waren ursprünglich für den 20.11. (zur Probe) und dann live auf dem zweiten Edmonton-Meeting (26.11., mit Bewertung) geplant.\nAus zeitlichen Gründen müssen wir leider etwas umplanen und die Vorträge um eine bzw. zwei Woche(n) verschieben. Wir werden dazu die Teams auf zwei Termine aufteilen: Die ersten drei Teams werden im Praktikum am 27.11. vortragen und die restlichen zwei Teams im Praktikum am 04.12. ... Abgabe für alle Teams im ILIAS ist aber bereits der 27.11.(!)\n28.10.24 Info zum ANTLR-Meeting mit Edmonton am Di, 29.10. Am Dienstag, den 29.10., treffen wir uns wie angekündigt um 18 Uhr zum ersten Meeting mit den Studis und Kollegen von der University of Alberta (Edmonton, Kanada). Dazu nutzen wir unseren Zoom (vgl. IFM 5.21 CB (PO18, 5. Semester)).\nBitte fügt eurem im Zoom angezeigten Namen ein \" (DE)\" hinten an.\nBeispiel: Euer angezeigter Name wäre normalerweise Vorname Nachname. Für die Sitzung am Dienstag hängt ihr bitte ein \"(DE)\" hinten dran und habt entsprechend den Anzeigenamen Vorname Nachname (DE).\nWir freuen uns auf eine spannende Einführung in ANTLR und ein lustiges Meeting!\n23.10.24 Verschiebung des Praktikums zu Blatt 01 auf 30.10., 16 Uhr Das Praktikum zur Vorstellung von Blatt 01 musste aus gesundheitlichen Gründen um eine Woche verschoben werden.\nNeuer Termin für die Vorstellung von Blatt 01: Mi, 30.10., 16:00 - 17:30 Uhr.\n16.10.24 Update B01 Bitte beachten Sie die Aktualisierung von B01.\nDie bisherigen Aufgaben 5 und 6 kamen versehentlich doppelt vor. Dies wurde korrigiert, d.h. es gibt jetzt eine Aufgabe weniger und Aufgabe 2 hat einen dritten Punkt neu dazu bekommen.\n09.10.24 Teams Bitte bearbeiten Sie die Aufgaben in 3er Teams.\nEs ist empfehlenswert, wenn alle Personen im Team in der selben Stundenplangruppe (Praktikumsgruppe) sind. Sie können aber auch Teams über verschiedene Gruppen hinweg bilden. Geben Sie individuell im ILIAS ab und stellen Sie die Lösung dann individuell in Ihrer jeweiligen Praktikumsgruppe vor.\nSie können Ihre Teams jederzeit selbstständig im Semester ändern/wechseln.\nAchtung: Den Vortrag zu B07x müssen Sie (wie auch den Vortrag zu B04x) aber gemeinsam als Team halten. Wenn Ihre Teammitglieder aus verschiedenen Stundenplangruppen kommen sollten, findet der Vortrag in der Gruppe statt, aus der die meisten der Teammitglieder kommen. Bitte beachten Sie das bei der Teamwahl!\nAbgabe ILIAS Das Abgabeverfahren im ILIAS wurde deutlich vereinfacht: Jede Person gibt für jedes Blatt individuell direkt im ILIAS an, welche Aufgaben das Team bearbeitet hat (also keine Teambildung und keine Textdatei mehr im ILIAS).\nBitte darauf achten, dass Sie das die angegebenen Aufgaben auch vorstellen können müssen! Achten Sie bitte auch auf die mind. 60% für das Testat.\nPraktikum Sie gehen einfach in das Praktikum, welches Ihrer Stundenplangruppe zugeordnet ist und stellen dort individuell die Lösungen Ihres Teams vor.\nDen Vortrag zu B07x (letzte VL-Woche) halten Sie dann in die Praktikumsgruppe, in der die meisten Teammitglieder sind. Bitte prüfen Sie, ob das für Sie passt (vom Stundenplan her möglich ist) und wählen Sie ggf. ein anderes Team. Wir werden rechtzeitig eine entsprechende Planung organisieren. Einige Vorträge werden wir aber auch im Vorlesungsslot machen müssen, d.h. hier besteht bei Bedarf eine Ausweichmöglichkeit.\nHier finden Sie einen abonnierbaren Google Kalender IFM 5.21 CB (PO18, 5. Semester) mit allen Terminen der Veranstaltung zum Einbinden in Ihre Kalender-App.\nAbgabe der Übungsblätter jeweils Mittwoch bis 09:00 Uhr im ILIAS. Vorstellung der Lösung im jeweiligen Praktikum in der Abgabewoche.\nMonat Tag Vorlesung Lead Abgabe Aufgabenblatt \u0026 Vorstellung Praktikum Oktober 09. Orga (Zoom); Überblick, Sprachen, Anwendungen Carsten, BC 16. Reguläre Sprachen BC 23. CFG BC B01 Reguläre Sprachen (BC, online) 29. 18:00 - 19:30 Uhr (online): Edmonton I: ANTLR + Live-Coding Edmonton 30. Lexer mit ANTLR, Parser mit ANTLR Carsten 16:00 Uhr: B01 Reguläre Sprachen (BC, online) November 06. Dienstbesprechung B02 CFG (BC, online) 13. Überblick Symboltabellen, Symboltabellen: Scopes, Symboltabellen: Funktionen, Symboltabellen: Klassen Carsten B03 ANTLR (Carsten, online) 20. 26. 18:00 - 19:30 Uhr (online): Edmonton II: Vorträge Mindener Projekte Minden (S5) 27. Überblick Zwischencode, Überblick Backend (LLVM) BC, Carsten Parcoursprüfung: Station 1: Vorstellung der Lösung von B04x (online, 3 Teams, siehe Ankündigung) Dezember 03. 18:00 - 19:30 Uhr (online): Edmonton III: Vorträge Edmontoner Projekte Edmonton 04. AST-basierte Interpreter 1, AST-basierte Interpreter 2 Carsten Parcoursprüfung: Station 1: Vorstellung der Lösung von B04x (online, 2 Teams, siehe Ankündigung) 11. C++ I: Basics, Pointer \u0026 Referenzen, Klassen, Big 3 Carsten B05x Interpreter (Carsten, online) 18. Projektwoche Semester 1+3 C++ II: Operatoren, Vererbung \u0026 Polymorphie, Templates Feedback zu Station 1 25. Weihnachtspause Januar 01. Weihnachtspause 08. Sprechstunde/Freies Arbeiten Carsten B06x C++ und dyn. Speicherverwaltung (Carsten, online) 15. Freies Arbeiten/Puffer 22. Parcoursprüfung: Station 2 B07x (VL- und Praktika-Slots, siehe Ankündigung) Carsten, BC B07x Mini-Projekt (Carsten/BC, online) (Prüfungsphase I) 30. Feedback-Gespräche (14:00 - 15:30 Uhr, online) (Prüfungsphase II) Parcoursprüfung: Do, 27. Mar 2025, 08-18 Uhr, mdl. Prüfung (alle Themen) (je Prüfung ca. 45', Vergabe ca. 2 Wochen vorher) Prüfungsform, Note und Credits ​ IFM 3.1 CB (PO23, 3. Semester) IFM 5.21 CB (PO18, 5. Semester) Parcoursprüfung plus Testat, 5 ECTS (PO23)\nTestat: Vergabe der Credit-Points\nMindestens 4 der Übungsblätter B01, B02, B03, B04, B05 und B06 erfolgreich bearbeitet, und aktive Teilnahme an allen 3 Edmonton-Terminen. (\"erfolgreich bearbeitet\": Bearbeitung in 3er Teams, je mindestens 60% bearbeitet, fristgerechte Abgabe der Lösungen im ILIAS, Vorstellung der Lösungen im Praktikum)\n​ Prüfung im ersten Zeitraum Prüfung im zweiten Zeitraum Stationen:\nILIAS-Test (einzeln, 20.11.) Vorstellung Mini-Projekt B07 (3er Teams, letzte VL-Woche) Note für das Modul: Beide Stationen ergeben zu je 50% oder in der Gewichtung 30 Punkte (Station I) und 50 Punkte (Station II) die Gesamtnote (individuelle Günstigerprüfung).\nFür Station I werden 3 Punkte Überhang gewährt: Von den 33 maximal erreichbaren Punkten werden 30 Punkte als 100% gewertet, darüber hinausgehende Punkte bleiben als Bonuspunkte erhalten.\nStationen:\nMündliche Prüfung (individuell, ca. 45 Minuten, zweiter Prüfungszeitraum) Die Note der mündlichen Prüfung ergibt die Gesamtnote.\nParcoursprüfung plus Testat, 5 ECTS (PO18)\nTestat: Vergabe der Credit-Points\nMindestens 4 der Übungsblätter B01, B02, B03, B04x, B05x und B06x erfolgreich bearbeitet, und aktive Teilnahme an allen 3 Edmonton-Terminen. (\"erfolgreich bearbeitet\": Bearbeitung in 3er Teams, je mindestens 60% bearbeitet, fristgerechte Abgabe der Lösungen im ILIAS, Vorstellung der Lösungen im Praktikum)\n​ Prüfung im ersten Zeitraum Prüfung im zweiten Zeitraum Stationen:\nVortrag (3er Team, 27.11. bzw. 04.12. im Praktikum): Vorstellung der Lösung von B04x Vorstellung Mini-Projekt B07x (3er Teams, letzte VL-Woche) Note für das Modul: Beide Stationen ergeben zu je 50% oder in der Gewichtung 40% (Station 1) und 60% (Station 2) die Gesamtnote (individuelle Günstigerprüfung).\nStationen:\nMündliche Prüfung (individuell, ca. 45 Minuten, zweiter Prüfungszeitraum) Die Note der mündlichen Prüfung ergibt die Gesamtnote.\nMaterialien \"Compilers: Principles, Techniques, and Tools\". Aho, A. V. und Lam, M. S. und Sethi, R. und Ullman, J. D. and Bansal, S., Pearson India, 2023. ISBN 978-9-3570-5488-1. Online über die O'Reilly-Lernplattform. \"Crafting Interpreters\". Nystrom, R., Genever Benning, 2021. ISBN 978-0-9905829-3-9. Online. \"The Definitive ANTLR 4 Reference\". Parr, T., Pragmatic Bookshelf, 2014. ISBN 978-1-9343-5699-9. Online über die O'Reilly-Lernplattform. \"Writing a C Compiler\". Sandler, N., No Starch Press, 2024. ISBN 978-1-0981-8222-9. Online über die O'Reilly-Lernplattform. Förderungen und Kooperationen Kooperation mit University of Alberta, Edmonton (Kanada) Über das Projekt \"We CAN virtuOWL\" der Fachhochschule Bielefeld ist im Frühjahr 2021 eine Kooperation mit der University of Alberta (Edmonton/Alberta, Kanada) im Modul \"Compilerbau\" gestartet.\nWir freuen uns, auch in diesem Semester wieder drei gemeinsame Sitzungen für beide Hochschulen anbieten zu können. (Diese Termine werden in englischer Sprache durchgeführt.)",
    "description": "Kursbeschreibung Der Compiler ist das wichtigste Werkzeug in der Informatik. In der Königsdisziplin der Informatik schließt sich der Kreis, hier kommen die unterschiedlichen Algorithmen und Datenstrukturen und Programmiersprachenkonzepte zur Anwendung.\nIn diesem Modul geht es um ein grundlegendes Verständnis für die wichtigsten Konzepte im Compilerbau. Wir schauen uns dazu relevante aktuelle Tools und Frameworks an und setzen diese bei der Erstellung eines kleinen Compiler-Frontends für C++ ein.",
    "tags": [],
    "title": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25)",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/index.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Praktikum",
    "content": "Aufgabe Entwickeln Sie in Ihrem 3er-Team gemeinsam einen Interpreter oder einen Compiler für C++.\nNutzen Sie als Implementierungssprache Java.1 Sie sollen ANTLR zur Erstellung Ihres Lexers und Parsers einsetzen (Lernziel).\nEntwickeln Sie verschiedene Eingabebeispiele in unterschiedlicher Komplexität, mit denen Sie Ihren Interpreter bzw. Compiler testen können.\nVariante A: Interpreter Der Interpreter muss den zu interpretierenden C++-Code aus einer Datei einlesen können.\nSie brauchen keine interaktive Interpretation implementieren, d.h. eine REPL ist nicht notwendig. Der Interpreter muss bei Bedarf an relevanten Stellen einen Log-Output erzeugen, um die Arbeitsweise des Programms nachvollziehen zu können. Das Arbeitsergebnis soll auf der Konsole ausgegeben werden.\nVariante B: Compiler Der Compiler muss den zu kompilierenden C++-Code aus einer Datei einlesen können.\nDer Compiler soll aus dem eingegebenen C++-Code passenden gültigen Java-Code erzeugen und in eine Datei speichern. Definieren Sie ggf. nötige Hilfsbibliotheken, so dass man den generierten Code zusammen mit den Hilfsbibliotheken mit Java übersetzen und ausführen kann.\nSprachumfang Sie sollen mindestens folgende C++-Konzepte unterstützen:\nBasisdatentypen: bool, int, char Variablen Arrays C++-Referenzen Zuweisungen und Expressions Kontrollfluss: if-then-else, while-Schleifen Funktionen (Definition, Deklaration, Aufrufe) Klassen (mit Attributen und Methoden) Einfach-Vererbung Polymorphie (dynamisch, statisch) Eingebaute Funktionen: print_bool, print_int, print_char (Ausgabe eines Werts des jeweiligen Typs auf der Konsole) Beachten Sie bei der Umsetzung, dass Polymorphie in C++ etwas anders funktioniert als in Java.\nAndere mit C++ verbundene Konzepte wie beispielsweise Präprozessor, Header-Files, Pointer, Templates, Sichtbarkeiten in Klassen, Trennung Deklaration/Implementierung bei Klassen (Trennung .h und .cpp) oder Initialisierungslisten2 brauchen Sie nicht umsetzen.\nSie finden im CB-Repo einige Beispiele, die mindestens umgesetzt werden sollten und die Sie zum Testen Ihres Interpreters bzw. Compilers nutzen können. Beachten Sie, dass diese Sammlung nicht vollständig ist.\nProjektvorstellung: Walk-Through statt Präsentation Stellen Sie Ihr Projekt am Semesterende vor (Termine siehe Fahrplan und Ankündigung).\nJedes Team hat dafür 20 Minuten Zeit.\nGehen Sie dabei am Code durch Ihr Projekt und diskutieren Sie relevante Teile, mindestens aber:\nGrammatik AST Semantische Analyse Interpreter bzw. Compiler Demonstrieren Sie die Funktionsfähigkeit mit Ihren C++-Codebeispielen.\nSie sollen keine Folien erstellen. Die Präsentation soll live in der IDE erfolgen.\nAbgabeformat Reichen Sie den als ZIP-Datei zusammengepackten Quellcode des Interpreters bzw. Compilers elektronisch über ILIAS ein.\nBewertungskriterien Inhalt (40 Punkte)\nAufgabenstellung (30 Punkte): Wurden alle Aspekte der Zielsprache sinnvoll umgesetzt? Argumentation und Nachvollziehbarkeit (10 Punkte): Sind die Konzepte logisch und schlüssig dargestellt? Werden die Aussagen durch relevante Code-Stellen gestützt? Verschiedenes (10 Punkte)\nRoter Faden (5 Punkte): Wird der rote Faden während des gesamten Walk-Through beibehalten? Ist der Zusammenhang zwischen den einzelnen Punkten nachvollziehbar? Zeitmanagement (5 Punkte): Wurde der Zeitrahmen (20 Minuten pro Vortrag) eingehalten? Gesamtbewertung: 50 Punkte\nNach Absprache können Sie auch eine andere Implementierungssprache verwenden. ↩︎\nLeider werden Initialisierungslisten für den Aufruf der Basisklassenkonstruktoren benötigt, sofern der Defaultkonstruktor der Basisklasse nicht ausreicht. ↩︎",
    "description": "Aufgabe Entwickeln Sie in Ihrem 3er-Team gemeinsam einen Interpreter oder einen Compiler für C++.\nNutzen Sie als Implementierungssprache Java.1 Sie sollen ANTLR zur Erstellung Ihres Lexers und Parsers einsetzen (Lernziel).\nEntwickeln Sie verschiedene Eingabebeispiele in unterschiedlicher Komplexität, mit denen Sie Ihren Interpreter bzw. Compiler testen können.\nVariante A: Interpreter Der Interpreter muss den zu interpretierenden C++-Code aus einer Datei einlesen können.\nSie brauchen keine interaktive Interpretation implementieren, d.h. eine REPL ist nicht notwendig. Der Interpreter muss bei Bedarf an relevanten Stellen einen Log-Output erzeugen, um die Arbeitsweise des Programms nachvollziehen zu können. Das Arbeitsergebnis soll auf der Konsole ausgegeben werden.",
    "tags": [],
    "title": "Blatt 07: Mini-Projekt C++",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/homework/sheet07.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25)",
    "content": "Was ist ein Compiler? Welche Bausteine lassen sich identifizieren, welche Aufgaben haben diese?\nStruktur eines Compilers Bandbreite der Programmiersprachen Anwendungen",
    "description": "Was ist ein Compiler? Welche Bausteine lassen sich identifizieren, welche Aufgaben haben diese?\nStruktur eines Compilers Bandbreite der Programmiersprachen Anwendungen",
    "tags": [],
    "title": "Überblick",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/00-intro.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Überblick",
    "content": "Sprachen verstehen, Texte transformieren The cat runs quickly.\n=\u003e Struktur? Bedeutung?\nWir können hier (mit steigender Abstraktionsstufe) unterscheiden:\nSequenz von Zeichen\nWörter: Zeichenketten mit bestimmten Buchstaben, getrennt durch bestimmte andere Zeichen; Wörter könnten im Wörterbuch nachgeschlagen werden\nSätze: Anordnung von Wörtern nach einer bestimmten Grammatik, Grenze: Satzzeichen\nHier (vereinfacht): Ein Satz besteht aus Subjekt und Prädikat. Das Subjekt besteht aus einem oder keinen Artikel und einem Substantiv. Das Prädikat besteht aus einem Verb und einem oder keinem Adverb.\nSprache: Die Menge der in einer Grammatik erlaubten Sätze\nCompiler: Big Picture Quelle: A Map of the Territory (mountain.png) by Bob Nystrom on Github.com (MIT)\nBegriffe und Phasen\nDie obige Bergsteige-Metapher kann man in ein nüchternes Ablaufdiagramm mit verschiedenen Stufen und den zwischen den Stufen ausgetauschten Artefakten übersetzen:\nFrontend, Analyse Die ersten Stufen eines Compilers, die mit der Analyse des Inputs beschäftigt sind. Dies sind in der Regel der Scanner, der Parser und die semantische Analyse.\nScanner, Lexer, Tokenizer, Lexikalische Analyse\nZerteilt den Zeichenstrom in eine Folge von Wörtern. Mit regulären Ausdrücken kann definiert werden, was Klassen gültiger Wörter (\"Token\") sind. Ein Token hat i.d.R. einen Namen und einen Wert.\nParser, Syntaxanalyse\nDer Parser erhält als Eingabe die Folge der Token und versucht mit Hilfe einer Grammatik zu bestimmen, ob es sich bei der Tokensequenz um gültige Sätze im Sinne der Grammatik handelt. Hier gibt es viele Algorithmen, die im Wesentlichen in die Klassen \"top-down\" und \"bottom-up\" fallen.\nSemantische Analyse, Kontexthandling\nIn den vorigen Stufen wurde eher lokal gearbeitet. Hier wird über den gesamten Baum und die Symboltabelle hinweg geprüft, ob beispielsweise Typen korrekt verwendet wurden, in welchen Scope ein Name gehört etc. Mit diesen Informationen wird der AST angereichert.\nSymboltabellen\nDatenstrukturen, um Namen, Werte, Scopes und weitere Informationen zu speichern. Die Symboltabellen werden vor allem beim Parsen befüllt und bei der semantischen Analyse gelesen, aber auch der Lexer benötigt u.U. diese Informationen.\nBackend, Synthese Die hinteren Stufen eines Compilers, die mit der Synthese der Ausgabe beschäftigt sind. Dies sind in der Regel verschiedene Optimierungen und letztlich die Code-Generierung\nCodegenerierung\nErzeugung des Zielprogramms aus der (optimierten) Zwischendarstellung. Dies ist oft Maschinencode, kann aber auch C-Code oder eine andere Ziel-Sprache sein.\nOptimierung\nDiverse Maßnahmen, um den resultierenden Code kleiner und/oder schneller zu gestalten.\nSymboltabellen\nDatenstrukturen, um Namen, Werte, Scopes und weitere Informationen zu speichern. Die Symboltabellen werden vor allem beim Parsen befüllt und bei der semantischen Analyse gelesen, aber auch der Lexer benötigt u.U. diese Informationen.\nWeitere Begriffe Parse Tree, Concrete Syntax Tree\nRepräsentiert die Struktur eines Satzes, wobei jeder Knoten dem Namen einer Regel der Grammatik entspricht. Die Blätter bestehen aus den Token samt ihren Werten.\nAST, (Abstract) Syntax Tree\nVereinfachte Form des Parse Tree, wobei der Bezug auf die Element der Grammatik (mehr oder weniger) weggelassen wird.\nAnnotierter AST\nAnmerkungen am AST, die für spätere Verarbeitungsstufen interessant sein könnten: Typ-Informationen, Optimierungsinformationen, ...\nZwischen-Code, IC\nZwischensprache, die abstrakter ist als die dem AST zugrunde liegenden Konstrukte der Ausgangssprache. Beispielsweise könnten while-Schleifen durch entsprechende Label und Sprünge ersetzt werden. Wie genau dieser Zwischen-Code aussieht, muss der Compilerdesigner entscheiden. Oft findet man den Assembler-ähnlichen \"3-Adressen-Code\".\nSprache\nEine Sprache ist eine Menge gültiger Sätze. Die Sätze werden aus Wörtern gebildet, diese wiederum aus Zeichenfolgen.\nGrammatik\nEine Grammatik beschreibt formal die Syntaxregeln für eine Sprache. Jede Regel in der Grammatik beschreibt dabei die Struktur eines Satzes oder einer Phrase.\nLexikalische Analyse: Wörter (\"Token\") erkennen Die lexikalische Analyse (auch Scanner oder Lexer oder Tokenizer genannt) zerteilt den Zeichenstrom in eine Folge von Wörtern (\"Token\"). Die geschieht i.d.R. mit Hilfe von regulären Ausdrücken.\nDabei müssen unsinnige/nicht erlaubte Wörter erkannt werden.\nÜberflüssige Zeichen (etwa Leerzeichen) werden i.d.R. entfernt.\nsp = 100; \u003cID, sp\u003e, \u003cOP, =\u003e, \u003cINT, 100\u003e, \u003cSEM\u003e Anmerkung: In der obigen Darstellung werden die Werte der Token (\"Lexeme\") zusammen mit den Token \"gespeichert\". Alternativ können die Werte der Token auch direkt in der Symboltabelle gespeichert werden und in den Token nur der Verweis auf den jeweiligen Eintrag in der Tabelle.\nSyntaxanalyse: Sätze erkennen In der Syntaxanalyse (auch Parser genannt) wird die Tokensequenz in gültige Sätze unterteilt. Dazu werden in der Regel kontextfreie Grammatiken und unterschiedliche Parsing-Methoden (top-down, bottom-up) genutzt.\nDabei müssen nicht erlaubte Sätze erkannt werden.\n\u003cID, sp\u003e, \u003cOP, =\u003e, \u003cINT, 100\u003e, \u003cSEM\u003e statement : assign SEM ; assign : ID OP INT ; statement = / \\ / \\ assign SEM sp 100 / | \\ | ID OP INT ; | | | sp = 100 Mit Hilfe der Produktionsregeln der Grammatik wird versucht, die Tokensequenz zu erzeugen. Wenn dies gelingt, ist der Satz (also die Tokensequenz) ein gültiger Satz im Sinne der Grammatik. Dabei sind die Token aus der lexikalischen Analyse die hier betrachteten Wörter!\nDabei entsteht ein sogenannter Parse-Tree (oder auch \"Syntax Tree\"; in der obigen Darstellung der linke Baum). In diesen Bäumen spiegeln sich die Regeln der Grammatik wider, d.h. zu einem Satz kann es durchaus verschiedene Parse-Trees geben.\nBeim AST (\"Abstract Syntax Tree\") werden die Knoten um alle später nicht mehr benötigten Informationen bereinigt (in der obigen Darstellung der rechte Baum).\nAnmerkung: Die Begriffe werden oft nicht eindeutig verwendet. Je nach Anwendung ist das Ergebnis des Parsers ein AST oder ein Parse-Tree.\nAnmerkung: Man könnte statt OP auch etwa ein ASSIGN nutzen und müsste dann das \"=\" nicht extra als Inhalt speichern, d.h. man würde die Information im Token-Typ kodieren.\nVorschau: Parser implementieren stat : assign | ifstat | ... ; assign : ID '=' expr ';' ; void stat() { switch (\u003c\u003ccurrent token\u003e\u003e) { case ID : assign(); break; case IF : ifstat(); break; ... default : \u003c\u003craise exception\u003e\u003e } } void assign() { match(ID); match('='); expr(); match(';'); } Der gezeigte Parser ist ein sogenannter \"LL(1)\"-Parser und geht von oben nach unten vor, d.h. ist ein Top-Down-Parser.\nNach dem Betrachten des aktuellen Tokens wird entschieden, welche Alternative vorliegt und in die jeweilige Methode gesprungen.\nDie match()-Methode entspricht dabei dem Erzeugen von Blättern, d.h. hier werden letztlich die Token der Grammatik erkannt.\nSemantische Analyse: Bedeutung erkennen In der semantischen Analyse (auch Context Handling genannt) wird der AST zusammen mit der Symboltabelle geprüft. Dabei spielen Probleme wie Scopes, Namen und Typen eine wichtige Rolle.\nDie semantische Analyse ist direkt vom Programmierparadigma der zu übersetzenden Sprache abhängig, d.h. müssen wir beispielsweise das Konzept von Klassen verstehen?\nAls Ergebnis dieser Phase entsteht typischerweise ein annotierter AST.\n{ int x = 42; { int x = 7; x += 3; // ??? } } = {type: real, loc: tmp1} sp = 100; / \\ / \\ sp inttofloat {type: real, | loc: var b} 100 Zwischencode generieren Aus dem annotierten AST wird in der Regel ein Zwischencode (\"Intermediate Code\", auch \"IC\") generiert. oft findet man hier den Assembler-ähnlichen \"3-Adressen-Code\", in manchen Compilern wird als IC aber auch der AST selbst genutzt.\n= {type: real, loc: tmp1} / \\ / \\ sp inttofloat {type: real, | loc: var b} 100 =\u003e t1 = inttofloat(100)\nCode optimieren An dieser Stelle verlassen wir das Compiler-Frontend und begeben uns in das sogenannte Backend. Die Optimierung des Codes kann sehr unterschiedlich ausfallen, beispielsweise kann man den Zwischencode selbst optimieren, dann nach sogenanntem \"Targetcode\" übersetzen und diesen weiter optimieren, bevor das Ergebnis im letzten Schritt in Maschinencode übersetzt wird.\nDie Optimierungsphase ist sehr stark abhängig von der Zielhardware. Hier kommen fortgeschrittene Mengen- und Graphalgorithmen zur Anwendung. Die Optimierung stellt den wichtigsten Teil aktueller Compiler dar.\nAus zeitlichen und didaktischen Gründen werden wir in dieser Veranstaltung den Fokus auf die Frontend-Phasen legen und die Optimierung nur grob streifen.\nt1 = inttofloat(100) =\u003e t1 = 100.0\nx = y*0; =\u003e x = 0;\nCode generieren Maschinencode:\nSTD t1, 100.0 Andere Sprache:\nBytecode C ... Probleme 5*4+3 AST?\nProblem: Vorrang von Operatoren\nVariante 1: +(*(5, 4), 3) Variante 2: *(5, +(4, 3)) stat : expr ';' | ID '(' ')' ';' ; expr : ID '(' ')' | INT ; Wrap-Up Compiler übersetzen Text in ein anderes Format\nTypische Phasen:\nLexikalische Analyse Syntaxanalyse Semantische Analyse Generierung von Zwischencode Optimierung des (Zwischen-) Codes Codegenerierung",
    "description": "Sprachen verstehen, Texte transformieren The cat runs quickly.\n=\u003e Struktur? Bedeutung?\nWir können hier (mit steigender Abstraktionsstufe) unterscheiden:\nSequenz von Zeichen\nWörter: Zeichenketten mit bestimmten Buchstaben, getrennt durch bestimmte andere Zeichen; Wörter könnten im Wörterbuch nachgeschlagen werden\nSätze: Anordnung von Wörtern nach einer bestimmten Grammatik, Grenze: Satzzeichen\nHier (vereinfacht): Ein Satz besteht aus Subjekt und Prädikat. Das Subjekt besteht aus einem oder keinen Artikel und einem Substantiv. Das Prädikat besteht aus einem Verb und einem oder keinem Adverb.",
    "tags": [],
    "title": "Struktur eines Compilers",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/00-intro/overview.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Überblick",
    "content": "99 Bottles of Beer 99 bottles of beer on the wall, 99 bottles of beer. Take one down and pass it around, 98 bottles of beer on the wall.\n98 bottles of beer on the wall, 98 bottles of beer. Take one down and pass it around, 97 bottles of beer on the wall.\n[...]\n2 bottles of beer on the wall, 2 bottles of beer. Take one down and pass it around, 1 bottle of beer on the wall.\n1 bottle of beer on the wall, 1 bottle of beer. Take one down and pass it around, no more bottles of beer on the wall.\nNo more bottles of beer on the wall, no more bottles of beer. Go to the store and buy some more, 99 bottles of beer on the wall.\nQuelle: nach \"Lyrics of the song 99 Bottles of Beer\" on 99-bottles-of-beer.net\nImperativ, Hardwarenah: C #define MAXBEER (99) void chug(int beers); main() { register beers; for(beers = MAXBEER; beers; chug(beers--)) puts(\"\"); puts(\"\\nTime to buy more beer!\\n\"); } void chug(register beers) { char howmany[8], *s; s = beers != 1 ? \"s\" : \"\"; printf(\"%d bottle%s of beer on the wall,\\n\", beers, s); printf(\"%d bottle%s of beeeeer . . . ,\\n\", beers, s); printf(\"Take one down, pass it around,\\n\"); if(--beers) sprintf(howmany, \"%d\", beers); else strcpy(howmany, \"No more\"); s = beers != 1 ? \"s\" : \"\"; printf(\"%s bottle%s of beer on the wall.\\n\", howmany, s); } Quelle: \"Language C\" by Bill Wein on 99-bottles-of-beer.net\nImperativ\nProcedural\nStatisches Typsystem\nResourcenschonend, aber \"unsicher\": Programmierer muss wissen, was er tut\nRelativ hardwarenah\nEinsatz: Betriebssysteme, Systemprogrammierung\nImperativ, Objektorientiert: Java class bottles { public static void main(String args[]) { String s = \"s\"; for (int beers=99; beers\u003e-1;) { System.out.print(beers + \" bottle\" + s + \" of beer on the wall, \"); System.out.println(beers + \" bottle\" + s + \" of beer, \"); if (beers==0) { System.out.print(\"Go to the store, buy some more, \"); System.out.println(\"99 bottles of beer on the wall.\\n\"); System.exit(0); } else System.out.print(\"Take one down, pass it around, \"); s = (--beers == 1)?\"\":\"s\"; System.out.println(beers + \" bottle\" + s + \" of beer on the wall.\\n\"); } } } Quelle: \"Language Java\" by Sean Russell on 99-bottles-of-beer.net\nImperativ\nObjektorientiert\nMulti-Threading\nBasiert auf C/C++\nStatisches Typsystem\nAutomatische Garbage Collection\n\"Sichere\" Architektur: Laufzeitumgebung fängt viele Probleme ab\nArchitekturneutral: Nutzt Bytecode und eine JVM\nEinsatz: High-Level All-Purpose Language\nLogisch: Prolog bottles :- bottles(99). bottles(1) :- write('1 bottle of beer on the wall, 1 bottle of beer,'), nl, write('Take one down, and pass it around,'), nl, write('Now they are all gone.'), nl,!. bottles(X) :- write(X), write(' bottles of beer on the wall,'), nl, write(X), write(' bottles of beer,'), nl, write('Take one down and pass it around,'), nl, NX is X - 1, write(NX), write(' bottles of beer on the wall.'), nl, nl, bottles(NX). Quelle: \"Language Prolog\" by M@ on 99-bottles-of-beer.net\nDeklarativ\nLogisch: Definition von Fakten und Regeln; eingebautes Beweissystem\nEinsatz: Theorem-Beweisen, Natural Language Programming (NLP), Expertensysteme, ...\nFunktional: Haskell bottles 0 = \"no more bottles\" bottles 1 = \"1 bottle\" bottles n = show n ++ \" bottles\" verse 0 = \"No more bottles of beer on the wall, no more bottles of beer.\\n\" ++ \"Go to the store and buy some more, 99 bottles of beer on the wall.\" verse n = bottles n ++ \" of beer on the wall, \" ++ bottles n ++ \" of beer.\\n\" ++ \"Take one down and pass it around, \" ++ bottles (n-1) ++ \" of beer on the wall.\\n\" main = mapM (putStrLn . verse) [99,98..0] Quelle: \"Language Haskell\" by Iavor on 99-bottles-of-beer.net\nDeklarativ\nFunktional\nLazy, pure\nStatisches Typsystem\nTypinferenz\nAlgebraische Datentypen, Patternmatching\nEinsatz: Compiler, DSL, Forschung\nBrainfuck Quelle: Screenshot of \"Language Brainfuck\" by Michal Wojciech Tarnowski on 99-bottles-of-beer.net\nImperativ\nFeldbasiert (analog zum Band der Turingmaschine)\n8 Befehle: Zeiger und Zellen inkrementieren/dekrementieren, Aus- und Eingabe, Sprungbefehle\nProgrammiersprache Lox fun fib(x) { if (x == 0) { return 0; } else { if (x == 1) { return 1; } else { fib(x - 1) + fib(x - 2); } } } var wuppie = fib; wuppie(4); Die Sprache \"Lox\" finden Sie hier: craftinginterpreters.com/the-lox-language.html\nC-ähnliche Syntax\nImperativ, objektorientiert, Funktionen als First Class Citizens, Closures\nDynamisch typisiert\nGarbage Collector\nStatements und Expressions\n(Kleine) Standardbibliothek eingebaut\nDie Sprache ähnelt stark anderen modernen Sprachen und ist gut geeignet, um an ihrem Beispiel Themen wie Scanner/Parser/AST, Interpreter, Object Code und VM zu studieren :)\nWrap-Up Compiler übersetzen formalen Text in ein anderes Format\nBerücksichtigung von unterschiedlichen\nSprachkonzepten (Programmierparadigmen) Typ-Systemen Speicherverwaltungsstrategien Abarbeitungsstrategien",
    "description": "99 Bottles of Beer 99 bottles of beer on the wall, 99 bottles of beer. Take one down and pass it around, 98 bottles of beer on the wall.\n98 bottles of beer on the wall, 98 bottles of beer. Take one down and pass it around, 97 bottles of beer on the wall.\n[...]\n2 bottles of beer on the wall, 2 bottles of beer. Take one down and pass it around, 1 bottle of beer on the wall.",
    "tags": [],
    "title": "Bandbreite der Programmiersprachen",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/00-intro/languages.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Überblick",
    "content": "Anwendung: Compiler Wie oben diskutiert: Der Sourcecode durchläuft alle Phasen des Compilers, am Ende fällt ein ausführbares Programm heraus. Dieses kann man starten und ggf. mit Inputdaten versehen und erhält den entsprechenden Output. Das erzeugte Programm läuft i.d.R. nur auf einer bestimmten Plattform.\nBeispiele: gcc, clang, ...\nAnwendung: Interpreter Beim Interpreter durchläuft der Sourcecode nur das Frontend, also die Analyse. Es wird kein Code erzeugt, stattdessen führt der Interpreter die Anweisungen im AST bzw. IC aus. Dazu muss der Interpreter mit den Eingabedaten beschickt werden. Typischerweise hat man hier eine \"Read-Eval-Print-Loop\" (REPL).\nBeispiele: Python\nAnwendung: Virtuelle Maschinen Hier liegt eine Art Mischform aus Compiler und Interpreter vor: Der Compiler übersetzt den Quellcode in ein maschinenunabhängiges Zwischenformat (\"Byte-Code\"). Dieser wird von der virtuellen Maschine (\"VM\") gelesen und ausgeführt. Die VM kann also als Interpreter für Byte-Code betrachtet werden.\nBeispiel: Java mit seiner JVM\nAnwendung: C-Toolchain Erinnern Sie sich an die LV \"Systemprogrammierung\" im dritten Semester :-)\nAuch wenn es so aussieht, als würde der C-Compiler aus dem Quelltext direkt das ausführbare Programm erzeugen, finden hier dennoch verschiedene Stufen statt. Zuerst läuft ein Präprozessor über den Quelltext und ersetzt alle #include und #define etc., danach arbeitet der C-Compiler, dessen Ausgabe wiederum durch einen Assembler zu ausführbarem Maschinencode transformiert wird.\nBeispiele: gcc, clang, ...\nAnwendung: C++-Compiler C++ hat meist keinen eigenen (vollständigen) Compiler :-)\nIn der Regel werden die C++-Konstrukte durch cfront nach C übersetzt, so dass man anschließend auf die etablierten Tools zurückgreifen kann.\nDieses Vorgehen werden Sie relativ häufig finden. Vielleicht sogar in Ihrem Projekt ...\nBeispiel: g++\nAnwendung: Bugfinder Tools wie FindBugs analysieren den (Java-) Quellcode und suchen nach bekannten Fehlermustern. Dazu benötigen sie nur den Analyse-Teil eines Compilers!\nAuf dem AST kann dann nach vorab definierten Fehlermustern gesucht werden (Stichwort \"Graphmatching\"). Dazu fällt die semantische Analyse entsprechend umfangreicher aus als normal.\nZusätzlich wird noch eine Reporting-Komponente benötigt, da die normalen durch die Analysekette erzeugten Fehlermeldungen nicht helfen (bzw. sofern der Quellcode wohlgeformter Code ist, würden ja keine Fehlermeldungen durch die Analyseeinheit generiert).\nBeispiele: SpotBugs, Checkstyle, ESLint, ...\nAnwendung: Pandoc Pandoc ist ein universeller und modular aufgebauter Textkonverter, der mit Hilfe verschiedener Reader unterschiedliche Textformate einlesen und in ein Zwischenformat (hier JSON) transformieren kann. Über verschiedene Writer können aus dem Zwischenformat dann Dokumente in den gewünschten Zielformaten erzeugt werden.\nDie Reader entsprechen der Analyse-Phase und die Writer der Synthese-Phase eines Compilers. Anstelle eines ausführbaren Programms (Maschinencode) wird ein anderes Textformat erstellt/ausgegeben.\nBeispielsweise wird aus diesem Markdown-Schnipsel ...\nDies ist ein Satz mit * einem Stichpunkt, und * einem zweiten Stichpunkt. ... dieses Zwischenformat erzeugt, ...\n{\"blocks\":[{\"t\":\"Para\",\"c\":[{\"t\":\"Str\",\"c\":\"Dies\"},{\"t\":\"Space\"}, {\"t\":\"Str\",\"c\":\"ist\"},{\"t\":\"Space\"},{\"t\":\"Str\",\"c\":\"ein\"}, {\"t\":\"Space\"},{\"t\":\"Str\",\"c\":\"Satz\"},{\"t\":\"Space\"}, {\"t\":\"Str\",\"c\":\"mit\"}]}, {\"t\":\"BulletList\",\"c\":[[{\"t\":\"Plain\",\"c\":[{\"t\":\"Str\",\"c\":\"einem\"},{\"t\":\"Space\"},{\"t\":\"Str\",\"c\":\"Stichpunkt,\"},{\"t\":\"Space\"},{\"t\":\"Str\",\"c\":\"und\"}]}],[{\"t\":\"Plain\",\"c\":[{\"t\":\"Str\",\"c\":\"einem\"},{\"t\":\"Space\"},{\"t\":\"Str\",\"c\":\"zweiten\"},{\"t\":\"Space\"},{\"t\":\"Str\",\"c\":\"Stichpunkt.\"}]}]]}],\"pandoc-api-version\":[1,17,0,4],\"meta\":{}} ... und daraus schließlich dieser TeX-Code.\nDies ist ein Satz mit \\begin{itemize} \\tightlist \\item einem Stichpunkt, und \\item einem zweiten Stichpunkt. \\end{itemize} Im Prinzip ist Pandoc damit ein Beispiel für Compiler, die aus einem formalen Text nicht ein ausführbares Programm erzeugen (Maschinencode), sondern einen anderen formalen Text. Dieser werden häufig auch \"Transpiler\" genannt.\nWeitere Beispiele:\nLexer-/Parser-Generatoren: ANTLR, Flex, Bison, ...: formale Grammatik nach Sourcecode CoffeeScript: CoffeeScript (eine Art \"JavaScript light\") nach JavaScript Emscripten: C/C++ nach LLVM nach WebAssembly (tatsächlich kann LLVM-IR auch direkt als Input verwendet werden) Fitnesse: Word/Wiki nach ausführbare Unit-Tests Was bringt mir das? Beschäftigung mit dem schönsten Thema in der Informatik ;-)\nAuswahl einiger Gründe für den Besuch des Moduls \"Compilerbau\" Erstellung eigener kleiner Interpreter/Compiler Einlesen von komplexen Daten DSL als Brücke zwischen Stakeholdern DSL zum schnelleren Programmieren (denken Sie etwa an CoffeeScript ...) Wie funktionieren FindBugs, Lint und ähnliche Tools? Statische Codeanalyse: Dead code elimination Language-theoretic Security: LangSec Verständnis für bestimmte Sprachkonstrukte und -konzepte (etwa virtual in C++) Vertiefung durch Besuch \"echter\" Compilerbau-Veranstaltungen an Uni möglich :-) Wie funktioniert: ein Python-Interpreter? das Syntaxhighlighting in einem Editor oder in Doxygen? ein Hardwarecompiler (etwa VHDL)? ein Text-Formatierer (TeX, LaTeX, ...)? CoffeeScript oder Emscripten? Wie kann man einen eigenen Compiler/Interpreter basteln, etwa für MiniJava (mit C-Backend) Brainfuck Übersetzung von JSON nach XML Um eine profundes Kenntnis von Programmiersprachen zu erlangen, ist eine Beschäftigung mit ihrer Implementierung unerlässlich. Viele Grundtechniken der Informatik und elementare Datenstrukturen wie Keller, Listen, Abbildungen, Bäume, Graphen, Automaten etc. finden im Compilerbau Anwendung. Dadurch schließt sich in gewisser Weise der Kreis in der Informatikausbildung ... Aufgrund seiner Reife gibt es hervorragende Beispiele von formaler Spezifikation im Compilerbau. Mit dem Gebiet der formalen Sprachen berührt der Compilerbau interessante Aspekte moderner Linguistik. Damit ergibt sich letztlich eine Verbindung zur KI ... Die Unterscheidung von Syntax und Semantik ist eine grundlegende Technik in fast allen formalen Systeme. Parser-Generatoren (Auswahl) Diese Tools könnte man beispielsweise nutzen, um seine eigene Sprache zu basteln.\nANTLR (ANother Tool for Language Recognition) is a powerful parser generator for reading, processing, executing, or translating structured text or binary files: github.com/antlr/antlr4 Grammars written for ANTLR v4; expectation that the grammars are free of actions: github.com/antlr/grammars-v4 An incremental parsing system for programmings tools: github.com/tree-sitter/tree-sitter Flex, the Fast Lexical Analyzer - scanner generator for lexing in C and C++: github.com/westes/flex Bison is a general-purpose parser generator that converts an annotated context-free grammar into a deterministic LR or generalized LR (GLR) parser employing LALR(1) parser tables: gnu.org/software/bison Parser combinators for binary formats, in C: github.com/UpstandingHackers/hammer Eclipse Xtext is a language development framework: github.com/eclipse/xtext Statische Analyse, Type-Checking und Linter Als Startpunkt für eigene Ideen. Oder Verbessern/Erweitern der Projekte ...\nPluggable type-checking for Java: github.com/typetools/checker-framework SpotBugs is FindBugs' successor. A tool for static analysis to look for bugs in Java code: github.com/spotbugs/spotbugs An extensible cross-language static code analyzer: github.com/pmd/pmd Checkstyle is a development tool to help programmers write Java code that adheres to a coding standard: github.com/checkstyle/checkstyle JaCoCo - Java Code Coverage Library: github.com/jacoco/jacoco Sanitizers: memory error detector: github.com/google/sanitizers JSHint is a tool that helps to detect errors and potential problems in your JavaScript code: github.com/jshint/jshint Haskell source code suggestions: github.com/ndmitchell/hlint Syntax checking hacks for vim: github.com/vim-syntastic/syntastic DSL (Domain Specific Language) NVIDIA Material Definition Language SDK: github.com/NVIDIA/MDL-SDK FitNesse -- The Acceptance Test Wiki: github.com/unclebob/fitnesse Hier noch ein Framework, welches auf das Erstellen von DSL spezialisiert ist:\nEclipse Xtext is a language development framework: github.com/eclipse/xtext Konverter von X nach Y Emscripten: An LLVM-to-JavaScript Compiler: github.com/kripken/emscripten \"Unfancy JavaScript\": github.com/jashkenas/coffeescript Universal markup converter: github.com/jgm/pandoc Übersetzung von JSON nach XML Odds and Ends How to write your own compiler: staff.polito.it/silvano.rivoira/HowToWriteYourOwnCompiler.htm Building a modern functional compiler from first principles: github.com/sdiehl/write-you-a-haskell Language-theoretic Security: LangSec Generierung von automatisierten Tests mit Esprima: heise.de/-4129726 Eigener kleiner Compiler/Interpreter, etwa für MiniJava mit C-Backend oder sogar LLVM-Backend Brainfuck Als weitere Anregung: Themen der Mini-Projekte im W17 Java2UMLet JavaDoc-to-Markdown Validierung und Übersetzung von Google Protocol Buffers v3 nach JSON svg2tikz SwaggerLang -- Schreiben wie im Tagebuch Markdown zu LaTeX JavaDocToLaTeX MySQL2REDIS-Parser Wrap-Up Compiler übersetzen formalen Text in ein anderes Format\nNicht alle Stufen kommen immer vor =\u003e unterschiedliche Anwendungen\n\"Echte\" Compiler: Sourcecode nach Maschinencode Interpreter: Interaktive Ausführung Virtuelle Maschinen als Zwischending zwischen Compiler und Interpreter Transpiler: formaler Text nach formalem Text Analysetools: Parsen den Sourcecode, werten die Strukturen aus",
    "description": "Anwendung: Compiler Wie oben diskutiert: Der Sourcecode durchläuft alle Phasen des Compilers, am Ende fällt ein ausführbares Programm heraus. Dieses kann man starten und ggf. mit Inputdaten versehen und erhält den entsprechenden Output. Das erzeugte Programm läuft i.d.R. nur auf einer bestimmten Plattform.\nBeispiele: gcc, clang, ...\nAnwendung: Interpreter",
    "tags": [],
    "title": "Anwendungen",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/00-intro/applications.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25)",
    "content": "In der lexikalischen Analyse soll ein Lexer (auch \"Scanner\") den Zeichenstrom in eine Folge von Token zerlegen. Zur Spezifikation der Token werden in der Regel reguläre Ausdrücke verwendet.\nReguläre Sprachen, Ausdrucksstärke Lexer mit ANTLR generieren",
    "description": "In der lexikalischen Analyse soll ein Lexer (auch \"Scanner\") den Zeichenstrom in eine Folge von Token zerlegen. Zur Spezifikation der Token werden in der Regel reguläre Ausdrücke verwendet.\nReguläre Sprachen, Ausdrucksstärke Lexer mit ANTLR generieren",
    "tags": [],
    "title": "Lexikalische Analyse",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/01-lexing.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Lexikalische Analyse",
    "content": "Motivation Was muss ein Compiler wohl als erstes tun? Hier entsteht ein Tafelbild.\nThemen für heute Endliche Automaten Reguläre Sprachen Lexer Endliche Automaten Alphabete Def.: Ein Alphabet $\\Sigma$ ist eine endliche, nicht-leere Menge von Symbolen. Die Symbole eines Alphabets heißen Buchstaben.\nDef.: Ein Wort $w$ über einem Alphabet $\\Sigma$ ist eine endliche Folge von Symbolen aus $\\Sigma$. $\\epsilon$ ist das leere Wort. Die Länge $\\vert w \\vert$ eines Wortes $w$ ist die Anzahl von Buchstaben, die es enthält (Kardinalität).\nDef.: Eine Sprache $L$ über einem Alphabet $\\Sigma$ ist eine Menge von Wörtern über diesem Alphabet. Sprachen können endlich oder unendlich viele Wörter enthalten.\nBeispiel Hier entsteht ein Tafelbild.\nDeterministische endliche Automaten Hier entsteht ein Tafelbild.\nDef.: Ein deterministischer endlicher Automat (DFA) ist ein 5-Tupel $A = (Q, \\Sigma, \\delta, q_0, F)$ mit\n$Q$ : endliche Menge von Zuständen\n$\\Sigma$ : Alphabet von Eingabesymbolen\n$\\delta$ : die (eventuell partielle) Übergangsfunktion $(Q \\times \\Sigma) \\rightarrow Q$, $\\delta$ kann partiell sein\n$q_0 \\in Q$ : der Startzustand\n$F \\subseteq Q$ : die Menge der Endzustände\nDie Übergangsfunktion Def.: Wir definieren $\\delta^{\\ast}: (Q \\times \\Sigma^{\\ast}) \\rightarrow Q$: induktiv wie folgt:\nBasis: $\\delta^{\\ast}(q, \\epsilon) = q\\ \\forall q \\in Q$\nInduktion: $\\delta^{\\ast}(q, a_1, \\ldots, a_n) = \\delta(\\delta^{\\ast}(q, a_1, \\ldots , a_{n-1}), a_n)$\nDef.: Ein DFA akzeptiert ein Wort $w \\in \\Sigma^{\\ast}$ genau dann, wenn $\\delta^{\\ast}(q_0, w) \\in F.$\nBeispiel Hier entsteht ein Tafelbild.\nNichtdeterministische endliche Automaten Def.: Ein nichtdeterministischer endlicher Automat (NFA) ist ein 5-Tupel $A = (Q, \\Sigma, \\delta, q_0, F)$ mit\n$Q$ : endliche Menge von Zuständen\n$\\Sigma$ : Alphabet von Eingabesymbolen\n$\\delta$ : die (eventuell partielle) Übergangsfunktion $(Q \\times \\Sigma) \\rightarrow Q$\n$q_0 \\in Q$ : der Startzustand\n$F \\subseteq Q$ : die Menge der Endzustände\nAkzeptierte Sprachen Def.: Sei A ein DFA oder ein NFA. Dann ist L(A) die von A akzeptierte Sprache, d. h.\n$L(A) = \\lbrace \\text{Wörter}\\ w\\ |\\ \\delta^*(q_0, w) \\in F \\rbrace$ Wozu NFAs im Compilerbau? Pattern Matching (Erkennung von Schlüsselwörtern, Bezeichnern, ...) geht mit NFAs.\nNFAs sind so nicht zu programmieren, aber:\nSatz: Eine Sprache $L$ wird von einem NFA akzeptiert $\\Leftrightarrow L$ wird von einem DFA akzeptiert.\nD. h. es existieren Algorithmen zur\nUmwandlung von NFAs in DFAS Minimierung von DFAs Reguläre Sprachen Reguläre Ausdrücke definieren Sprachen Def.: Induktive Definition von regulären Ausdrücken (regex) und der von ihnen repräsentierten Sprache L:\nBasis:\n$\\epsilon$ und $\\emptyset$ sind reguläre Ausdrücke mit $L(\\epsilon) = \\lbrace \\epsilon\\rbrace$, $L(\\emptyset)=\\emptyset$ Sei $a$ ein Symbol $\\Rightarrow$ $a$ ist ein regex mit $L(a) = \\lbrace a\\rbrace$ Induktion: Seien $E,\\ F$ reguläre Ausdrücke. Dann gilt:\n$E+F$ ist ein regex und bezeichnet die Vereinigung $L(E + F) = L(E)\\cup L(F)$ $EF$ ist ein regex und bezeichnet die Konkatenation $L(EF) = L(E)L(F)$ $E^{\\ast}$ ist ein regex und bezeichnet die Kleene-Hülle $L(E^{\\ast})=(L(E))^{\\ast}$ $(E)$ ist ein regex mit $L((E)) = L(E)$ Vorrangregeln der Operatoren für reguläre Ausdrücke: *, Konkatenation, +\nBeispiel Hier entsteht ein Tafelbild.\nWichtige Identitäten Satz: Sei $A$ ein DFA $\\Rightarrow \\exists$ regex $R$ mit $L(A) = L(R)$.\nSatz: Sei $E$ ein regex $\\Rightarrow \\exists$ DFA $A$ mit $L(E) = L(A)$.\nFormale Grammatiken Hier entsteht ein Tafelbild.\nFormale Definition formaler Grammatiken Def.: Eine formale Grammatik ist ein 4-Tupel $G=(N,T,P,S)$ aus\n$N$: endliche Menge von Nichtterminalen\n$T$: endliche Menge von Terminalen, $N \\cap T = \\emptyset$\n$S \\in N$: Startsymbol\n$P$: endliche Menge von Produktionen der Form\n$\\qquad X \\rightarrow Y$ mit $X \\in (N \\cup T)^{\\ast} N (N \\cup T)^{\\ast}, Y \\in (N \\cup T)^{\\ast}$\nAbleitungen Def.: Sei $G = (N, T, P, S)$ eine Grammatik, sei $\\alpha A \\beta$ eine Zeichenkette über $(N \\cup T)^{\\ast}$ und sei $A$ $\\rightarrow \\gamma$ eine Produktion von $G$.\nWir schreiben: $\\alpha A \\beta \\Rightarrow \\alpha \\gamma \\beta$ ($\\alpha A \\beta$ leitet $\\alpha \\gamma \\beta$ ab).\nDef.: Wir definieren die Relation $\\overset{\\ast}{\\Rightarrow}$ induktiv wie folgt:\nBasis: $\\forall \\alpha \\in (N \\cup T)^{\\ast} \\alpha \\overset{\\ast}{\\Rightarrow} \\alpha$ (Jede Zeichenkette leitet sich selbst ab.)\nInduktion: Wenn $\\alpha \\overset{\\ast}{\\Rightarrow} \\beta$ und $\\beta\\Rightarrow \\gamma$ dann $\\alpha \\overset{\\ast}{\\Rightarrow} \\gamma$\nDef.: Sei $G = (N, T ,P, S)$ eine formale Grammatik. Dann ist $L(G) = \\lbrace \\text{Wörter}\\ w\\ \\text{über}\\ T \\mid S \\overset{\\ast}{\\Rightarrow} w\\rbrace$ die von $G$ erzeugte Sprache.\nBeispiel Hier entsteht ein Tafelbild.\nReguläre Grammatiken Def.: Eine reguläre (oder type-3-) Grammatik ist eine formale Grammatik mit den folgenden Einschränkungen:\nAlle Produktionen sind entweder von der Form\n$X \\to aY$ mit $X \\in N, a \\in T, Y \\in N$ (rechtsreguläre Grammatik) oder $X \\to Ya$ mit $X \\in N, a \\in T, Y \\in N$ (linksreguläre Grammatik) $X\\rightarrow\\epsilon$ ist erlaubt\nBeispiel Hier entsteht ein Tafelbild.\nReguläre Sprachen und ihre Grenzen Satz: Die von endlichen Automaten akzeptiert Sprachklasse, die von regulären Ausdrücken beschriebene Sprachklasse und die von regulären Grammatiken erzeugte Sprachklasse sind identisch und heißen reguläre Sprachen.\nReguläre Sprachen\neinfache Struktur Matchen von Symbolen (z. B. Klammern) nicht möglich, da die fixe Anzahl von Zuständen eines DFAs die Erkennung solcher Sprachen verhindert. Wozu reguläre Sprachen im Compilerbau? Reguläre Ausdrücke\ndefinieren Schlüsselwörter und alle weiteren Symbole einer Programmiersprache, z. B. den Aufbau von Gleitkommazahlen werden (oft von einem Generator) in DFAs umgewandelt sind die Basis des Scanners oder Lexers Lexer Ein Lexer ist mehr als ein DFA Ein Lexer\nwandelt mittels DFAs aus regulären Ausdrücken die Folge von Zeichen der Quelldatei in eine Folge von sog. Token um\nbekommt als Input eine Liste von Paaren aus regulären Ausdrücken und Tokennamen, z. B. (\"while\", WHILE)\nKommentare und Strings müssen richtig erkannt werden. (Schachtelungen)\nliefert Paare von Token und deren Werte, sofern benötigt, z. B. (WHILE, _), oder (IDENTIFIER, \"radius\") oder (INTEGERZAHL, \"334\")\nWie geht es weiter? Ein Parser\nführt mit Hilfe des Tokenstreams vom Lexer die Syntaxanalyse durch\nbasiert auf einer sog. kontextfreien Grammatik, deren Terminale die Token sind\nliefert die syntaktische Struktur in Form eines Ableitungsbaums (syntax tree, parse tree), bzw. einen AST (abstract syntax tree) ohne redundante Informationen im Ableitungsbaum (z. B. Semikolons)\nliefert evtl. Fehlermeldungen\nWrap-Up Wrap-Up Definition und Aufgaben von Lexern DFAs und NFAs Reguläre Ausdrücke Reguläre Grammatiken Zusammenhänge zwischen diesen Mechanismen und Lexern, bzw. Lexergeneratoren",
    "description": "Motivation Was muss ein Compiler wohl als erstes tun? Hier entsteht ein Tafelbild.\nThemen für heute Endliche Automaten Reguläre Sprachen Lexer Endliche Automaten Alphabete Def.: Ein Alphabet $\\Sigma$ ist eine endliche, nicht-leere Menge von Symbolen. Die Symbole eines Alphabets heißen Buchstaben.\nDef.: Ein Wort $w$ über einem Alphabet $\\Sigma$ ist eine endliche Folge von Symbolen aus $\\Sigma$. $\\epsilon$ ist das leere Wort. Die Länge $\\vert w \\vert$ eines Wortes $w$ ist die Anzahl von Buchstaben, die es enthält (Kardinalität).",
    "tags": [],
    "title": "Reguläre Sprachen, Ausdrucksstärke",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/01-lexing/regular.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25)",
    "content": "In der syntaktischen Analyse arbeitet ein Parser mit dem Tokenstrom, der vom Lexer kommt. Mit Hilfe einer Grammatik wird geprüft, ob gültige Sätze im Sinne der Sprache/Grammatik gebildet wurden. Der Parser erzeugt dabei den Parse-Tree. Man kann verschiedene Parser unterscheiden, beispielsweise die LL- und die LR-Parser.\nCFG Parser mit ANTLR generieren",
    "description": "In der syntaktischen Analyse arbeitet ein Parser mit dem Tokenstrom, der vom Lexer kommt. Mit Hilfe einer Grammatik wird geprüft, ob gültige Sätze im Sinne der Sprache/Grammatik gebildet wurden. Der Parser erzeugt dabei den Parse-Tree. Man kann verschiedene Parser unterscheiden, beispielsweise die LL- und die LR-Parser.\nCFG Parser mit ANTLR generieren",
    "tags": [],
    "title": "Syntaktische Analyse",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/02-parsing.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Syntaktische Analyse",
    "content": "Wiederholung Endliche Automaten, reguläre Ausdrücke, reguläre Grammatiken, reguläre Sprachen Wie sind DFAs und NFAs definiert? Was sind reguläre Ausdrücke? Was sind formale und reguläre Grammatiken? In welchem Zusammenhang stehen all diese Begriffe? Wie werden DFAs und reguläre Ausdrücke im Compilerbau eingesetzt? Motivation Wofür reichen reguläre Sprachen nicht? Für z. B. alle Sprachen, in deren Wörtern Zeichen über eine Konstante hinaus gezählt werden müssen. Diese Sprachen lassen sich oft mit Variablen im Exponenten beschreiben, die unendlich viele Werte annehmen können.\n$a^ib^{2*i}$ ist nicht regulär\n$a^ib^{2*i}$ für $0 \\leq i \\leq 3$ ist regulär\nWo finden sich die oben genannten Variablen bei einem DFA wieder?\nWarum ist die erste Sprache oben nicht regulär, die zweite aber?\nThemen für heute PDAs: mächtiger als DFAs, NFAs kontextfreie Grammatiken und Sprachen: mächtiger als reguläre Grammatiken und Sprachen DPDAs und deterministisch kontextfreie Grammatiken: die Grundlage der Syntaxanalyse im Compilerbau Der Einsatz kontextfreier Grammatiken zur Syntaxanalyse mittels Top-Down-Techniken Einordnung: Erweiterung der Automatenklasse DFA, um komplexere Sprachen als die regulären akzeptieren zu können Wir spendieren den DFAs einen möglichst einfachen, aber beliebig großen, Speicher, um zählen und matchen zu können. Wir suchen dabei konzeptionell die \"kleinstmögliche\" Erweiterung, die die akzeptierte Sprachklasse gegenüber DFAs vergrößert.\nDer konzeptionell einfachste Speicher ist ein Stack. Wir haben keinen wahlfreien Zugriff auf die gespeicherten Werte.\nEs soll eine deterministische und eine indeterministische Variante der neuen Automatenklasse geben.\nIn diesem Zusammenhang wird der Stack auch Keller genannt.\nKellerautomaten (Push-Down-Automata, PDAs) Def.: Ein Kellerautomat (PDA) $P = (Q,\\ \\Sigma,\\ \\Gamma,\\ \\delta,\\ q_0,\\ \\perp,\\ F)$ ist ein Septupel mit:\nDefinition eines PDAs\nEin PDA ist per Definition nichtdeterministisch und kann spontane Zustandsübergänge durchführen.\nWas kann man damit akzeptieren? Strukturen mit paarweise zu matchenden Symbolen.\nBei jedem Zustandsübergang wird ein Zeichen (oder $\\epsilon$) aus der Eingabe gelesen, ein Symbol von Keller genommen. Diese und das Eingabezeichen bestimmen den Folgezustand und eine Zeichenfolge, die auf den Stack gepackt wird. Dabei wird ein Symbol, (z. B. eines, das später mit einem Eingabesymbol zu matchen ist,) auf den Stack gepackt. Soll das automatisch vom Stack genommene Symbol auf dem Stack bleiben, muss es wieder gepusht werden.\nBeispiel Ein PDA für $L=\\lbrace ww^{R}\\mid w\\in \\lbrace a,b\\rbrace^{\\ast}\\rbrace$:\nDeterministische PDAs Def. Ein PDA $P = (Q, \\Sigma, \\Gamma, \\delta, q_0, \\perp, F)$ ist deterministisch $: \\Leftrightarrow$\n$\\delta(q, a, X)$ hat höchstens ein Element für jedes $q \\in Q, a \\in\\Sigma$ oder $(a = \\epsilon$ und $X \\in \\Gamma)$.\nWenn $\\delta (q, a, x)$ nicht leer ist für ein $a \\in \\Sigma$, dann muss $\\delta (q, \\epsilon, x)$ leer sein.\nDeterministische PDAs werden auch DPDAs genannt.\nDer kleine Unterschied Satz: Die von DPDAs akzeptierten Sprachen sind eine echte Teilmenge der von PDAs akzeptierten Sprachen.\nDie regulären Sprachen sind eine echte Teilmenge der von DPDAs akzeptierten Sprachen.\nKontextfreie Grammatiken und Sprachen Kontextfreie Grammatiken Def. Eine kontextfreie (cf-) Grammatik ist ein 4-Tupel $G = (N, T, P, S)$ mit $N, T, S$ wie in (formalen) Grammatiken und $P$ ist eine endliche Menge von Produktionen der Form:\n$X \\rightarrow Y$ mit $X \\in N, Y \\in {(N \\cup T)}^{\\ast}$.\n$\\Rightarrow, \\overset{\\ast}{\\Rightarrow}$ sind definiert wie bei regulären Sprachen. Bei cf-Grammatiken nennt man die Ableitungsbäume oft Parse trees.\nBeispiel $S \\rightarrow a \\mid S\\ +\\ S\\ |\\ S \\ast S$ Ableitungsbäume für $a + a \\ast a$:\nHier entsteht ein Tafelbild.\nNicht jede kontextfreie Grammatik ist eindeutig Def.: Gibt es in einer von einer kontextfreien Grammatik erzeugten Sprache ein Wort, für das mehr als ein Ableitungsbaum existiert, so heißt diese Grammatik mehrdeutig. Anderenfalls heißt sie eindeutig.\nSatz: Es ist nicht entscheidbar, ob eine gegebene kontextfreie Grammatik eindeutig ist.\nSatz: Es gibt kontextfreie Sprachen, für die keine eindeutige Grammatik existiert.\nKontextfreie Grammatiken und PDAs Satz: Die kontextfreien Sprachen und die Sprachen, die von PDAs akzeptiert werden, sind dieselbe Sprachklasse.\nSatz: Eine von einem DPDA akzeptierteSprache hat eine eindeutige Grammatik.\nVorgehensweise im Compilerbau: Eine Grammatik für die gewünschte Sprache definieren und schauen, ob sich daraus ein DPDA generieren lässt (automatisch).\nSyntaxanalyse Was brauchen wir für die Syntaxanalyse von Programmen? einen Grammatiktypen, aus dem sich manuell oder automatisiert ein Programm zur deterministischen Syntaxanalyse (=Parser) erstellen lässt\neinen Algorithmus zum Parsen von Programmen mit Hilfe einer solchen Grammatik\nSyntax Wir verstehen unter Syntax eine Menge von Regeln, die die Struktur von Daten (z. B. Programmen) bestimmen.\nDiese vorgegebene Syntax wird im Compilerbau mit einer kontextfreien Grammatik beschrieben und mit einem sogenannten Parser analysiert.\nHeute: LL-Parsing, mit dem man eine Teilmenge der eindeutigen kontextfreien Grammatiken syntaktich analysieren kann.\nDabei wird der Ableitungsbaum von oben nach unten aufgebaut.\nZiele der Syntaxanalyse Bestimmung der syntaktischen Struktur eines Programms\naussagekräftige Fehlermeldungen, wenn ein Eingabeprogramm syntaktisch nicht korrekt ist\nErstellung des AST (abstrakter Syntaxbaum): Der Parse Tree ohne Symbole, die nach der Syntaxanalyse inhaltlich irrelevant sind (z. B. Semikolons, manche Schlüsselwörter)\ndie Symboltablelle(n) mit Informationen bzgl. Bezeichner (Variable, Funktionen und Methoden, Klassen, benutzerdefinierte Typen, Parameter, ...), aber auch die Gültigkeitsbereiche.\nLL(k)-Grammatiken First-Mengen $S \\rightarrow A \\ \\vert \\ B \\ \\vert \\ C$ Welche Produktion nehmen?\nWir brauchen die \"terminalen k-Anfänge\" von Ableitungen von Nichtterminalen, um eindeutig die nächste zu benutzende Produktion festzulegen. $k$ ist dabei die Anzahl der Vorschautoken.\nDef.: Wir definieren $First$ - Mengen einer Grammatik wie folgt:\n$a \\in T^\\ast, |a| \\leq k: {First}_k (a) = \\lbrace a \\rbrace$ $a \\in T^\\ast, |a| \u003e k: {First}_k (a) = \\lbrace v \\in T^\\ast \\mid a = vw, |v| = k \\rbrace$ $\\alpha \\in (N \\cup T)^\\ast \\backslash T^\\ast: {First}_k (\\alpha) = \\lbrace v \\in T^\\ast \\mid \\alpha \\overset{\\ast}{\\Rightarrow} w,\\text{mit}\\ w \\in T^\\ast, First_k(w) = \\lbrace v \\rbrace \\rbrace$ Linksableitungen Def.: Bei einer kontextfreien Grammatik $G$ ist die Linksableitung von $\\alpha \\in (N \\cup T)^{\\ast}$ die Ableitung, die man erhält, wenn in jedem Schritt das am weitesten links stehende Nichtterminal in $\\alpha$ abgeleitet wird.\nMan schreibt $\\alpha \\overset{\\ast}{\\Rightarrow}_l \\beta.$\nLL(k)-Grammatiken Def.: Eine kontextfreie Grammatik $G = (N, T, P, S)$ ist genau dann eine LL(k)-Grammatik, wenn für alle Linksableitungen der Form:\n$S \\overset{\\ast}{\\Rightarrow}_l\\ wA \\gamma\\ {\\Rightarrow}_l\\ w\\alpha\\gamma \\overset{\\ast}{\\Rightarrow}_l wx$ und\n$S \\overset{\\ast}{\\Rightarrow}_l wA \\gamma {\\Rightarrow}_l w\\beta\\gamma \\overset{\\ast}{\\Rightarrow}_l wy$ mit $(w, x, y \\in T^\\ast, \\alpha, \\beta, \\gamma \\in (N \\cup T)^\\ast, A \\in N)$ und $First_k(x) = First_k(y)$ gilt:\n$\\alpha = \\beta$ LL(1)-Grammatiken Hier entsteht ein Tafelbild.\nLL(k)-Sprachen Die von LL(k)-Grammatiken erzeugten Sprachen sind eine echte Teilmenge der deterministisch parsbaren Sprachen.\nDie von LL(k)-Grammatiken erzeugten Sprachen sind eine echte Teilmenge der von LL(k+1)-Grammatiken erzeugten Sprachen.\nFür eine kontextfreie Grammatik $G$ ist nicht entscheidbar, ob es eine LL(1) - Grammatik $G'$ gibt mit $L(G) = L(G')$.\nIn der Praxis reichen LL(1) - Grammatiken oft. Hier gibt es effiziente Parsergeneratoren (hier: ANTLR), deren Eingabe eine LL-Grammatik ist, und die als Ausgabe den Quellcode eines (effizienten) tabellengesteuerten Parsers generieren.\nWas brauchen wir zur Erzeugung eines LL(k)-Parsers? eine LL(k)-Grammatik die $First_k$-Mengen der rechten Seiten aller Produktionsregeln die $Follow_k$-Mengen aller Nichtterminale und der rechten Seiten aller Produktionsregeln das Endezeichen $\\perp$ hinter dem Eingabewort Def.: Wir definieren $Follow$ - Mengen einer Grammatik wie folgt:\n$Follow_k(\\beta) = \\lbrace w \\in T^\\ast\\ |\\ \\exists \\alpha, \\gamma \\in (N \\cup T)^\\ast\\ \\text{mit}\\ S \\overset{\\ast}{\\Rightarrow}_l\\ \\alpha \\beta \\gamma\\ \\text{und}\\ w \\in First_k(\\gamma) \\rbrace$ Beispiel: First- und Follow-Mengen Hier entsteht ein Tafelbild.\nAlgorithmus: Konstruktion einer LL-Parsertabelle Eingabe: Eine Grammatik $G = (N, T, P, S)$\nAusgabe: Eine Parsertabelle $P$\nAlgorithmus zur Generierung einer LL-Parsertabelle\nStatt $First_1(\\alpha)$ wird oft nur $First(\\alpha)$ geschrieben.\nBeispiel: LL-Parsertabellen Hier entsteht ein Tafelbild.\nLL-Parser Rekursive Programmierung bedeutet, dass das Laufzeitsystem einen Stack benutzt. Diesen Stack kann man auch \"selbst programmieren\", d. h. einen PDA implementieren. Dabei wird ebenfalls die oben genannte Tabelle zur Bestimmung der nächsten anzuwendenden Produktion benutzt. Der Stack enthält die zu erwartenden Eingabezeichen, wenn immer eine Linksableitung gebildet wird. Diese Zeichen im Stack werden mit dem Input gematcht.\nAlgorithmus: Tabellengesteuertes LL-Parsen mit einem PDA Eingabe: Eine Grammatik $G = (N, T, P, S)$, eine Parsertabelle $P$ mit \"$w\\perp$\" als initialem Kellerinhalt\nAusgabe: Wenn $w \\in L(G)$, eine Linksableitung von $w$, Fehler sonst\nAlgorithmus zum tabellengesteuerten LL-Parsen\nBeispiel: LL-Parsen Hier entsteht ein Tafelbild.\nErgebnisse der Syntaxanalyse eventuelle Syntaxfehler mit Angabe der Fehlerart und des -Ortes\nFormat für die Weiterverarbeitung:\nAbleitungsbaum oder Syntaxbaum oder Parse Tree abstrakter Syntaxbaum (AST): Der Parse Tree ohne Symbole, die nach der Syntaxanalyse inhaltlich irrelevant sind (z. B. ;, Klammern, manche Schlüsselwörter, $\\ldots$) Wrap-Up Das sollen Sie mitnehmen Die Struktur von gängigen Programmiersprachen lässt sich nicht mit regulären Ausdrücken beschreiben und damit nicht mit DFAs akzeptieren. Das Automatenmodell der DFAs wird um einen endlosen Stack erweitert, das ergibt PDAs. Kontextfreie Grammatiken (CFGs) erweitern die regulären Grammatiken. Deterministisch parsebare Sprachen haben eine eindeutige kontextfreie Grammatik. Es ist nicht entscheidbar, ob eine gegebene kontextfreie Grammatik eindeutig ist. Syntaxanalyse wird mit deterministisch kontextfreien Grammatiken durchgeführt. Eine Teilmenge der dazu gehörigen Sprachen lässt sich top-down parsen. Ein effizienter LL(k)-Parser realisiert einen DPDA und kann automatisch aus einer LL(k)-Grammatik generiert werden. Der Parser liefert in der Regel einen abstrakten Syntaxbaum.",
    "description": "Wiederholung Endliche Automaten, reguläre Ausdrücke, reguläre Grammatiken, reguläre Sprachen Wie sind DFAs und NFAs definiert? Was sind reguläre Ausdrücke? Was sind formale und reguläre Grammatiken? In welchem Zusammenhang stehen all diese Begriffe? Wie werden DFAs und reguläre Ausdrücke im Compilerbau eingesetzt? Motivation Wofür reichen reguläre Sprachen nicht? Für z. B. alle Sprachen, in deren Wörtern Zeichen über eine Konstante hinaus gezählt werden müssen. Diese Sprachen lassen sich oft mit Variablen im Exponenten beschreiben, die unendlich viele Werte annehmen können.",
    "tags": [],
    "title": "CFG",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/02-parsing/cfg.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Praktikum",
    "content": "A1.1: Sprachen von regulären Ausdrücken (1P) Welche Sprache wird von dem folgenden regulären Ausdruck beschrieben?\n$a\\ +\\ a\\ (a\\ +\\ b)^*\\ a$ A1.2: Bezeichner in Programmiersprachen (3P) Betrachten Sie eine Programmiersprache, in der die Bezeichner (= Namen für Variablen, Funktionen, Klassen, Methoden, ...) folgenden Aufbau haben:\nAlle Variablennamen beginnen mit V oder v Handelt es sich um globale Variablen, beginnen Sie mit V, lokale beginnen mit v Funktions- und Methodenparameter beginnen mit p, KLassenparameter (bei der Definition von Vererbung) beginnen mit P Weitere Bezeichner müssen mit einem Buchstaben (a-z, A-Z) beginnen Die folgenden Zeichen dürfen Buchstaben, Ziffern und ein Untersreich sein Bezeichner dürfen nicht mit einem Unterstrich enden Alle Bezeichner müssen aus mindestens zwei Zeichen bestehen Entwickeln Sie einen regulären Ausdruck, der den Aufbau der Bezeichner beschreibt. Beachten Sie, dass Ihr regex alle zulässigen Bezeichner beschreiben muss, aber keinen einzigen unzulässigen beschreiben darf. Wählen Sie zwei Bezeichner aus der Sprache und zeigen Sie, wie sie vom regex gematcht werden.\nEntwickeln Sie einen DFA, der diese Bezeichner akzeptiert. Beachten Sie, dass Ihr DFA alle zulässigen Bezeichner akzeptieren muss, aber keinen einzigen unzulässigen akzeptieren darf. Wählen Sie zwei Bezeichner aus der Sprache und zeigen Sie, wie sie vom Automaten zeichenweise gelesen und akzeptiert werden.\nEntwickeln Sie eine reguläre Grammatik, die diese Bezeichner generiert. Beachten Sie, dass Ihre Grammatik alle zulässigen Bezeichner generieren können muss, aber keinen einzigen unzulässigen generieren darf. Wählen Sie zwei Bezeichner aus der Sprache und zeigen Sie die Ableitungsbäume dazu.\nA1.3: Gleitkommazahlen in Programmiersprachen (2P) Recherchieren Sie zunächst den Aufbau von Gleitkommazahlen in Python und Java.\nErstellen Sie für jede der beiden Programmiersprachen reguläre Ausdrücke, DFAs und reguläre Grammatiken wie in Aufgabe 1. Verifizieren Sie Ihre Lösungen wie in Aufgabe 1.\nA1.4: Mailadressen? (1P) Warum ist der folgende regex ungeeignet für die Verarbeitung von Mailadressen?\n$(a-z)^+@(a-z).(a-z)$ Bitte beachten Sie, dass die Schreibweise a-z nicht unserer Definition genügt. Eigentlich müsste jedes Zeichen aufgeführt werden:\n$a + b + c + c + \\ldots + z$ ist besser, aber immer noch nicht richtig. Warum?\nAnmerkung: Diese Darstellung wird ab jetzt akzeptiert.\nVerbessern Sie den gegebenen regulären Ausdruck.\nA1.5: Der zweitletzte Buchstabe (1P) Entwickeln Sie einen DFA, der nur Wörter über $\\Sigma = \\lbrace 1,2,3 \\rbrace$ akzeptiert, deren zweitletztes Zeichen dasselbe ist wie das zweite.\nA1.6: Sprache einer regulären Grammatik (2P) Welche Sprache generiert die folgende Grammatik?\n$$\\begin{eqnarray} S \u0026\\rightarrow\u0026 a A \\nonumber \\\\ A \u0026\\rightarrow\u0026 d B \\ | \\ b A \\ | \\ c A \\nonumber \\\\ B \u0026\\rightarrow\u0026 a c \\ | \\ b C \\ | \\ c A \\nonumber \\\\ C \u0026\\rightarrow\u0026 \\epsilon \\nonumber \\end{eqnarray}$$",
    "description": "A1.1: Sprachen von regulären Ausdrücken (1P) Welche Sprache wird von dem folgenden regulären Ausdruck beschrieben?\n$a\\ +\\ a\\ (a\\ +\\ b)^*\\ a$ A1.2: Bezeichner in Programmiersprachen (3P) Betrachten Sie eine Programmiersprache, in der die Bezeichner (= Namen für Variablen, Funktionen, Klassen, Methoden, ...) folgenden Aufbau haben:\nAlle Variablennamen beginnen mit V oder v Handelt es sich um globale Variablen, beginnen Sie mit V, lokale beginnen mit v Funktions- und Methodenparameter beginnen mit p, KLassenparameter (bei der Definition von Vererbung) beginnen mit P Weitere Bezeichner müssen mit einem Buchstaben (a-z, A-Z) beginnen Die folgenden Zeichen dürfen Buchstaben, Ziffern und ein Untersreich sein Bezeichner dürfen nicht mit einem Unterstrich enden Alle Bezeichner müssen aus mindestens zwei Zeichen bestehen Entwickeln Sie einen regulären Ausdruck, der den Aufbau der Bezeichner beschreibt. Beachten Sie, dass Ihr regex alle zulässigen Bezeichner beschreiben muss, aber keinen einzigen unzulässigen beschreiben darf. Wählen Sie zwei Bezeichner aus der Sprache und zeigen Sie, wie sie vom regex gematcht werden.",
    "tags": [],
    "title": "Blatt 01: Reguläre Sprachen",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/homework/sheet01.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Lexikalische Analyse",
    "content": "Lexer: Erzeugen eines Token-Stroms aus einem Zeichenstrom Aus dem Eingabe(-quell-)text\n/* demo */ a= [5 , 6] ; erstellt der Lexer (oder auch Scanner genannt) eine Sequenz von Token:\n\u003cID, \"a\"\u003e \u003cASSIGN\u003e \u003cLBRACK\u003e \u003cNUM, 5\u003e \u003cCOMMA\u003e \u003cNUM, 6\u003e \u003cRBRACK\u003e \u003cSEMICOL\u003e Input: Zeichenstrom (Eingabedatei o.ä.) Verarbeitung: Finden sinnvoller Sequenzen im Zeichenstrom (\"Lexeme\"), Einteilung in Kategorien und Erzeugen von Token (Paare: Typ/Name, Wert) Ausgabe: Tokenstrom Normalerweise werden für spätere Phasen unwichtige Elemente wie White-Space oder Kommentare entfernt.\nDurch diese Vorverarbeitung wird eine höhere Abstraktionsstufe erreicht und es können erste grobe Fehler gefunden werden. Dadurch kann der Parser auf einer abstrakteren Stufe arbeiten und muss nicht mehr den gesamten ursprünglichen Zeichenstrom verarbeiten.\nAnmerkung: In dieser Phase steht die Geschwindigkeit stark im Vordergrund: Der Lexer \"sieht\" alle Zeichen im Input. Deshalb findet man häufig von Hand kodierte Lexer, obwohl die Erstellung der Lexer auch durch Generatoren erledigt werden könnte ...\nAnmerkung: Die Token sind die Terminalsymbole in den Parserregeln (Grammatik).\nDefinition wichtiger Begriffe Token: Tupel (Tokenname, optional: Wert)\nDer Tokenname ist ein abstraktes Symbol, welches eine lexikalische Einheit repräsentiert (Kategorie). Die Tokennamen sind die Eingabesymbole für den Parser.\nToken werden i.d.R. einfach über ihren Namen referenziert. Token werden häufig zur Unterscheidung von anderen Symbolen in der Grammatik in Fettschrift oder mit großen Anfangsbuchstaben geschrieben.\nEin Token kann einen Wert haben, etwa eine Zahl oder einen Bezeichner, der auf das zum Token gehörende Pattern gematcht hatte (also das Lexem). Wenn der Wert des Tokens eindeutig über den Namen bestimmt ist (im Beispiel oben beim Komma oder den Klammern), dann wird häufig auf den Wert verzichtet.\nLexeme: Sequenz von Zeichen im Eingabestrom, die auf ein Tokenpattern matcht und vom Lexer als Instanz dieses Tokens identifiziert wird.\nPattern: Beschreibung der Form eines Lexems\nBei Schlüsselwörtern oder Klammern etc. sind dies die Schlüsselwörter oder Klammern selbst. Bei Zahlen oder Bezeichnern (Namen) werden i.d.R. reguläre Ausdrücke zur Beschreibung der Form des Lexems formuliert.\nTypische Muster für Erstellung von Token Schlüsselwörter\nEin eigenes Token (RE/DFA) für jedes Schlüsselwort, oder Erkennung als Name und Vergleich mit Wörterbuch und nachträgliche Korrektur des Tokentyps Wenn Schlüsselwörter über je ein eigenes Token abgebildet werden, benötigt man für jedes Schlüsselwort einen eigenen RE bzw. DFA. Die Erkennung als Bezeichner und das Nachschlagen in einem Wörterbuch (geeignete Hashtabelle) sowie die entsprechende nachträgliche Korrektur des Tokentyps kann die Anzahl der Zustände im Lexer signifikant reduzieren!\nOperatoren\nEin eigenes Token für jeden Operator, oder Gemeinsames Token für jede Operatoren-Klasse Bezeichner: Ein gemeinsames Token für alle Namen\nZahlen: Ein gemeinsames Token für alle numerischen Konstante (ggf. Integer und Float unterscheiden)\nFür Zahlen führt man oft ein Token \"NUM\" ein. Als Attribut speichert man das Lexem i.d.R. als String. Alternativ kann man (zusätzlich) das Lexem in eine Zahl konvertieren und als (zusätzliches) Attribut speichern. Dies kann in späteren Stufen viel Arbeit sparen.\nString-Literale: Ein gemeinsames Token\nKomma, Semikolon, Klammern, ...: Je ein eigenes Token\nRegeln für White-Space und Kommentare etc. ...\nNormalerweise benötigt man Kommentare und White-Spaces in den folgenden Stufen nicht und entfernt diese deshalb aus dem Eingabestrom. Dabei könnte man etwa White-Spaces in den Pattern der restlichen Token berücksichtigen, was die Pattern aber sehr komplex macht. Die Alternative sind zusätzliche Pattern, die auf die White-Space und anderen nicht benötigten Inhalt matchen und diesen \"geräuschlos\" entfernen. Mit diesen Pattern werden keine Token erzeugt, d.h. der Parser und die anderen Stufen bemerken nichts von diesem Inhalt.\nGelegentlich benötigt man aber auch Informationen über White-Spaces, beispielsweise in Python. Dann müssen diese Token wie normale Token an den Parser weitergereicht werden.\nJedes Token hat i.d.R. ein Attribut, in dem das Lexem gespeichert wird. Bei eindeutigen Token (etwa bei eigenen Token je Schlüsselwort oder bei den Interpunktions-Token) kann man sich das Attribut auch sparen, da das Lexem durch den Tokennamen eindeutig rekonstruierbar ist.\nToken Beschreibung Beispiel-Lexeme if Zeichen i und f if relop \u003c oder \u003e oder \u003c= oder \u003e= oder == oder != \u003c, \u003c= id Buchstabe, gefolgt von Buchstaben oder Ziffern pi, count, x3 num Numerische Konstante 42, 3.14159, 0 literal Alle Zeichen außer \", in \" eingeschlossen \"core dumped\" Anmerkung: Wenn es mehrere matchende REs gibt, wird in der Regel das längste Lexem bevorzugt. Wenn es mehrere gleich lange Alternativen gibt, muss man mit Vorrangregeln bzgl. der Token arbeiten.\nHello World grammar Hello; start : 'hello' GREETING ; GREETING : [a-zA-Z]+ ; WHITESPACE : [ \\t\\n]+ -\u003e skip ; Konsole: Hello (Classpath, Aliase, grun, Main, Dateien, Ausgabe) Hinweis zur Grammatik (Regeln) start ist eine Parser-Regel =\u003e Eine Parser-Regel pro Grammatik wird benötigt, damit man den generierten Parser am Ende auch starten kann ... Die anderen beiden Regeln (mit großem Anfangsbuchstaben) aus der obigen Grammatik zählen zum Lexer ANTLR einrichten Aktuelle Version herunterladen: antlr.org, für Java als Zielsprache: \"Complete ANTLR 4.x Java binaries jar\" CLASSPATH setzen: export CLASSPATH=\".:/\u003cpathToJar\u003e/antlr-4.11.1-complete.jar:$CLASSPATH\" Aliase einrichten (.bashrc): alias antlr='java org.antlr.v4.Tool' alias grun='java org.antlr.v4.gui.TestRig' Alternativ über den Python-Installer: pip install antlr4-tools Im Web ohne lokale Installation: ANTLR Lab (vgl. github.com/antlr/antlr4/blob/master/doc/getting-started.md)\n\"Hello World\" übersetzen und ausführen Grammatik übersetzen und Code generieren: antlr Hello.g4 Java-Code kompilieren: javac *.java Lexer ausführen: grun Hello start -tokens (Grammatik \"Hello\", Startregel \"start\")\nAlternativ mit kleinem Java-Programm:\nimport org.antlr.v4.runtime.*; public class Main { public static void main(String[] args) throws Exception { Lexer l = new HelloLexer(CharStreams.fromStream(System.in)); Token t = l.nextToken(); while (t.getType() != Token.EOF) { System.out.println(t); t = l.nextToken(); } } } Generierte Dateien und Klassen Nach dem Übersetzen finden sich folgende Dateien und Klassen vor:\n. ├── bin │ ├── HelloBaseListener.class │ ├── HelloBaseVisitor.class │ ├── HelloLexer.class │ ├── HelloListener.class │ ├── HelloParser.class │ ├── HelloParser$RContext.class │ ├── HelloVisitor.class │ └── Main.class ├── Hello.g4 └── src ├── HelloBaseListener.java ├── HelloBaseVisitor.java ├── HelloLexer.java ├── HelloLexer.tokens ├── HelloListener.java ├── HelloParser.java ├── Hello.tokens ├── HelloVisitor.java └── Main.java Anmerkung: Die Ordnerstruktur wurde durch ein ANTLR-Plugin für Eclipse erzeugt. Bei Ausführung in der Konsole liegen alle Dateien in einem Ordner.\nAnmerkung: Per Default werden nur die Listener angelegt, für die Visitoren muss eine extra Option mitgegeben werden.\nDie Dateien Hello.tokens und HelloLexer.tokens enthalten die Token samt einer internen Nummer. (Der Inhalt beider Dateien ist identisch.)\nDie Datei HelloLexer.java enthält den generierten Lexer, der eine Spezialisierung der abstrakten Basisklasse Lexer darstellt. Über den Konstruktor wird der zu scannende CharStream gesetzt. Über die Methode Lexer#nextToken() kann man sich die erkannten Token der Reihe nach zurückgeben lassen. (Diese Methode wird letztlich vom Parser benutzt.)\nDie restlichen Dateien werden für den Parser und verschiedene Arten der Traversierung des AST generiert (vgl. AST-basierte Interpreter).\nBedeutung der Ausgabe Wenn man dem Hello-Lexer die Eingabe\nhello world \u003cEOF\u003e (das \u003cEOF\u003e wird durch die Tastenkombination STRG-D erreicht) gibt, dann lautet die Ausgabe\n$ grun Hello start -tokens hello world \u003cEOF\u003e [@0,0:4='hello',\u003c'hello'\u003e,1:0] [@1,6:10='world',\u003cGREETING\u003e,1:6] [@2,12:11='\u003cEOF\u003e',\u003cEOF\u003e,2:0] Die erkannten Token werden jeweils auf einer eigenen Zeile ausgegeben.\n@0: Das erste Token (fortlaufend nummeriert, beginnend mit 0) 0:4: Das Token umfasst die Zeichen 0 bis 4 im Eingabestrom ='hello': Das gefundene Lexem (Wert des Tokens) \u003c'hello'\u003e: Das Token (Name/Typ des Tokens) 1:0: Das Token wurde in Zeile 1 gefunden (Start der Nummerierung mit Zeile 1), und startet in dieser Zeile an Position 0 Entsprechend bekommt man mit\n$ grun Hello start -tokens hello world \u003cEOF\u003e [@0,0:4='hello',\u003c'hello'\u003e,1:0] [@1,8:12='world',\u003cGREETING\u003e,2:2] [@2,15:14='\u003cEOF\u003e',\u003cEOF\u003e,4:0] ANTLR-Grammatik für die Lexer-Generierung Start der Grammatik mit dem Namen \"XYZ\" mit\ngrammar XYZ; oder (nur Lexer)\nlexer grammar XYZ; Token und Lexer-Regeln starten mit großen Anfangsbuchstaben (Ausblick: Parser-Regeln starten mit kleinen Anfangsbuchstaben)\nFormat: TokenName : Alternative1 | ... | AlternativeN ;\nRekursive Lexer-Regeln sind erlaubt. Achtung: Es dürfen keine links-rekursiven Regeln genutzt werden, etwa wie ID : ID '*' ID ; ... (Eine genauere Definition und die Transformation in nicht-linksrekursive Regeln siehe CFG).\nAlle Literale werden in einfache Anführungszeichen eingeschlossen (es erfolgt keine Unterscheidung zwischen einzelnen Zeichen und Strings wie in anderen Sprachen)\nZeichenmengen: [a-z\\n] umfasst alle Zeichen von 'a' bis 'z' sowie '\\n'\n'a'..'z' ist identisch zu [a-z]\nSchlüsselwörter: Die folgenden Strings stellen reservierte Schlüsselwörter dar und dürfen nicht als Token, Regel oder Label genutzt werden:\nimport, fragment, lexer, parser, grammar, returns, locals, throws, catch, finally, mode, options, tokens Anmerkung: rule ist zwar kein Schlüsselwort, wird aber als Methodenname bei der Codegenerierung verwendet. =\u003e Wie ein Schlüsselwort behandeln!\n(vgl. github.com/antlr/antlr4/blob/master/doc/lexicon.md)\nGreedy und Non-greedy Lexer-Regeln Die regulären Ausdrücke (...)?, (...)* und (...)+ sind greedy und versuchen soviel Input wie möglich zu matchen.\nFalls dies nicht sinnvoll sein sollte, kann man mit einem weiteren ? das Verhalten auf non-greedy umschalten. Allerdings können non-greedy Regeln das Verhalten des Lexers u.U. schwer vorhersehbar machen!\nDie Empfehlung ist, non-greedy Lexer-Regeln nur sparsam einzusetzen (vgl. github.com/antlr/antlr4/blob/master/doc/wildcard.md).\nVerhalten des Lexers: 1. Längster Match Primäres Ziel: Erkennen der längsten Zeichenkette\nCHARS : [a-z]+ ; DIGITS : [0-9]+ ; FOO : [a-z]+ [0-9]+ ; Die Regel, die den längsten Match für die aktuelle Eingabesequenz produziert, \"gewinnt\".\nIm Beispiel würde ein \"foo42\" als FOO erkannt und nicht als CHARS DIGITS.\nVerhalten des Lexers: 2. Reihenfolge Reihenfolge in Grammatik definiert Priorität\nFOO : 'f' .*? 'r' ; BAR : 'foo' .*? 'bar' ; Falls mehr als eine Lexer-Regel die selbe Inputsequenz matcht, dann hat die in der Grammatik zuerst genannte Regel Priorität.\nIm Beispiel würden für die Eingabe \"foo42bar\" beide Regeln den selben längsten Match liefern - die Regel FOO ist in der Grammatik früher definiert und \"gewinnt\".\nVerhalten des Lexers: 3. Non-greedy Regeln Non-greedy Regeln versuchen so wenig Zeichen wie möglich zu matchen\nFOO : 'foo' .*? 'bar' ; BAR : 'bar' ; Hier würde ein \"foo42barbar\" zu FOO gefolgt von BAR erkannt werden.\nAchtung: Nach dem Abarbeiten einer non-greedy Sub-Regel in einer Lexer-Regel gilt \"first match wins\"\n.*? ('4' | '42')\n=\u003e Der Teil '42' auf der rechten Seite ist \"toter Code\" (wegen der non-greedy Sub-Regel .*?)!\nDie Eingabe \"x4\" würde korrekt erkannt, währende \"x42\" nur als \"x4\" erkannt wird und für die verbleibende \"2\" würde ein token recognition error geworfen.\n(vgl. github.com/antlr/antlr4/blob/master/doc/wildcard.md)\nAttribute und Aktionen grammar Demo; @header { import java.util.*; } @members { String s = \"\"; } start : TYPE ID '=' INT ';' ; TYPE : ('int' | 'float') {s = getText();} ; INT : [0-9]+ {System.out.println(s+\":\"+Integer.valueOf(getText()));}; ID : [a-z]+ {setText(String.valueOf(getText().charAt(0)));} ; WS : [ \\t\\n]+ -\u003e skip ; Attribute bei Token (Auswahl) Token haben Attribute, die man abfragen kann. Dies umfasst u.a. folgende Felder:\ntext: Das gefundene Lexem als String type: Der Token-Typ als Integer index: Das wievielte Token (als Integer) (vgl. github.com/antlr/antlr4/blob/master/doc/actions.md)\nZur Auswertung in den Lexer-Regeln muss man anders vorgehen als in Parser-Regeln: Nach der Erstellung eines Tokens kann man die zum Attribut gehörenden getX() und setX()-Methoden aufrufen, um die Werte abzufragen oder zu ändern.\nDies passiert im obigen Beispiel für das Attribut text: Abfrage mit getText(), Ändern/Setzen mit setText().\nDie Methodenaufrufe wirken sich immer auf das gerade erstellte Token aus.\nAchtung: Bei Aktionen in Parser-Regeln gelten andere Spielregeln!\nAktionen mit den Lexer-Regeln Aktionen für Lexer-Regeln sind Code-Blöcke in der Zielsprache, eingeschlossen in geschweifte Klammern. Die Code-Blöcke werden direkt in die generierten Lexer-Methoden kopiert.\nZusätzlich:\n@header: Package-Deklarationen und/oder Importe (wird vor der Klassendefinition eingefügt) @members: zusätzliche Attribute für die generierten Lexer- (und Parser-) Klassen. Mit @lexer::header bzw. @lexer::members werden diese Codeblöcke nur in den generierten Lexer eingefügt.\nAnmerkung: Lexer-Aktionen müssen am Ende der äußersten Alternative erscheinen. Wenn eine Lexer-Regel mehr als eine Alternative hat, müssen diese in runde Klammern eingeschlossen werden.\n(vgl. github.com/antlr/antlr4/blob/master/doc/grammars.md)\nWrap-Up Lexer mit ANTLR generieren: Lexer-Regeln werden mit Großbuchstaben geschrieben\nLängster Match gewinnt, Gleichstand: zuerst definierte Regel non greedy-Regeln: versuche so wenig Zeichen zu matchen wie möglich Aktionen beim Matchen",
    "description": "Lexer: Erzeugen eines Token-Stroms aus einem Zeichenstrom Aus dem Eingabe(-quell-)text\n/* demo */ a= [5 , 6] ; erstellt der Lexer (oder auch Scanner genannt) eine Sequenz von Token:\n\u003cID, \"a\"\u003e \u003cASSIGN\u003e \u003cLBRACK\u003e \u003cNUM, 5\u003e \u003cCOMMA\u003e \u003cNUM, 6\u003e \u003cRBRACK\u003e \u003cSEMICOL\u003e Input: Zeichenstrom (Eingabedatei o.ä.) Verarbeitung: Finden sinnvoller Sequenzen im Zeichenstrom (\"Lexeme\"), Einteilung in Kategorien und Erzeugen von Token (Paare: Typ/Name, Wert) Ausgabe: Tokenstrom Normalerweise werden für spätere Phasen unwichtige Elemente wie White-Space oder Kommentare entfernt.",
    "tags": [],
    "title": "Lexer mit ANTLR generieren",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/01-lexing/antlr-lexing.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Syntaktische Analyse",
    "content": "Hello World grammar Hello; start : stmt* ; stmt : ID '=' expr ';' | expr ';' ; expr : term ('+' term)* ; term : atom ('*' atom)* ; atom : ID | NUM ; ID : [a-z][a-zA-Z]* ; NUM : [0-9]+ ; WS : [ \\t\\n]+ -\u003e skip ; Konsole: Hello (grun, Parse-Tree) Starten des Parsers Grammatik übersetzen und Code generieren: antlr Hello.g4 Java-Code kompilieren: javac *.java Parser ausführen: grun Hello start -tree oder grun Hello start -gui (Grammatik \"Hello\", Startregel \"start\")\nAlternativ mit kleinem Java-Programm:\nimport org.antlr.v4.runtime.CharStreams; import org.antlr.v4.runtime.CommonTokenStream; import org.antlr.v4.runtime.tree.ParseTree; public class Main { public static void main(String[] args) throws Exception { HelloLexer lexer = new HelloLexer(CharStreams.fromStream(System.in)); CommonTokenStream tokens = new CommonTokenStream(lexer); HelloParser parser = new HelloParser(tokens); ParseTree tree = parser.start(); // Start-Regel System.out.println(tree.toStringTree(parser)); } } Startregeln start ist eine Parser-Regel =\u003e Eine Parser-Regel pro Grammatik wird benötigt, damit man den generierten Parser am Ende auch starten kann ... Alle Regeln mit kleinem Anfangsbuchstaben sind Parser-Regeln Alle Regeln mit großem Anfangsbuchstaben sind Lexer-Regeln Formen der Subregeln stmt : ID '=' expr ';' ; Um die Regel stmt anwenden zu können, müssen alle Elemente auf der rechten Seite der Regel erfüllt werden. Dabei müssen die Token wie ID, = und ; matchen und die Subregel expr muss erfüllt werden können. Beachten Sie das abschließende Semikolon am Ende einer ANTLR-Regel!\nstmt : ID '=' expr ';' | expr ';' ; Alternativen werden durch ein | getrennt. Hier muss genau eine Alternative erfüllt werden. Falls nötig, trennt man die Alternativen durch Einschließung in runden Klammern vom Rest der Regel ab: r : a (b | c) d ;.\nexpr : term ('+' term)* ; Der durch den * gekennzeichnete Teil kann beliebig oft vorkommen oder auch fehlen. Bei einem + müsste der Teil mind. einmal vorkommen und bei einem ? entsprechend einmal oder keinmal.\nAuch hier kann man die Operatoren durch ein zusätzliches ? auf non-greedy umschalten (analog zu den Lexer-Regeln).\n(vgl. github.com/antlr/antlr4/blob/master/doc/parser-rules.md)\nReihenfolge in Grammatik definiert Priorität Falls mehr als eine Parser-Regel die selbe Input-Sequenz matcht, löst ANTLR diese Mehrdeutigkeit auf, indem es die erste Alternative nimmt, die an der Entscheidung beteiligt ist.\nstart : stmt ; stmt : expr | ID ; expr : ID | NUM ; Bei der Eingabe \"foo\" würde die Alternative ID in der Regel expr \"gewinnen\", weil sie in der Grammatik vor der Alternative ID in der Regel stmt kommt und damit Vorrang hat.\nParse-Tree Betrachten wir erneut die obige Grammatik.\nDie Eingabe von \"a = 42;\" führt zu folgendem Parse-Tree:\nDiese Eingabe führt zur Erkennung der Token [ID, WS, =, WS, NUM, ;], wobei die WS-Token verworfen werden und der Parser den Tokenstream [ID, =, NUM, ;] erhält.\nDie Startregel hat auf der rechten Seite kein oder mehrere stmt-Regeln. Die stmt-Regel fordert auf der rechten Seite entweder die Token IDund = sowie die Regel expr gefolgt vom Token ;, oder die Regel expr gefolgt vom Token ;. In unserem Beispiel kann für das \"a\" das Token ID produziert werden, das \"=\" matcht ebenfalls. Die \"42\" wird erklärt, indem für expr ein term und dort ein atom aufgerufen wird. Für das atom muss entweder ein Token ID oder NUM als nächstes Token kommen - hier wird die \"42\" wird als Token NUM verarbeitet. Da die weiteren Regelteile in term und expr optional sind, haben wir damit ein expr erfüllt und das nachfolgende ;-Token schließt die erste Alternative der Regel stmt erfolgreich ab.\nIm entstehenden Parse-Tree sind diese Abläufe und grammatikalischen Strukturen direkt erkennbar. Jede erfolgreich durchlaufene Parserregel wird zu einem Knoten im Parse-Tree. Die Token werden als Terminale (Blätter) in den Baum eingehängt.\nAnmerkung: Der Parse-Tree ist das Ergebnis der Parsers-Phase im Compiler und dient damit als Input für die folgenden Compilerstufen. In der Regel benötigt man die oft recht komplexen Strukturen aber später nicht mehr und vereinfacht den Baum zu einem Abstract Syntax Tree (AST). Im Beispiel könnte man den Zweig stmt - expr - term - atom - 42 zu stmt - 42 vereinfachen.\nBetrachten wir nun die Eingabe foo = 2+3*4; bar = 3*4+2;. Diese führt zu folgendem Parse-Tree:\nWie man sehen kann, sind in der Grammatik die üblichen Vorrangregeln für die Operationen + und * berücksichtigt - die Multiplikation wird in beiden Fällen korrekt \"unter\" der Addition im Baum eingehängt.\nTo EOF not to EOF? Startregeln müssen nicht unbedingt den gesamten Input \"konsumieren\". Sie müssen per Default nur eine der Alternativen in der Startregel erfüllen.\nBetrachten wir noch einmal einen leicht modifizierten Ausschnitt aus der obigen Grammatik:\nstart : stmt ; Die Startregel wurde so geändert, dass sie nur noch genau ein Statement akzeptieren soll.\nIn diesem Fall würde die Startregel bei der Eingabe \"aa; bb;\" nur den ersten Teil \"aa;\" konsumieren (als Token ID) und das folgende \"bb;\" ignorieren. Das wäre in diesem Fall aber auch kein Fehler.\nWenn der gesamte Eingabestrom durch die Startregel erklärt werden soll, dann muss das vordefinierte Token EOF am Ende der Startregel eingesetzt werden:\nstart : stmt EOF; Hier würde die Eingabe \"aa; bb;\" zu einem Fehler führen, da nur der Teil \"aa;\" durch die Startregel abgedeckt ist (Token ID), und der Rest \"bb;\" zwar sogar ein gültiges Token wären (ebenfalls ID und ;), aber eben nicht mehr von der Startregel akzeptiert. Durch das EOF soll die Startregel aber den gesamten Input konsumieren und erklären, was hier nicht geht und entsprechend zum Fehler führt.\n(vgl. github.com/antlr/antlr4/blob/master/doc/parser-rules.md)\nExpressions und Vorrang (Operatoren) Betrachten wir noch einmal den Ausschnitt für die Ausdrücke (Expressions) in der obigen Beispielgrammatik:\nexpr : term ('+' term)* ; term : atom ('*' atom)* ; atom : ID ; Diese typische, etwas komplex anmutende Struktur soll sicher stellen, dass die Vorrangregeln für Addition und Multiplikation korrekt beachtet werden, d.h. dass 2+3*4 als 2+(3*4) geparst wird und nicht fälschlicherweise als (2+3)*4 erkannt wird.\nZusätzlich muss bei LL-Parsern Links-Rekursion vermieden werden: Die Parser-Regeln werden in Funktionsaufrufe übersetzt, d.h. bei einer Links-Rekursion würde man die selbe Regel immer wieder aufrufen, ohne ein Token aus dem Token-Strom zu entnehmen.\nANTLR (ab Version 4) kann mit beiden Aspekten automatisch umgehen:\nANTLR kann direkte Linksrekursion automatisch auflösen. Die Regel r : r T U | V ; kann also in ANTLR verarbeitet werden. ANTLR besitzt einen Mechanismus zur Auflösung von Mehrdeutigkeiten. Wie oben geschrieben, wird bei der Anwendbarkeit von mehreren Alternativen die erste Alternative genutzt. Damit lässt sich die typische Struktur für Expression-Grammatiken deutlich lesbarer gestalten:\nexpr : expr '*' expr | expr '+' expr | ID ; Die Regel expr ist links-rekursiv, was normalerweise bei LL-Parsern problematisch ist. ANTLR löst diese Links-Rekursion automatisch auf (vgl. github.com/antlr/antlr4/blob/master/doc/left-recursion.md).\nDa bei Mehrdeutigkeit in der Grammatik, also bei der Anwendbarkeit mehrerer Alternativen stets die erste Alternative genommen wird, lassen sich die Vorrangregeln durch die Reihenfolge der Alternativen in der expr-Regel implementieren: Die Multiplikation hat Vorrang von der Addition, und diese hat wiederum Vorrang von einer einfachen ID.\nDirekte vs. indirekte Links-Rekursion ANTLR kann nur direkte Links-Rekursion auflösen. Regeln wie r : r T U | V ; stellen in ANTLR also kein Problem dar.\nIndirekte Links-Rekursion erkennt ANTLR dagegen nicht:\nr : s T U | V ; s : r W X ; Hier würden sich die Regeln r und s gegenseitig aufrufen und kein Token aus dem Tokenstrom entfernen, so dass der generierte LL-Parser hier in einer Endlosschleife stecken bleiben würde. Mit indirekter Links-Rekursion kann ANTLR nicht umgehen.\nKonflikte in Regeln Wenn mehrere Alternativen einer Regel anwendbar sind, entscheidet sich ANTLR für die erste Alternative.\nWenn sich mehrere Tokenregeln überlappen, \"gewinnt\" auch hier die zuerst definierte Regel.\ndef : 'func' ID '(' ')' block ; FOR : 'for' ; ID : [a-z][a-zA-Z]* ; Hier werden ein implizites Token 'func' sowie die expliziten Token FOR und ID definiert. Dabei sind die Lexeme für 'func' und FOR auch in ID enthalten. Dennoch werden 'func' und FOR erkannt und nicht über ID gematcht, weil sie vor der Regel ID definiert sind.\nTatsächlich sortiert ANTLR die Regeln intern um, so dass alle Parser-Regeln vor den Lexer-Regeln definiert sind. Die impliziten Token werden dabei noch vor den expliziten Token-Regeln angeordnet. Im obigen Beispiel hat also 'func' eine höhere Priorität als FOR, und FOR hat eine höhere Priorität als ID. Aus diesem Grund gibt es die Konvention, die Parser-Regeln in der Grammatik vor den Lexer-Regeln zu definieren - dies entspricht quasi der Anordnung, die ANTLR bei der Verarbeitung sowieso erzeugen würde.\nAus diesem Grund würde auch eine Umsortierung der obigen Grammatik funktionieren:\nFOR : 'for' ; ID : [a-z][a-zA-Z]* ; def : 'func' ID '(' ')' block ; Intern würde ANTLR die Parser-Regel def wieder vor den beiden Lexer-Regeln anordnen, und zwischen den Parser-Regeln und den Lexer-Regeln die impliziten Token (hier 'func').\nKontext-Objekte für Parser-Regeln s : expr {List\u003cEContext\u003e x = $expr.ctx.e();} ; expr : e '*' e ; Jede Regel liefert ein passend zu dieser Regel generiertes Kontext-Objekt zurück. Darüber kann man das/die Kontextobjekt(e) der Sub-Regeln abfragen.\nDie Regel s liefert entsprechend ein SContext-Objekt und die Regel expr liefert ein ExprContext-Objekt zurück.\nIn der Aktion fragt man das Kontextobjekt über ctx ab, in den Listener- und Visitor-Methoden erhält man die Kontextobjekte als Parameter.\nFür einfache Regel-Aufrufe liefert die parameterlose Methode nur ein einziges Kontextobjekt (statt einer Liste) zurück.\nAnmerkung: ANTLR generiert nur dann Felder für die Regel-Elemente im Kontextobjekt, wenn diese in irgendeiner Form referenziert werden. Dies kann beispielsweise durch Benennung (Definition eines Labels, siehe nächste Folie) oder durch Nutzung in einer Aktion (siehe obiges Beispiel) geschehen.\nBenannte Regel-Elemente oder Alternativen stat : 'return' value=e ';' # Return | 'break' ';' # Break ; public static class StatContext extends ParserRuleContext { ... } public static class ReturnContext extends StatContext { public EContext value; public EContext e() { ... } } public static class BreakContext extends StatContext { ... } Mit value=e wird der Aufruf der Regel e mit dem Label value belegt, d.h. man kann mit $e.text oder $value.text auf das text-Attribut von e zugreifen. Falls es in einer Produktion mehrere Aufrufe einer anderen Regel gibt, muss man für den Zugriff auf die Attribute eindeutige Label vergeben.\nAnalog wird für die beiden Alternativen je ein eigener Kontext erzeugt.\nArbeiten mit ANTLR-Listeners ANTLR (generiert auf Wunsch) zur Grammatik passende Listener (Interface und leere Basisimplementierung). Beim Traversieren mit dem Default-ParseTreeWalker wird der Parse-Tree mit Tiefensuche abgelaufen und jeweils beim Eintritt in bzw. beim Austritt aus einen/m Knoten der passende Listener mit dem passenden Kontext-Objekt aufgerufen.\nDamit kann man die Grammatik \"für sich\" halten, d.h. unabhängig von einer konkreten Zielsprache und die Aktionen über die Listener (oder Visitors, s.u.) ausführen.\nexpr : e1=expr '*' e2=expr # MULT | e1=expr '+' e2=expr # ADD | DIGIT # ZAHL ; ANTLR kann zu dieser Grammatik calc.g4 einen passenden Listener (Interface calcListener) generieren (Option -listener beim Aufruf von antlr). Weiterhin generiert ANTLR eine leere Basisimplementierung (Klasse calcBaseListener):\n(Nur \"interessante\" Methoden gezeigt.)\nVon dieser Basisklasse leitet man einen eigenen Listener ab und implementiert die Methoden, die man benötigt.\npublic static class MyListener extends calcBaseListener { public void exitMULT(calcParser.MULTContext ctx) { ... } public void exitADD(calcParser.ADDContext ctx) { ... } public void exitZAHL(calcParser.ZAHLContext ctx) { ... } } Anschließend baut man das alles in eine Traversierung des Parse-Trees ein:\npublic class TestMyListener { public static class MyListener extends calcBaseListener { ... } public static void main(String[] args) throws Exception { calcLexer lexer = new calcLexer(CharStreams.fromStream(System.in)); CommonTokenStream tokens = new CommonTokenStream(lexer); calcParser parser = new calcParser(tokens); ParseTree tree = parser.s(); // Start-Regel ParseTreeWalker walker = new ParseTreeWalker(); MyListener eval = new MyListener(); walker.walk(eval, tree); } } Beispiel: TestMyListener.java und calc.g4 Arbeiten mit dem Visitor-Pattern ANTLR (generiert ebenfalls auf Wunsch) zur Grammatik passende Visitoren (Interface und leere Basisimplementierung).\nHier muss man im Gegensatz zu den Listeners allerdings selbst für eine geeignete Traversierung des Parse-Trees sorgen. Dafür hat man mehr Freiheiten im Vergleich zum Einsatz von Listeners, insbesondere im Hinblick auf Rückgabewerte.\nexpr : e1=expr '*' e2=expr # MULT | e1=expr '+' e2=expr # ADD | DIGIT # ZAHL ; ANTLR kann zu dieser Grammatik einen passenden Visitor (Interface calcVisitor\u003cT\u003e) generieren (Option -visitor beim Aufruf von antlr). Weiterhin generiert ANTLR eine leere Basisimplementierung (Klasse calcBaseVisitor\u003cT\u003e):\n(Nur \"interessante\" Methoden gezeigt.)\nVon dieser Basisklasse leitet man einen eigenen Visitor ab und überschreibt die Methoden, die man benötigt. Wichtig ist, dass man selbst für das \"Besuchen\" der Kindknoten sorgen muss (rekursiver Aufruf der geerbten Methode visit()).\npublic static class MyVisitor extends calcBaseVisitor\u003cInteger\u003e { public Integer visitMULT(calcParser.MULTContext ctx) { return ... } public Integer visitADD(calcParser.ADDContext ctx) { return ... } public Integer visitZAHL(calcParser.ZAHLContext ctx) { return ... } } Anschließend baut man das alles in eine manuelle Traversierung des Parse-Trees ein:\npublic class TestMyVisitor { public static class MyVisitor extends calcBaseVisitor\u003cInteger\u003e { ... } public static void main(String[] args) throws Exception { calcLexer lexer = new calcLexer(CharStreams.fromStream(System.in)); CommonTokenStream tokens = new CommonTokenStream(lexer); calcParser parser = new calcParser(tokens); ParseTree tree = parser.s(); // Start-Regel MyVisitor eval = new MyVisitor(); eval.visit(tree); } } Beispiel: TestMyVisitor.java und calc.g4 Eingebettete Aktionen und Attribute s : expr {System.err.println($expr.v);} ; expr returns [int v] : e1=expr '*' e2=expr {$v = $e1.v * $e2.v;} ; Auch die Parser-Regeln können mit eingebetteten Aktionen ergänzt werden, die in die (für die jeweilige Regel) generierte Methode eingefügt werden und bei erfolgreicher Anwendung der Parser-Regel ausgeführt werden.\nÜber returns [int v] fügt man der Regel expr ein Attribut v (Integer) hinzu, welches man im jeweiligen Kontext abfragen bzw. setzen kann (agiert als Rückgabewert der generierten Methode). Auf diesen Wert kann in den Aktionen mit $v zugegriffen werden.\nAnmerkung: Durch den Einsatz von eingebetteten Aktionen und Attributen wird die Grammatik abhängig von der Zielsprache des generierten Lexers/Parsers!\nAusblick Damit haben wir die sprichwörtliche \"Spitze des Eisbergs\" gesehen. Mit ANTLR sind noch viele weitere Dinge möglich. Bitte nutzen Sie aktiv die Dokumentation auf github.com/antlr/antlr4.\nWrap-Up Parser mit ANTLR generieren: Parser-Regeln werden mit Kleinbuchstaben geschrieben\nRegeln können Lexer- und Parser-Regeln \"aufrufen\" Regeln können Alternativen haben Bei Mehrdeutigkeit: Vorrang für erste Alternative ANTLR erlaubt direkte Links-Rekursion ANTLR erzeugt Parse-Tree Benannte Alternativen und Regel-Elemente Traversierung des Parse-Tree: Listener oder Visitoren, Zugriff auf Kontextobjekte",
    "description": "Hello World grammar Hello; start : stmt* ; stmt : ID '=' expr ';' | expr ';' ; expr : term ('+' term)* ; term : atom ('*' atom)* ; atom : ID | NUM ; ID : [a-z][a-zA-Z]* ; NUM : [0-9]+ ; WS : [ \\t\\n]+ -\u003e skip ; Konsole: Hello (grun, Parse-Tree) Starten des Parsers Grammatik übersetzen und Code generieren: antlr Hello.g4 Java-Code kompilieren: javac *.java Parser ausführen: grun Hello start -tree oder grun Hello start -gui (Grammatik \"Hello\", Startregel \"start\")",
    "tags": [],
    "title": "Parser mit ANTLR generieren",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/02-parsing/antlr-parsing.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Praktikum",
    "content": "A2.1: PDA (2P) Erstellen Sie einen deterministischen PDA, der die Sprache\n$$L = \\lbrace w \\in \\lbrace a, b, c \\rbrace^* \\; | \\; w \\; \\text{hat doppelt so viele a's wie c's} \\rbrace$$ akzeptiert.\nBeschreiben Sie Schritt für Schritt, wie der PDA die Eingaben bcaba und bccac abarbeitet.\nA2.2: Akzeptierte Sprache (1P) Ist der folgenden PDA deterministisch? Warum (nicht)?\n$q_4$ sei der akzeptierende Zustand.\n$$\\begin{eqnarray} \\delta(q_0,a, \\perp) \u0026=\u0026 (q_0, A\\perp) \\nonumber \\\\ \\delta(q_0,a, A) \u0026=\u0026 (q_0, AA) \\nonumber \\\\ \\delta(q_0,b, A) \u0026=\u0026 (q_1, BA) \\nonumber \\\\ \\delta(q_1,b, B) \u0026=\u0026 (q_1, BB) \\nonumber \\\\ \\delta(q_1,c, B) \u0026=\u0026 (q_2, \\epsilon) \\nonumber \\\\ \\delta(q_2,c, B) \u0026=\u0026 (q_2, \\epsilon) \\nonumber \\\\ \\delta(q_2,d, A) \u0026=\u0026 (q_3, \\epsilon) \\nonumber \\\\ \\delta(q_3,d, A) \u0026=\u0026 (q_3, \\epsilon) \\nonumber \\\\ \\delta(q_3,d, A) \u0026=\u0026 (q_3, AA) \\nonumber \\\\ \\delta(q_3,\\epsilon, \\perp) \u0026=\u0026 (q_4, \\epsilon) \\nonumber \\end{eqnarray}$$ Zeichnen Sie den Automaten. Geben Sie das 7-Tupel des PDa an. Welche Sprache akzeptiert er?\nA2.3: Kontextfreie Sprache (1P) Welche Sprache generiert die folgende kontextfreie (Teil-) Grammatik?\n$$G = (\\lbrace \\text{Statement}, \\text{Condition}, \\ldots \\rbrace, \\lbrace \\text{\"if\"}, \\text{\"else\"}, \\ldots \\rbrace, P, \\text{Statement})$$ mit\n$$\\begin{eqnarray} P = \\lbrace \u0026\u0026 \\nonumber \\\\ \u0026\\text{Statement}\u0026 \\rightarrow \\text{\"if\" Condition Statement} \\; | \\; \\text{\"if\" Condition Statement \"else\" Statement} \\nonumber \\\\ \u0026\\text{Condition}\u0026 \\rightarrow \\ldots \\nonumber \\\\ \\rbrace \\nonumber \\end{eqnarray}$$ Ist die Grammatik mehrdeutig? Warum (nicht)?\nA2.4: Kontextfreie Grammatik (2P) Entwickeln Sie eine kontextfreie Grammatik für die Sprache\n$$L = \\lbrace a^ib^jc^k \\; | \\; i = j \\lor j = k \\rbrace$$ Zeigen Sie, dass die Grammatik mehrdeutig ist. Entwickeln Sie einen PDA für diese Sprache.\nA2.5: Kontextfreie Grammatik (4P) Betrachten sie die folgende Grammatik:\n$$G = (\\lbrace S, A \\rbrace, \\lbrace 1, 2, 3 \\rbrace, P, S)$$ mit\n$$\\begin{eqnarray} P = \\lbrace \u0026\u0026 \\nonumber \\\\ \u0026S\u0026 \\rightarrow 1AS \\; | \\; 3 \\nonumber \\\\ \u0026A\u0026 \\rightarrow 2AS \\; | \\; \\epsilon \\nonumber \\\\ \\rbrace \\nonumber \\end{eqnarray}$$ Berechnen die die First- und Follow-Mengen der Grammatik.\nZeigen Sie, dass die Grammatik LL(1) ist.\nKonstruieren Sie die LL-Parsertabelle für die Grammatik und simulieren Sie das Parsen des Wortes 1233.",
    "description": "A2.1: PDA (2P) Erstellen Sie einen deterministischen PDA, der die Sprache\n$$L = \\lbrace w \\in \\lbrace a, b, c \\rbrace^* \\; | \\; w \\; \\text{hat doppelt so viele a's wie c's} \\rbrace$$ akzeptiert.\nBeschreiben Sie Schritt für Schritt, wie der PDA die Eingaben bcaba und bccac abarbeitet.\nA2.2: Akzeptierte Sprache (1P) Ist der folgenden PDA deterministisch? Warum (nicht)?\n$q_4$ sei der akzeptierende Zustand.\n$$\\begin{eqnarray} \\delta(q_0,a, \\perp) \u0026=\u0026 (q_0, A\\perp) \\nonumber \\\\ \\delta(q_0,a, A) \u0026=\u0026 (q_0, AA) \\nonumber \\\\ \\delta(q_0,b, A) \u0026=\u0026 (q_1, BA) \\nonumber \\\\ \\delta(q_1,b, B) \u0026=\u0026 (q_1, BB) \\nonumber \\\\ \\delta(q_1,c, B) \u0026=\u0026 (q_2, \\epsilon) \\nonumber \\\\ \\delta(q_2,c, B) \u0026=\u0026 (q_2, \\epsilon) \\nonumber \\\\ \\delta(q_2,d, A) \u0026=\u0026 (q_3, \\epsilon) \\nonumber \\\\ \\delta(q_3,d, A) \u0026=\u0026 (q_3, \\epsilon) \\nonumber \\\\ \\delta(q_3,d, A) \u0026=\u0026 (q_3, AA) \\nonumber \\\\ \\delta(q_3,\\epsilon, \\perp) \u0026=\u0026 (q_4, \\epsilon) \\nonumber \\end{eqnarray}$$ Zeichnen Sie den Automaten. Geben Sie das 7-Tupel des PDa an. Welche Sprache akzeptiert er?",
    "tags": [],
    "title": "Blatt 02: CFG",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/homework/sheet02.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25)",
    "content": "Auf die lexikalische Analyse und die Syntaxanalyse folgt die semantische Analyse. Nach dem Parsen steht fest, dass ein Programm syntaktisch korrekt ist. Nun muss geprüft werden, ob es auch semantisch korrekt ist. Dazu gehören u.a. die Identifikation und Sammlung von Bezeichnern und die Zuordnung zur richtigen Ebene (Scopes) sowie die die Typ-Prüfung und -Inferenz.\nIn dieser Phase zeigen sich die Eigenschaften der zu verarbeitenden Sprache sehr deutlich, beispielsweise müssen Bezeichner deklariert sein vor der ersten Benutzung, welche Art von Scopes soll es geben, gibt es Klassen und Vererbung ...\nDa hier der Kontext der Symbole eine Rolle spielt, wird diese Phase oft auch \"Context Handling\" oder \"Kontext Analyse\" bezeichnet. Neben attributierten Grammatiken sind die Symboltabellen wichtige Werkzeuge.\nSymbTab0: Überblick Symboltabellen SymbTab1: Nested Scopes SymbTab2: Funktionen SymbTab3: Strukturen und Klassen",
    "description": "Auf die lexikalische Analyse und die Syntaxanalyse folgt die semantische Analyse. Nach dem Parsen steht fest, dass ein Programm syntaktisch korrekt ist. Nun muss geprüft werden, ob es auch semantisch korrekt ist. Dazu gehören u.a. die Identifikation und Sammlung von Bezeichnern und die Zuordnung zur richtigen Ebene (Scopes) sowie die die Typ-Prüfung und -Inferenz.\nIn dieser Phase zeigen sich die Eigenschaften der zu verarbeitenden Sprache sehr deutlich, beispielsweise müssen Bezeichner deklariert sein vor der ersten Benutzung, welche Art von Scopes soll es geben, gibt es Klassen und Vererbung ...",
    "tags": [],
    "title": "Semantische Analyse",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/03-semantics.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Semantische Analyse",
    "content": "Was passiert nach der Syntaxanalyse? int x = 42; int f(int x) { int y = 9; return y+x; } x = f(x); Nach der Syntaxanalyse braucht der Compiler für die darauf folgenden Phasen semantische Analyse, Optimierung und Codegenerierung Informationen über Bezeichner, z.B.\nWelcher Bezeichner ist gemeint? Welchen Typ hat ein Bezeichner? Auf dem Weg zum Interpreter/Compiler müssen die Symbole im AST korrekt zugeordnet werden. Dies geschieht über Symboltabellen. Im Folgenden werden wir verschiedene Aspekte von Symboltabellen betrachten und eine mögliche Implementierung erarbeiten, bevor wir uns um die Auswertung (Interpretation) des AST kümmern können.\nLogische Compilierungsphasen Die lexikalische Analyse generiert eine Folge von Token.\nDie Syntaxanalyse generiert einen Parse Tree.\nDie semantische Analyse macht folgendes:\nDer Parse Tree wird in einen abstrakten Syntaxbaum (AST) umgewandelt. Dieser wird häufig mit Attributen annotiert. Dabei sind oft mehrere Baumdurchläufe nötig (z.B. wegen der Abhängigkeiten der Attribute). Nachfolgende Stufen:\nDer AST wird in einen Zwischencode umgewandelt mit Registern und virtuellen Adressen. Der Zwischencode wird optimiert. Aus dem optimierten Zwischencode wird der endgültige Code, aber immer noch mit virtuellen Adressen, generiert. Der generierte Code wird nachoptimiert. Der Linker ersetzt die virtuellen Adressen durch reale Adressen. Abgrenzung der Phasen Diese Phasen sind oft nicht klar unterscheidbar. Schon allein zur Verbesserung der Laufzeit baut der Parser oft schon den abstrakten Syntaxbaum auf, der Lexer trägt schon Bezeichner in Symboltabellen ein, der Parser berechnet beim Baumaufbau schon Attribute, ...\nOft werden gar nicht alle Phasen und alle Zwischendarstellungen benötigt.\nSemantische Analyse und Symboltabellen Syntax und Semantik Syntaxregeln: Formaler Aufbau eines Programms\nSemantik: Bedeutung eines (syntaktisch korrekten) Programms\n=\u003e Keine Codegenerierung für syntaktisch/semantisch inkorrekte Programme!\nZur Erinnerung: Die Syntaxregeln einer Programmiersprache bestimmen den formalen Aufbau eines zu übersetzenden Programms. Die Semantik gibt die Bedeutung eines syntaktisch richtigen Programms an.\nLexikalische und syntaktische Analyse können formalisiert mit regulären Ausdrücken und endlichen Automaten, sowie mit CFG und Parsern durchgeführt werden.\nDie Durchführung der semantischen Analyse ist stark von den Eigenschaften der zu übersetzenden Sprache, sowie der Zielsprache abhängig und kann hier nur beispielhaft für einige Eigenschaften erklärt werden.\nEs darf kein lauffähiges Programm erstellt werden können, dass nicht syntaktisch und semantisch korrekt ist. Ein lauffähiges Programm muss syntaktisch und semantisch korrekt sein!\nAufgaben der semantischen Analyse Identifikation und Sammlung der Bezeichner\nZuordnung zur richtigen Ebene (Scopes)\nTyp-Inferenz\nTypkonsistenz (Ausdrücke, Funktionsaufrufe, ...)\nValidieren der Nutzung von Symbolen\nVermeidung von Mehrfachdefinition Zugriff auf nicht definierte Bezeichner (Lesender) Zugriff auf nicht initialisierte Bezeichner Funktionen werden nicht als Variablen genutzt ... Die semantische Analyse überprüft die Gültigkeit eines syntaktisch korrekten Programms bzgl. statischer semantischer Eigenschaften und liefert die Grundlage für die (Zwischen-) Codeerzeugung und -optimierung. Insbesondere wird hier die Typkonsistenz (in Ausdrücken, von Parametern, ...) überprüft, und implizite Typumwandlungen werden vorgenommen. Oft müssen Typen automatisch bestimmt werden (z.B. bei Polymorphie, Typinferenz). Damit Typen bestimmt oder angepasst werden können, müssen Bezeichner zunächst identifiziert werden, d.h. bei namensgleichen Bezeichnern der richtige Bezug bestimmt werden.\n=\u003e Ein wichtiges Hilfsmittel dazu sind Symboltabellen\nIdentifizierung von Objekten Beim Compiliervorgang müssen Namen immer wieder den dazugehörigen Definitionen zugeordnet, ihre Eigenschaften gesammelt und geprüft und darauf zugegriffen werden. Symboltabellen werden im Compiler fast überall gebraucht (siehe Abbildung unter \"Einordnung\").\nWelche Informationen zu einem Bezeichner gespeichert und ermittelt werden, ist dann abhängig von der Klasse des Bezeichners.\nValidieren der Nutzung von Symbolen Hier sind unendlich viele Möglichkeiten denkbar. Dies reicht von den unten aufgeführten Basisprüfungen bis hin zum Prüfen der Typkompatibilität bei arithmetischen Operationen. Dabei müssen für alle Ausdrücke die Ergebnistypen berechnet werden und ggf. automatische Konvertierungen vorgenommen werden, etwa bei 3+4.1 ...\nZugriff auf Variablen: Müssen sichtbar sein Zugriff auf Funktionen: Vorwärtsreferenzen sind OK Variablen werden nicht als Funktionen genutzt Funktionen werden nicht als Variablen genutzt Da Funktionen bereits vor dem Bekanntmachen der Definition aufgerufen werden dürfen, bietet sich ein zweimaliger Durchlauf (pass) an: Beim ersten Traversieren des AST werden alle Definitionen in der Symboltabelle gesammelt. Beim zweiten Durchlauf werden dann die Referenzen aufgelöst.\nDas Mittel der Wahl: Tabellen für die Symbole (= Bezeichner) Def.: Symboltabellen sind die zentrale Datenstruktur zur Identifizierung und Verwaltung von bezeichneten Elementen.\nDie Organisation der Symboltabellen ist stark anwendungsabhängig. Je nach Sprachkonzept gibt es eine oder mehrere Symboltabellen, deren Einträge vom Lexer oder Parser angelegt werden. Die jeweiligen Inhalte jedes einzelnen Eintrags kommen aus den verschiedenen Phasen der Compilierung. Symboltabellen werden oft als Hashtables oder auch als Bäume implementiert, manchmal als verkettete Listen. In seltenen Fällen kommt man auch mit einem Stack aus.\nEine Symboltabelle enthält benutzerdefinierte Bezeichner (oder Verweise in eine Hashtable mit allen vorkommenden Namen), manchmal auch die Schlüsselwörter der Programmiersprache. Die einzelnen Felder eines Eintrags variieren stark, abhängig vom Typ des Bezeichners (= Bezeichnerklasse).\nManchmal gibt es für Datentypen eine Extra-Tabelle, ebenso eine für die Werte von Konstanten.\nManchmal werden die Namen selbst in eine (Hash-) Tabelle geschrieben. Die Symboltabelle enthält dann statt der Namen Verweise in diese (Hash-) Tabelle.\nEinfache Verwaltung von Variablen primitiven Typs int x = 0; int i = 0; for (i=0; i\u003c10; i++) { x++; } Bsp.: Die zu übersetzende Sprache hat nur einen (den globalen) Scope und kennt nur Bezeichner für Variablen.\nEine Symboltabelle für alle Bezeichner Jeder Bezeichner ist der Name einer Variablen Symboltabelle wird evtl. mit Einträgen aller Schlüsselwörter initialisiert -- warum? Scanner erkennt Bezeichner und sucht ihn in der Symboltabelle Ist der Bezeichner nicht vorhanden, wird ein (bis auf den Namen leerer) Eintrag angelegt Scanner übergibt dem Parser das erkannte Token und einen Verweis auf den Symboltabelleneintrag Die Symboltabelle könnte hier eine (Hash-) Tabelle oder eine einfache verkettete Liste sein.\nWas kann jetzt weiter passieren? int x = 0; int i = 0; for (i=0; i\u003c10; i++) { x++; } a = 42; In vielen Sprachen muss überprüft werden, ob es ein definierendes Vorkommen des Bezeichners oder ein angewandtes Vorkommen ist.\nDefinitionen und Deklarationen von Bezeichnern Def.: Die Definition eines (bisher nicht existenten) Bezeichners in einem Programm generiert einen neuen Bezeichner und legt für ihn seinem Typ entsprechend Speicherplatz an.\nDef.: Unter der Deklaration eines (bereits existierenden) Bezeichners verstehen wir seine Bekanntmachung, damit er benutzt werden kann. Er ist oft in einem anderen Scope definiert und bekommt dort Speicherplatz zugeteilt.\nInsbesondere werden auch Typen deklariert. Hier gibt es in der Regel gar keine Speicherplatzzuweisung.\nEin Bezeichner kann beliebig oft deklariert werden, während er in einem Programm nur einmal definiert werden kann. Oft wird bei der Deklarationen eines Elements sein Namensraum mit angegeben.\nVorsicht: Die Begriffe werden auch anders verwendet. Z.B. findet sich in der Java-Literatur der Begriff Deklaration anstelle von Definition.\nAnmerkung: Deklarationen beziehen sich auf Definitionen, die woanders in einer Symboltabelle stehen, evtl. in einer anderen Datei, also in diesem Compilerlauf nicht zugänglich sind und erst von Linker aufgelöst werden können. Beim Auftreten einer Deklaration muss die dazugehörige Definition gesucht werden,und wenn vorhanden, im Symboltabelleneintrag für den deklarierten Bezeichner festgehalten werden. Hier ist evtl. ein zweiter Baumdurchlauf nötig, um alle offenen Deklarationen, die sich auf Definitionen in derselben Datei beziehen, aufzulösen.\nWird bei objektorientierten Sprachen ein Objekt definiert, dessen Klassendefinition in einer anderen Datei liegt, kann man die Definition des Objekts gleichzeitig als Deklaration der Klasse auffassen (Java).\nWo werden Verweise in Symboltabellen gebraucht? =\u003e Parse Tree und AST enthalten Verweise auf Symboltabelleneinträge\nIm Parse Tree enthält der Knoten für einen Bezeichner einen Verweis auf den Symboltabelleneintrag. Parser und semantische Analyse (AST) vervollständigen die Einträge. Attribute des AST können Feldern der Symboltabelle entsprechen, bzw. sich aus ihnen berechnen. Für Debugging-Zwecke können die Symboltabellen die ganze Compilierung und das Linken überleben. Grenzen der semantischen Analyse Welche semantischen Eigenschaften einer Sprache kann die semantische Analyse nicht überprüfen?\nWer ist dann dafür verantwortlich? Wie äußert sich das im Fehlerfall? Dinge, die erst durch eine Ausführung/Interpretation eines Programms berechnet werden können.\nBeispielsweise können Werte von Ausdrücken oft erst zur Laufzeit bestimmt werden. Insbesondere kann die semantische Analyse in der Regel nicht feststellen, ob ein Null-Pointer übergeben wird und anschließend dereferenziert wird.\nWrap-Up Semantische Analyse:\nIdentifikation und Sammlung der Bezeichner Zuordnung zur richtigen Ebene (Scopes) Validieren der Nutzung von Symbolen Typ-Inferenz Typkonsistenz (Ausdrücke, Funktionsaufrufe, ...) Symboltabellen: Verwaltung von Symbolen und Typen (Informationen über Bezeichner)\nSymboltabelleneinträge werden an verschiedenen Stellen des Compilers generiert und benutzt",
    "description": "Was passiert nach der Syntaxanalyse? int x = 42; int f(int x) { int y = 9; return y+x; } x = f(x); Nach der Syntaxanalyse braucht der Compiler für die darauf folgenden Phasen semantische Analyse, Optimierung und Codegenerierung Informationen über Bezeichner, z.B.\nWelcher Bezeichner ist gemeint? Welchen Typ hat ein Bezeichner? Auf dem Weg zum Interpreter/Compiler müssen die Symbole im AST korrekt zugeordnet werden. Dies geschieht über Symboltabellen. Im Folgenden werden wir verschiedene Aspekte von Symboltabellen betrachten und eine mögliche Implementierung erarbeiten, bevor wir uns um die Auswertung (Interpretation) des AST kümmern können.",
    "tags": [],
    "title": "SymbTab0: Überblick Symboltabellen",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/03-semantics/symbtab0-intro.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Semantische Analyse",
    "content": "Scopes und Name Spaces Def.: Unter dem Gültigkeitsbereich (Sichtbarkeitsbereich, Scope) eines Bezeichners versteht man den Programmabschnitt, in dem der Bezeichner sichtbar und nutzbar ist. Das ist oft der kleinste umgebende Block, außer darin enthaltene Scopes, die ein eigenes Element dieses Namens benutzen.\nScopes sind fast immer hierarchisch angeordnet.\nDef.: Unter einem Namensraum (name space) versteht man die Menge der zu einem Zeitpunkt sichtbaren Bezeichner.\nEs gibt Sprachen, in denen man eigene Namensräume explizit definieren kann (z.B. C++).\nVorsicht: Diese Begriffe werden nicht immer gleich definiert und auch gerne verwechselt.\nSymbole und (nested) Scopes int x = 42; float y; { int x; x = 1; y = 2; { int y = x; } } Aufgaben:\nbind(): Symbole im Scope definieren resolve(): Symbole aus Scope oder Eltern-Scope abrufen Hinzunahme von Scopes Bsp.: Die zu übersetzende Sprache ist scope-basiert und kennt nur Bezeichner für Variablen\nScopes können ineinander verschachtelt sein. Die Spezifikation der zu übersetzenden Sprache legt fest, in welcher Reihenfolge Scopes zu durchsuchen sind, wenn auf einen Bezeichner Bezug genommen wird, der nicht im aktuellen Scope definiert ist.\nInsgesamt bilden die Scopes oft eine Baumstruktur, wobei jeder Knoten einen Scope repräsentiert und seine Kinder die direkt in ihm enthaltenen Scopes sind. Dabei ist es in der Regel so, dass Scopes sich entweder vollständig überlappen oder gar nicht. Wenn ein Bezeichner nicht im aktuellen Scope vorhanden ist, muss er in der Regel in umschließenden Scopes gesucht werden. Hier kann ein Stack aller \"offenen\" Scopes benutzt werden.\nGrundlegendes Vorgehen Das Element, das einen neuen Scope definiert, steht selbst in dem aktuell behandelten Scope. Wenn dieses Element selbst ein Bezeichner ist, gehört dieser in den aktuellen Scope. Nur das, was nur innerhalb des oben genannten Elements oder Bezeichners definiert wird, gehört in den Scope des Elements oder Bezeichners.\nNested Scopes: Symbole und Scopes Implementierung mit hierarchischen (verketteten) Tabellen Pro Scope wird eine Symboltabelle angelegt, dabei enthält jede Symboltabelle zusätzlich einen Verweis auf ihre Vorgängersymboltabelle für den umgebenden Scope. Die globale Symboltabelle wird typischerweise mit allen Schlüsselwörtern initialisiert.\nWenn ein neuer Scope betreten wird, wird eine neue Symboltabelle erzeugt. Scanner: Erkennt Bezeichner und sucht ihn in der Symboltabelle des aktuellen Scopes bzw. trägt ihn dort ein und übergibt dem Parser das erkannte Token und einen Verweis auf den Symboltabelleneintrag (Erinnerung: Der Scanner wird i.d.R. vom Parser aus aufgerufen, d.h. der Parser setzt den aktuellen Scope!) Parser: Wird ein neues Element (ein Bezeichner) definiert, muss bestimmt werden, ob es einen eigenen Scope hat. Wenn ja, wird eine neue Symboltabelle für den Scope angelegt. Sie enthält alle Definitionen von Elementen, die in diesem Scope liegen. Der Bezeichner selbst wird in die aktuelle Symboltabelle eingetragen mit einem Verweis auf die neue Tabelle, die all die Bezeichner beinhaltet, die außerhalb dieses Scopes nicht sichtbar sein sollen. Die Tabellen werden untereinander verzeigert. Wird ein Element deklariert oder benutzt, muss sein Eintrag in allen sichtbaren Scopes in der richtigen Reihenfolge entlang der Verzeigerung gesucht (und je nach Sprachdefinition auch gefunden) werden. Der Parse-Tree enthält im Knoten für den Bezeichner den Verweis in die Symboltabelle Klassenhierarchie für Scopes Für die Scopes wird eine Klasse Scope definiert mit den Methoden bind() (zum Definieren von Symbolen im Scope) und resolve() (zum Abrufen von Symbolen aus dem Scope oder dem umgebenden Scope).\nFür lokale Scopes wird eine Instanz dieser Klasse angelegt, die eine Referenz auf den einschließenden Scope im Attribut enclosingScope hält. Für den globalen Scope ist diese Referenz einfach leer (None).\nKlassen und Interfaces für Symbole Für die Symbole gibt es die Klasse Symbol, wo für jedes Symbol Name und Typ gespeichert wird. Variablensymbole leiten direkt von dieser Klasse ab. Für die eingebauten Typen wird ein \"Marker-Interface\" Type erstellt, um Variablen- und Typ-Symbole unterscheiden zu können.\nQuelle: Eigene Modellierung nach einer Idee in [Parr2010, p. 142]\nAlternative Implementierung über einen Stack Der Parse Tree bzw. der AST enthalten an den Knoten, die jeweils einen ganzen Scope repräsentieren, einen Verweis auf die Symboltabelle dieses Scopes. Die Scopes werden in einem Stack verwaltet. Wird ein Scope betreten beim Baumdurchlauf, wird ein Verweis auf seine Symboltabelle auf den Stack gepackt. Die Suche von Bezeichnern in umliegenden Scopes erfordert ein Durchsuchen des Stacks von oben nach unten. Beim Verlassen eines Scopes beim Baumdurchlauf wird der Scope vom Stack entfernt. Nested Scopes: Definieren und Auflösen von Namen class Scope: Scope enclosingScope # None if global (outermost) scope Symbol\u003cString, Symbol\u003e symbols def resolve(name): # do we know \"name\" here? if symbols[name]: return symbols[name] # if not here, check any enclosing scope if enclosingScope: return enclosingScope.resolve(name) else: return None # not found def bind(symbol): symbols[symbol.name] = symbol symbol.scope = self # track the scope in each symbol Quelle: Eigene Implementierung nach einer Idee in [Parr2010, p. 169]\nAnmerkung: In der Klasse Symbol kann man ein Feld scope vom Typ Scope implementieren. Damit \"weiss\" jedes Symbol, in welchem Scope es definiert ist und man muss sich auf der Suche nach dem Scope eines Symbols ggf. nicht erst durch die Baumstruktur hangeln. Aus technischer Sicht verhindert das Attribut das Aufräumen eines lokalen Scopes durch den Garbage Collector, wenn man den lokalen Scope wieder verlässt: Jeder Scope hat eine Referenz auf den umgebenden (Eltern-) Scope (Feld enclosingScope). Wenn man den aktuellen Scope \"nach oben\" verlässt, würde der eben verlassene lokale Scope bei nächster Gelegenheit aufgeräumt, wenn es keine weiteren Referenzen auf diesen gäbe. Da nun aber die Symbole, die in diesem Scope definiert wurden, auf diesen verweisen, passiert das nicht :)\nNested Scopes: Listener Mit einem passenden Listener kann man damit die nötigen Scopes aufbauen:\nenterStart: erzeuge neuen globalen Scope definiere und pushe die eingebauten Typen exitVarDecl: löse den Typ der Variablen im aktuellen Scope auf definiere ein neues Variablensymbol im aktuellen Scope exitVar: löse die Variable im aktuellen Scope auf enterBlock: erzeuge neuen lokalen Scope, wobei der aktuelle Scope der Elternscope ist ersetze den aktuellen Scope durch den lokalen Scope exitBlock: ersetze den aktuellen Scope durch dessen Elternscope start : stat+ ; stat : block | varDecl | expr ';' ; block : '{' stat* '}' ; varDecl : type ID ('=' expr)? ';' ; expr : var '=' INT ; var : ID ; type : 'float' | 'int' ; Relevanter Ausschnitt aus der Grammatik\nint x = 42; { int y = 9; x = 7; } class MyListener(BaseListener): Scope scope def enterStart(Parser.FileContext ctx): globals = Scope() globals.bind(BuiltIn(\"int\")) globals.bind(BuiltIn(\"float\")) scope = globals def enterBlock(Parser.BlockContext ctx): scope = Scope(scope) def exitBlock(Parser.BlockContext ctx): scope = scope.enclosingScope def exitVarDecl(Parser.VarDeclContext ctx): t = scope.resolve(ctx.type().getText()) var = Variable(ctx.ID().getText(), t) scope.bind(var) def exitVar(Parser.VarContext ctx): name = ctx.ID().getText() var = scope.resolve(name) if var == None: error(\"no such var: \" + name) Anmerkung: Um den Code auf die Folie zu bekommen, ist dies ein Mix aus Java und Python geworden. Sry ;)\nIn der Methode exitVar() wird das Variablensymbol beim Ablaufen des AST lediglich aufgelöst und ein Fehler geworfen, wenn das Variablensymbol (noch) nicht bekannt ist. Hier könnte man weiteres Type-Checking und/oder -Propagation ansetzen.\nSpäter im Interpreter muss an dieser Stelle dann aber auch der Wert der Variablen abgerufen werden ...\nLöschen von Symboltabellen Möglicherweise sind die Symboltabellen nach der Identifizierungsphase der Elemente überflüssig, weil die zusammengetragenen Informationen als Attribute im AST stehen. Die Knoten enthalten dann Verweise auf definierende Knoten von Elementen, nicht mehr auf Einträge in den Symboltabellen. In diesem Fall können die Symboltabellen nach der Identifizierung gelöscht werden, wenn sie nicht z.B. für einen symbolischen Debugger noch gebraucht werden.\nWrap-Up Symboltabellen: Verwaltung von Symbolen und Typen (Informationen über Bezeichner)\nBlöcke: Nested Scopes =\u003e hierarchische Organisation\nBinden von Bezeichner gleichen Namens an ihren jeweiligen Scope =\u003e bind()\nAbrufen von Bezeichnern aus dem aktuellen Scope oder den Elternscopes =\u003e resolve()",
    "description": "Scopes und Name Spaces Def.: Unter dem Gültigkeitsbereich (Sichtbarkeitsbereich, Scope) eines Bezeichners versteht man den Programmabschnitt, in dem der Bezeichner sichtbar und nutzbar ist. Das ist oft der kleinste umgebende Block, außer darin enthaltene Scopes, die ein eigenes Element dieses Namens benutzen.\nScopes sind fast immer hierarchisch angeordnet.\nDef.: Unter einem Namensraum (name space) versteht man die Menge der zu einem Zeitpunkt sichtbaren Bezeichner.\nEs gibt Sprachen, in denen man eigene Namensräume explizit definieren kann (z.B. C++).",
    "tags": [],
    "title": "SymbTab1: Nested Scopes",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/03-semantics/symbtab1-scopes.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Semantische Analyse",
    "content": "Funktionen und Scopes int x = 42; int y; void f() { int x; x = 1; y = 2; { int y = x; } } void g(int z){} Behandlung von Funktionsdefinitionen Jeder Symboltabelleneintrag braucht ein Feld, das angibt, ob es sich um eine Variable, eine Funktion, ... handelt. Alternativ eine eigene Klasse ableiten ... Der Name der Funktion steht als Bezeichner in der Symboltabelle des Scopes, in dem die Funktion definiert wird. Der Symboltabelleneintrag für den Funktionsnamen enthält Verweise auf die Parameter. Der Symboltabelleneintrag für den Funktionsnamen enthält Angaben über den Rückgabetypen. Jede Funktion wird grundsätzlich wie ein neuer Scope behandelt. Die formalen Parameter werden als Einträge in der Symboltabelle für den Scope der Funktion angelegt and entsprechend als Parameter gekennzeichnet. Behandlung von Funktionsaufrufen Der Name der Funktion steht als Bezeichner in der Symboltabelle des Scopes, in dem die Funktion aufgerufen wird und wird als Aufruf gekennzeichnet. Der Symboltabelleneintrag für den Funktionsnamen enthält Verweise auf die aktuellen Parameter. Die Definition der Funktion wird in den zugänglichen Scopes gesucht (wie oben) und ein Verweis darauf in der Symboltabelle gespeichert. Erweiterung des Klassendiagramms für Funktions-Scopes Quelle: Eigene Modellierung nach einer Idee in [Parr2010, p. 147]\nFunktionen sind Symbole und Scopes class Function(Scope, Symbol): def __init__(name, retType, enclScope): Symbol.__init__(name, retType) # we are \"Symbol\" ... enclosingScope = enclScope # ... and \"Scope\" Funktionen: Listener Den Listener zum Aufbau der Scopes könnte man entsprechend erweitern:\nenterFuncDecl: löse den Typ der Funktion im aktuellen Scope auf lege neues Funktionssymbol an, wobei der aktuelle Scope der Elternscope ist definiere das Funktionssymbol im aktuellen Scope ersetze den aktuellen Scope durch das Funktionssymbol exitFuncDecl: ersetze den aktuellen Scope durch dessen Elternscope exitParam: analog zu exitVarDecl löse den Typ der Variablen im aktuellen Scope auf definiere ein neues Variablensymbol im aktuellen Scope exitCall: analog zu exitVar löse das Funktionssymbol (und die Argumente) im aktuellen Scope auf funcDecl : type ID '(' params? ')' block ; params : param (',' param)* ; param : type ID ; call : ID '(' exprList? ')' ; exprList : expr (',' expr)* ; Relevanter Ausschnitt aus der Grammatik\nint f(int x) { int y = 9; } int x = f(x); def enterFuncDecl(Parser.FuncDeclContext ctx): name = ctx.ID().getText() type = scope.resolve(ctx.type().getText()) func = Function(name, type, scope) scope.bind(func) # change current scope to function scope scope = func def exitFuncDecl(Parser.FuncDeclContext ctx): scope = scope.enclosingScope def exitParam(Parser.ParamContext ctx): t = scope.resolve(ctx.type().getText()) var = Variable(ctx.ID().getText(), t) scope.bind(var) def exitCall(Parser.CallContext ctx): name = ctx.ID().getText() func = scope.resolve(name) if func == None: error(\"no such function: \" + name) if func.type == Variable: error(name + \" is not a function\") Anmerkung: Um den Code auf die Folie zu bekommen, ist dies wieder ein Mix aus Java und Python geworden. Sry ;)\nIm Vergleich zu den einfachen nested scopes kommt hier nur ein weiterer Scope für den Funktionskopf dazu. Dieser spielt eine Doppelrolle: Er ist sowohl ein Symbol (welches im Elternscope bekannt ist) als auch ein eigener (lokaler) Scope für die Funktionsparameter.\nUm später im Interpreter eine Funktion tatsächlich auswerten zu können, muss im Scope der Funktion zusätzlich der AST-Knoten der Funktionsdefinition gespeichert werden (weiteres Feld/Attribut in Function)!\nWrap-Up Symboltabellen: Verwaltung von Symbolen und Typen (Informationen über Bezeichner)\nFunktionen: Nested Scopes =\u003e hierarchische Organisation\nUmgang mit dem Funktionsnamen, den Parametern und dem Funktionskörper",
    "description": "Funktionen und Scopes int x = 42; int y; void f() { int x; x = 1; y = 2; { int y = x; } } void g(int z){} Behandlung von Funktionsdefinitionen Jeder Symboltabelleneintrag braucht ein Feld, das angibt, ob es sich um eine Variable, eine Funktion, ... handelt. Alternativ eine eigene Klasse ableiten ... Der Name der Funktion steht als Bezeichner in der Symboltabelle des Scopes, in dem die Funktion definiert wird. Der Symboltabelleneintrag für den Funktionsnamen enthält Verweise auf die Parameter. Der Symboltabelleneintrag für den Funktionsnamen enthält Angaben über den Rückgabetypen. Jede Funktion wird grundsätzlich wie ein neuer Scope behandelt. Die formalen Parameter werden als Einträge in der Symboltabelle für den Scope der Funktion angelegt and entsprechend als Parameter gekennzeichnet. Behandlung von Funktionsaufrufen Der Name der Funktion steht als Bezeichner in der Symboltabelle des Scopes, in dem die Funktion aufgerufen wird und wird als Aufruf gekennzeichnet. Der Symboltabelleneintrag für den Funktionsnamen enthält Verweise auf die aktuellen Parameter. Die Definition der Funktion wird in den zugänglichen Scopes gesucht (wie oben) und ein Verweis darauf in der Symboltabelle gespeichert. Erweiterung des Klassendiagramms für Funktions-Scopes",
    "tags": [],
    "title": "SymbTab2: Funktionen",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/03-semantics/symbtab2-functions.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Semantische Analyse",
    "content": "Strukturen struct A { int x; struct B {int x;}; B b; struct C {int z;}; }; A a; void f() { A a; a.b.x = 42; } Strukturen: Erweiterung der Symbole und Scopes Quelle: Eigene Modellierung nach einer Idee in [Parr2010, p. 162]\nStrukturen stellen wie Funktionen sowohl einen Scope als auch ein Symbol dar.\nZusätzlich stellt eine Struktur (-definition) aber auch einen neuen Typ dar, weshalb Struct auch noch das Interface Type \"implementiert\".\nStrukturen: Auflösen von Namen class Struct(Scope, Symbol, Type): def resolveMember(name): return symbols[name] =\u003e Auflösen von \"a.b\" (im Listener in exitMember()):\na im \"normalen\" Modus mit resolve() über den aktuellen Scope Typ von a ist Struct mit Verweis auf den eigenen Scope b nur innerhalb des Struct-Scopes mit resolveMember() In der Grammatik würde es eine Regel member geben, die auf eine Struktur der Art ID.ID anspricht (d.h. eigentlich den Teil .ID), und entsprechend zu Methoden enterMember() und exitMember() im Listener führt.\nDas Symbol für a hat als type-Attribut eine Referenz auf die Struct, die ja einen eigenen Scope hat (symbols-Map). Darin muss dann b aufgelöst werden.\nKlassen class A { public: int x; void foo() { ; } }; class B : public A { public int y; void foo() { int z = x+y; } }; Klassen: Erweiterung der Symbole und Scopes Quelle: Eigene Modellierung nach einer Idee in [Parr2010, p. 167]\nBei Klassen kommt in den Tabellen ein weiterer Pointer parentClazz auf die Elternklasse hinzu (in der Superklasse ist der Wert None).\nKlassen: Auflösen von Namen class Clazz(Struct): Clazz parentClazz # None if base class def resolve(name): # do we know \"name\" here? if symbols[name]: return symbols[name] # NEW: if not here, check any parent class ... if parentClazz and parentClazz.resolve(name): return parentClazz.resolve(name) else: # ... or enclosing scope if base class if enclosingScope: return enclosingScope.resolve(name) else: return None # not found def resolveMember(name): if symbols[name]: return symbols[name] # NEW: check parent class if parentClazz: return parentClazz.resolveMember(name) else: return None Quelle: Eigene Implementierung nach einer Idee in [Parr2010, p. 172]\nHinweis: Die obige Implementierungsskizze soll vor allem das Prinzip demonstrieren - sie ist aus Gründen der Lesbarkeit nicht besonders effizient: beispielsweise wird parentClazz.resolve(name) mehrfach evaluiert ...\nBeim Auflösen von Attributen oder Methoden muss zunächst in der Klasse selbst gesucht werden, anschließend in der Elternklasse.\nBeispiel (mit den obigen Klassen A und B):\nB foo; foo.x = 42; Hier wird analog zu den Structs zuerst foo mit resolve() im lokalen Scope aufgelöst. Der Typ des Symbols foo ist ein Clazz, was zugleich ein Scope ist. In diesem Scope wird nun mit resolveMember() nach dem Symbol x gesucht. Falls es hier nicht gefunden werden kann, wird in der Elternklasse (sofern vorhanden) weiter mitresolveMember() gesucht.\nDie normale Namensauflösung wird ebenfalls erweitert um die Auflösung in der Elternklasse.\nBeispiel:\nint wuppie; class A { public: int x; void foo() { ; } }; class B : public A { public int y; void foo() { int z = x+y+wuppie; } }; Hier würde wuppie als Symbol im globalen Scope definiert werden. Beim Verarbeiten von int z = x+y+wuppie; würde mit resolve() nach wuppie gesucht: Zuerst im lokalen Scope unterhalb der Funktion, dann im Funktions-Scope, dann im Klassen-Scope von B. Hier sucht resolve() auch zunächst lokal, geht dann aber die Vererbungshierarchie entlang (sofern wie hier vorhanden). Erst in der Superklasse (wenn der parentClazz-Zeiger None ist), löst resolve() wieder normal auf und sucht um umgebenden Scope. Auf diese Weise kann man wie gezeigt in Klassen (Methoden) auf globale Variablen verweisen ...\nAnmerkung: Durch dieses Vorgehen wird im Prinzip in Methoden aus dem Zugriff auf ein Feld x implizit ein this.x aufgelöst, wobei this die Klasse auflöst und x als Attribut darin.\nWrap-Up Symboltabellen: Verwaltung von Symbolen und Typen (Informationen über Bezeichner)\nStrukturen und Klassen bilden eigenen Scope\nStrukturen/Klassen lösen etwas anders auf: Zugriff auf Attribute und Methoden",
    "description": "Strukturen struct A { int x; struct B {int x;}; B b; struct C {int z;}; }; A a; void f() { A a; a.b.x = 42; } Strukturen: Erweiterung der Symbole und Scopes Quelle: Eigene Modellierung nach einer Idee in [Parr2010, p. 162]",
    "tags": [],
    "title": "SymbTab3: Strukturen und Klassen",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/03-semantics/symbtab3-classes.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Praktikum",
    "content": "Zusammenfassung Ziel dieses Aufgabenblattes ist die Erstellung eines einfachen Pretty Printers für eine einfache fiktive Sprache mit Expressions und Kontrollstrukturen.\nDazu werden Sie eine passende kontextfreie Grammatik definieren mit Lexer- und Parser-Regeln und dabei auch übliche Vorrangregeln beachten.\nFür diese Grammatik erstellen Sie mit Hilfe von ANTLR einen Lexer und einen Parser, die zu einem Eingabeprogramm einen Parse-Tree erzeugen.\nDen im Parse-Tree repräsentierten Code des Eingabeprogramms können Sie mit Hilfe einer Traversierung konsistent eingerückt wieder auf der Standardausgabe ausgeben - das ist der Pretty Printer.\nSie werden merken, dass viele Strukturen im Parse-Tree für diese Aufgabe nicht relevant sind und den Baum mit einer weiteren Traversierung in einen vereinfachten Baum, den sogenannten Abstract-Syntex-Tree (AST), transformieren und diesen erneut als formatierten Code auf der Konsole ausgeben.\nMethodik Nutzen Sie das Starter-Projekt in der Vorgabe.\nLaden Sie sich das Projekt herunter, binden Sie es in Ihre IDE ein und vergewissern Sie sich, dass alles funktioniert: Führen Sie das enthaltene Programm aus, ändern Sie die mitgelieferten Beispielgrammatik.\nBauen Sie dann Ihre Grammatik für die Aufgabe schrittweise auf. Testen Sie diese mit Hilfe der Beispielprogramme der Zielsprache (s.u.) und überlegen Sie sich selbst weitere Code-Schnipsel, die Sie mit Ihrem Parser einlesen bzw. die Ihr Parser zurückweisen sollte.1 Es empfiehlt sich, in dieser Phase mit dem ANTLR-Plugin für IntelliJ zu arbeiten.\nErkunden Sie dann die Strukturen Ihres Parse-Trees. Diese sind an die Regeln Ihrer Grammatik gekoppelt und sind deshalb so individuell wie Ihre Grammatik. Mit einer Traversierung des Baumes können Sie die gewünschte Ausgabe programmieren und auch die Erstellung des vereinfachten Baumes (AST).\nSprachdefinition Ein Programm besteht aus einer oder mehreren Anweisungen (Statements).\nAnweisungen (Statements) Eine Anweisung ist eine einzeilige Befehlsfolge, beispielsweise eine Zuweisung oder eine Operation. Sie muss immer mit einem Newline abgeschlossen werden. Eine Anweisung hat keinen Wert.\na := 10 - 5 # Zuweisung des Ausdruckes 10-5 (Integer-Wert 5) an die Variable a b := \"foo\" # Zuweisung des Ausdrucks \"foo\" (String) an die Variable b Kontrollstrukturen (s.u.) zählen ebenfalls als Anweisungen.\nAusdrücke (Expressions) Die einfachsten Ausdrücke sind Integer- oder String-Literale. Variablen sind ebenfalls Ausdrücke. Komplexere Ausdrücke werden mit Hilfe von Operationen gebildet, dabei sind die Operanden jeweils auch wieder Ausdrücke. Ein Ausdruck hat/ergibt immer einen Wert.\nDie Operatoren besitzen eine Rangfolge, um verschachtelte Operationen aufzulösen. Sie dürfen daher nicht einfach von links nach rechts aufgelöst werden. Die Rangfolge der Operatoren entspricht der üblichen Semantik (vgl. Java, C, Python).\nEs gibt in unserer Sprache folgende Operationen mit der üblichen Semantik:\nVergleichsoperatoren Operation Operator Gleichheit == Ungleichheit != Größer \u003e Kleiner \u003c Arithmetische Operatoren Operation Operator Addition / String-Literal-Verkettung + Subtraktion - Multiplikation * Division / Beispiele für Ausdrücke 10 - 5 # Der Integer-Wert 5 \"foo\" # Der String \"foo\" a # Wert der Variablen a a + b # Ergebnis der Addition der Variablen a und b Bezeichner Werden zur Bezeichnung von Variablen verwendet. Sie bestehen aus einer Zeichenkette der Zeichen a-z,A-Z, 0-9, _. Bezeichner dürfen nicht mit einer Ziffer 0-9 beginnen.\nVariablen Variablen bestehen aus einem eindeutigen Bezeichner (Variablennamen). Den Variablen können Werte zugewiesen werden und Variablen können als Werte verwendet werden. Die Zuweisung erfolgt mithilfe des :=-Operators. Auf der rechten Seite der Zuweisung können auch Ausdrücke stehen.\na := 5 # Zuweisung des Wertes 5 an die Variable a a := 2 + 3 # Zuweisung des Wertes 5 an die Variable a Kommentare Kommentare werden durch das Zeichen # eingeleitet und umfassen sämtliche Zeichen bis zum nächsten Newline.\nKontrollstrukturen While-Schleife While-Schleifen werden mit dem Schlüsselwort while eingeleitet. Sie bestehen im Weiteren aus einer Bedingung, die durch ein do abgeschlossen wird, einer Folge von Anweisungen und werden mit dem Schlüsselwort end abgeschlossen.\nDie Bedingung kann aus einem Vergleichsausdruck bestehen.\nwhile \u003cBedingung\u003e do \u003cAnweisung_1\u003e \u003cAnweisung_2\u003e end a := 10 b := 0 while a \u003e= 0 do a := a - 1 b := b + 9 end Bedingte Anweisung (If-Else) Eine bedingte Anweisung besteht immer aus genau einer if-Anweisung, gefolgt von einer Bedingung, die mit einem do abgeschlossen wird und einer Folge von Anweisungen.\nDanach wird die bedingte Anweisung entweder mit dem Schlüsselwort end abgeschlossen oder es folgt genau ein else-Teil.\nEin else-Teil wird mit dem Schlüsselwort else eingeleitet. Darauf folgt ein do und eine Folge von Anweisungen. Der else-Teil wird mit dem Schlüsselwort end abgeschlossen.\nif \u003cBedingung\u003e do \u003cAnweisung_1\u003e \u003cAnweisung_2\u003e end if \u003cBedingung\u003e do \u003cAnweisung\u003e else do \u003cAnweisung\u003e end a := \"abc\" if a \u003c \"abc\" do a := \"wuppie\" else do a := \"nope\" end Datentypen Unsere Sprache hat zwei eingebaute Datentypen, für die entsprechende Literale erkannt werden müssen:\nDatentyp Definition der Literale int eine beliebige Folge der Ziffern 0-9 string eine beliebige Folge von ASCII-Zeichen, eingeschlossen in \" Die Sprache ist dynamisch typisiert, d.h. beim Parsen werden Ihnen keine Typ-Angaben im Code begegnen. Aber Sie müssen die entsprechenden Werte (Literale) parsen können.\nBeispiele a := \"wuppie fluppie\" a := 0 if 10 \u003c 1 do a := 42 else do a := 7 end Aufgaben A3.1: Grammatik (4P) Definieren Sie für die obige Sprache eine geeignete ANTLR-Grammatik.\nSie werden sowohl Lexer- als auch (rekursive) Parser-Regeln benötigen. Beachten Sie die üblichen Vorrangregeln für die Operatoren, orientieren Sie sich hier an Sprachen wie Java oder Python oder C.\nA3.2: Pretty Printer (3P) Erzeugen Sie mithilfe der Grammatik und ANTLR einen Lexer und Parser. Damit können Sie syntaktisch korrekte Eingabe-Programme in einen Parse-Tree überführen.\nProgrammieren Sie eine Traversierung Ihres Parse-Trees, in der Sie syntaktisch korrekte Programme konsistent eingerückt ausgeben können.\nJede Anweisung soll auf einer eigenen Zeile stehen. Die Einrückung soll mit Leerzeichen erfolgen und konsistent sein. Sie brauchen keine Begrenzung der Zeilenlänge implementieren.\nDemonstrieren Sie die Fähigkeiten an mehreren Beispielen mit unterschiedlicher Komplexität.\nBeispiel:\nAus\na := 0 if 10 \u003c 1 do a := 42 # Zuweisung des Wertes 42 an die Variable a else do a := 7 end soll\na := 0 if 10 \u003c 1 do a := 42 else do a := 7 end werden.\nHinweis: Es geht nur um die Ausgabe syntaktisch korrekter Programme. Sie brauchen sich um die Semantik (z.B. passende Typen wie etwa keine Multiplikation von Strings mit Integern o.ä.) noch keine Gedanken machen! Achten Sie auf die korrekten Einrücktiefen. Die Zeilenlänge spielt hier keine Rolle, es wird einfach direkt nach jedem Statement umgebrochen (bzw. wie bei den Kontrollstrukturen gezeigt).\nHinweis: Das Thema Pretty Printing ist interessant und kann recht schnell ziemlich aufwändig werden. Sie finden im Paper \"A prettier printer\" von Philip Wadler [wadler2003prettier] und im Blog \"The Hardest Program I've Ever Written\" von Bob Nystrom [Nystrom2015] gut geschriebene Beiträge, um tiefer in die Materie einzusteigen.\nA3.3: AST (3P) Beim Parsen bekommen Sie von ANTLR einen Parse-Tree zurück, der direkt die Struktur Ihrer Grammatik widerspiegelt. Die einzelnen Zweige sind damit in der Regel aber auch viel zu tief verschachtelt.\nÜberlegen Sie sich, welche Informationen/Knoten Sie für die formatierte Ausgabe wirklich benötigen - das ist Ihr Abstract-Syntex-Tree (AST).\nProgrammieren Sie eine Transformation des Parse-Tree in die von Ihnen hier formulierten AST-Strukturen. Dies können Sie beispielsweise mit einer passenden Traversierung (Visitor-Pattern) erreichen.\nPassen Sie den Pretty-Printer so an, dass er auch den AST ausgeben kann. (Alternativ können auch einen zweiten Pretty-Printer für den AST implementieren.)\nUm den Text lesbar zu halten, wird hier oft nur von \"Parser\" gesprochen - gemeint ist aber die gesamte auf diesem Blatt zu erstellende Toolchain: Lexer - Parser - AST - Ausgabe. ↩︎",
    "description": "Zusammenfassung Ziel dieses Aufgabenblattes ist die Erstellung eines einfachen Pretty Printers für eine einfache fiktive Sprache mit Expressions und Kontrollstrukturen.\nDazu werden Sie eine passende kontextfreie Grammatik definieren mit Lexer- und Parser-Regeln und dabei auch übliche Vorrangregeln beachten.\nFür diese Grammatik erstellen Sie mit Hilfe von ANTLR einen Lexer und einen Parser, die zu einem Eingabeprogramm einen Parse-Tree erzeugen.\nDen im Parse-Tree repräsentierten Code des Eingabeprogramms können Sie mit Hilfe einer Traversierung konsistent eingerückt wieder auf der Standardausgabe ausgeben - das ist der Pretty Printer.",
    "tags": [],
    "title": "Blatt 03: ANTLR",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/homework/sheet03.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Praktikum",
    "content": "Zusammenfassung Ziel dieses Aufgabenblattes ist die Erstellung einer Symboltabelle und eines einfachen Type-Checkers für eine fiktive statisch typisierte Sprache mit Expressions, Kontrollstrukturen und Funktionen.\nMethodik Sie finden im Sample Project eine Grammatik, die (teilweise) zu der Zielsprache auf diesem Blatt passt. Analysieren Sie diese Grammatik und vervollständigen Sie diese bzw. passen Sie diese an.\nErstellen Sie mit dieser Grammatik und ANTLR wieder einen Lexer und Parser. Definieren Sie einen AST und konvertieren Sie Ihren Parse-Tree in einen AST.\nEs ist empfehlenswert, den Type-Checker dreiphasig zu realisieren:\nAufbauen der Symboltabelle und Prüfen von z.B. Deklaration/Definition vs. Benutzung (Variablen) usw. Prüfen bei Funktionsaufrufen auf vorhandene/sichtbare Funktionsdefinitionen Prüfen der verwendeten Typen Sprachdefinition Ein Programm besteht aus einer oder mehreren Anweisungen (Statements).\nAnweisungen (Statements) Eine Anweisung ist eine Befehlsfolge, beispielsweise eine Deklaration (Funktionen), Definition (Variablen, Funktionen), Zuweisung, ein Funktionsaufruf oder eine Operation. Sie muss immer mit einem Semikolon abgeschlossen werden. Eine Anweisung hat keinen Wert.\nint a; # Definition der Integer-Variablen a int b = 10 - 5; # Definition der Integer-Variablen b und Zuweisung des Ausdruckes 10-5 (Integer-Wert 5) c = \"foo\"; # Zuweisung des Ausdrucks \"foo\" (String) an die Variable c (diese muss dazu vorher definiert und sichtbar sein) func1(a, c); # Funktionsaufruf mit Variablen a und c Kontrollstrukturen und Code-Blöcke sowie return-Statements zählen ebenfalls als Anweisung.\nCode-Blöcke und Scopes Code-Blöcke werden in geschweifte Klammern eingeschlossen und enthalten eine beliebige Anzahl von Anweisungen.\nJeder Code-Block bildet einen eigenen Scope - alle Deklarationen/Definition in diesem Scope sind im äußeren Scope nicht sichtbar. Im Scope kann auf die Symbole des/der umgebenden Scopes zugegriffen werden. Symbole in einem Scope können gleichnamige Symbole im äußeren Scope verdecken.\n# globaler Scope int a = 7; int d; { # erster innerer Scope int b = 7; # b ist nur in diesem und im zweiten inneren Scope sichtbar foo(a); # Funktionsaufruf mit der Variable a aus dem äußeren Scope (Wert 7) int a = 42; # Variable verdeckt das a aus dem äußeren Scope foo(a); # Funktionsaufruf mit der Variable a aus dem aktuellen Scope (Wert 42) { # zweiter innerer Scope int c = 9; # dieses c ist nur hier sichtbar foo(d); # d wird im äußeren Scope gesucht, dort nicht gefunden und im nächsthöheren Scope gesucht (rekursiv) } } { # dritter innerer Scope int b; # dieses b hat mit dem b aus dem ersten inneren Scope nichts zu tun foo(a); # Funktionsaufruf mit der Variable a aus dem äußeren Scope (Wert 7) } Ausdrücke (Expressions) Die einfachsten Ausdrücke sind Integer- oder String-Literale. Variablen und Funktionsaufrufe sind ebenfalls Ausdrücke. Komplexere Ausdrücke werden mit Hilfe von Operationen gebildet, dabei sind die Operanden jeweils auch wieder Ausdrücke.\nEin Ausdruck hat immer einen Wert und einen Typ.\nDie Operatoren besitzen eine Rangfolge, um verschachtelte Operationen aufzulösen. Sie dürfen daher nicht einfach von links nach rechts aufgelöst werden. Die Rangfolge der Operatoren entspricht der üblichen Semantik (vgl. Java, C, Python).\nEs gibt in unserer Sprache folgende Operationen mit der üblichen Semantik:\nVergleichsoperatoren Operation Operator Gleichheit == Ungleichheit != Größer \u003e Kleiner \u003c Die Operanden müssen jeweils beide den selben Typ haben. Dabei sind string und int zulässig. Das Ergebnis ist immer vom Typ bool.\nArithmetische Operatoren Operation Operator Addition / String-Literal-Verkettung + Subtraktion - Multiplikation * Division / Die Operanden müssen jeweils beide den selben Typ haben. Für + sind string und int zulässig, für die anderen Operatoren (-, *, /) nur int. Das Ergebnis ist vom Typ der Operanden.\nBeispiele für Ausdrücke 10 - 5 # Der Integer-Wert 5 \"foo\" # Der String \"foo\" a # Wert der Variablen a (Zugriff auf a) a + b # Ergebnis der Addition der Variablen a und b func1(a, b) # Ergebnis des Funktionsaufrufs Ausdrücke werden nicht mit einem Semikolon abgeschlossen. Sie sind also Teil einer Anweisung.\nBezeichner Werden zur Bezeichnung von Variablen und Funktionsnamen verwendet. Sie bestehen aus einer Zeichenkette der Zeichen a-z,A-Z, 0-9. Bezeichner dürfen nicht mit einer Ziffer 0-9 beginnen.\nVariablen Variablen bestehen aus einem eindeutigen Bezeichner (Variablennamen). Den Variablen können Werte zugewiesen werden und Variablen können als Werte verwendet werden. Die Zuweisung erfolgt mithilfe des =-Operators. Auf der rechten Seite der Zuweisung können auch Ausdrücke stehen.\nint a; # Definition der Variablen a (Typ: Integer) int a = 7; # Definition und Initialisierung einer Variablen a = 5; # Zuweisung des Wertes 5 an die Variable a a = 2 + 3; # Zuweisung des Wertes 5 an die Variable a Variablen müssen vor ihrer Benutzung (Zugriff, Zuweisung) definiert und im aktuellen Scope sichtbar sein. Die Initialisierung kann zusammen mit der Definition erfolgen.\nVariablen können in einem Scope nicht mehrfach definiert werden.\nint a = 42; { a = 7; # zulässig - a ist hier sichtbar, Zugriff auf globalen Scope b = 9; # unzulässig - b ist nicht definiert int a; # zulässig - erste Definition in diesem Scope int a; # unzulässig - a ist in diesem Scope bereits definiert } Kommentare Kommentare werden durch das Zeichen # eingeleitet und umfassen sämtliche Zeichen bis zum nächsten Newline.\nKontrollstrukturen While-Schleife While-Schleifen werden mit dem Schlüsselwort while eingeleitet. Sie bestehen im Weiteren aus einer Bedingung in runden Klammern und einem in geschweiften Klammern formulierten Code-Block.\nDie Bedingung besteht aus einem Vergleichsausdruck.\nwhile (\u003cBedingung\u003e) { \u003cAnweisung_1\u003e \u003cAnweisung_2\u003e } int a = 10; while (a \u003e 0) { a = a - 1; } Bedingte Anweisung (If-Else) Eine bedingte Anweisung besteht immer aus genau einer if-Anweisung, und einer oder keiner else-Anweisung.\nEine if-Anweisung wird mit dem Schlüsselwort if eingeleitet und besteht aus einer Bedingung in runden Klammern und einem in geschweiften Klammern formulierten Code-Block.\nDie Bedingung besteht aus einem Vergleichsausdruck.\nEine else-Anweisung wird mit dem Schlüsselwort else eingeleitet. Auf das Schlüsselwort folgt in geschweiften Klammern formulierter Code-Block.\nif (\u003cBedingung\u003e) { \u003cAnweisung_1\u003e \u003cAnweisung_2\u003e } if (\u003cBedingung\u003e) { \u003cAnweisung\u003e } else { \u003cAnweisung\u003e } int a = 42; if (a \u003e 0) { a = a - 1; if (a \u003e 0) { a = a - 1; } } else { a = a + 1; } Funktionen Funktionsdefinition Eine Funktionsdefinition macht dem Compiler die Implementierung einer Funktion bekannt.\nSie gibt zunächst die Signatur der Funktion (den \"Funktionskopf\") bekannt: Rückgabetyp, Funktionsname, Parameterliste.\nDie Parameterliste ist eine Komma-separierte Liste mit der Deklaration der Parameter (jeweils Typ und Variablenname). Die Parameterliste kann auch leer sein.\nNach dem Funktionskopf folgt der Körper der Funktion als Code-Block.\nFunktionen können in einem Scope nicht mehrfach definiert werden.\ntype bezeichner(type param1, type param2) { \u003cAnweisung_1\u003e \u003cAnweisung_2\u003e return \u003cBezeichner, Wert oder Operation\u003e; } bool func1(int a, string b) { int c = a + f2(b); return c == 42; } Funktionsaufrufe Funktionsaufrufe bestehen aus einem Bezeichner (Funktionsname) gefolgt von einer in Klammern angegebenen Liste der Argumente, die auch leer sein kann. Als Argumente können alle passend typisierten Ausdrücke dienen.\nfunc1(5, var1) func1(func2(), 1 + 1) Die aufgerufene Funktion muss im aktuellen Scope sichtbar sein, der Funktionsaufruf muss zur Definition passen.\nDie aufgerufene Funktion muss (im Gegensatz zum Zugriff auf Variablen) nicht vor dem ersten Aufruf definiert sein. Folgender Code ist also zulässig:\nint a = 42; if (a == 42) { foo(5); # zulässig: foo ist erst nach diesem Aufruf definiert, aber in diesem Scope sichtbar } int foo(int a) { return a + 37; } Datentypen Unsere Sprache hat drei eingebaute Datentypen:\nDatentyp Definition der Literale int eine beliebige Folge der Ziffern 0-9 string eine beliebige Folge von ASCII-Zeichen, eingeschlossen in \" bool eines der beiden Schlüsselwörter T oder F Beispiele string a = \"wuppie fluppie\"; int a = 0; if (10 \u003c 1) { a = 42; } else { foo(); } int f95(int n) { if (n == 0) { return 1; } else { if (n == 1) { return 1; } else { return f95(n - 1) + f95(n - 2) + f95(n - 3) + f95(n - 4) + f95(n - 5); } } } int n = 10; f95(n); Aufgaben A4.1: Grammatik und AST (2P) Erstellen Sie eine ANTLR-Grammatik für die Zielsprache. Sie können dabei die Grammatik im Sample Project als Ausgangspunkt nutzen und diese anpassen und vervollständigen.\nDefinieren Sie einen AST für die Zielsprache. Welche Informationen aus dem Eingabeprogramm müssen repräsentiert werden?\nProgrammieren Sie eine Traversierung des Parse-Trees, die den AST erzeugt. Testen Sie dies mit den obigen Beispielprogrammen und definieren Sie sich selbst weitere Programme unterschiedlicher Komplexität für diesen Zweck.\nA4.2: Aufbau der Symboltabelle (2P) Bauen Sie für den AST eine Symboltabelle auf. Führen Sie dabei die im ersten Lauf möglichen Prüfungen durch, beispielsweise ob referenzierte Variablen tatsächlich bereits definiert und sichtbar sind oder ob eine Variable oder Funktion in einem Scope mehrfach definiert wird oder ob Variablen als Funktion genutzt werden. Geben Sie erkannte Fehler auf der Konsole aus.\nA4.3: Symboltabelle: Funktionsaufrufe (1P) Implementieren Sie einen zweiten Lauf. Dabei soll für Funktionsaufrufe geprüft werden, ob diese Funktionen bereits definiert sind und im Scope sichtbar sind. Geben Sie erkannte Fehler auf der Konsole aus.\nA4.4: Symboltabelle: Typprüfungen (5P) Implementieren Sie einen dritten Lauf. Führen Sie die Typprüfung durch: Haben die Operanden in Ausdrücken die richtigen Typen, passen die Typen der Funktionsargumente, passen die Typen bei einer Zuweisung, ... Geben Sie erkannte Fehler auf der Konsole aus. Hinweis: Sie brauchen hier nur die Typprüfung durchführen. Eine Typinferenz oder Typerweiterung o.ä. ist nicht notwendig.",
    "description": "Zusammenfassung Ziel dieses Aufgabenblattes ist die Erstellung einer Symboltabelle und eines einfachen Type-Checkers für eine fiktive statisch typisierte Sprache mit Expressions, Kontrollstrukturen und Funktionen.\nMethodik Sie finden im Sample Project eine Grammatik, die (teilweise) zu der Zielsprache auf diesem Blatt passt. Analysieren Sie diese Grammatik und vervollständigen Sie diese bzw. passen Sie diese an.\nErstellen Sie mit dieser Grammatik und ANTLR wieder einen Lexer und Parser. Definieren Sie einen AST und konvertieren Sie Ihren Parse-Tree in einen AST.",
    "tags": [],
    "title": "Blatt 04: Semantische Analyse",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/homework/sheet04.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25)",
    "content": "Die Schnittstelle zwischen dem \"Frontend\" und dem \"Backend\" ist der \"Zwischencode\" (intermediate code (IC), auch intermediate representation (IR) genannt).\nFür den Zwischencode gibt es kein allgemein definiertes Format. In der Praxis trifft man auf eine große Bandbreite an verschiedenen Formaten, besonders verbreitet sind beispielsweise die Formate AST, SSA, LLVM-IR und MLIR.\nÜberblick Zwischencode LLVM als IR",
    "description": "Die Schnittstelle zwischen dem \"Frontend\" und dem \"Backend\" ist der \"Zwischencode\" (intermediate code (IC), auch intermediate representation (IR) genannt).\nFür den Zwischencode gibt es kein allgemein definiertes Format. In der Praxis trifft man auf eine große Bandbreite an verschiedenen Formaten, besonders verbreitet sind beispielsweise die Formate AST, SSA, LLVM-IR und MLIR.\nÜberblick Zwischencode LLVM als IR",
    "tags": [],
    "title": "Zwischencode",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/04-intermediate.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Zwischencode",
    "content": "Einordnung Die Schritte in der letzten Phase der Compiler-Pipeline können sehr unterschiedlich ausfallen.\nBeispielsweise könnte direkt aus dem AST der Ziel-Machine-Code erzeugt werden. Auf der anderen Seite könnte aus dem AST ein Zwischenformat erzeugt werden, darauf Optimierungen vorgenommen werden, daraus ein weiteres Zwischenformat erzeugt werden, darauf weitere Optimierungen vorgenommen werden, ..., bis schließlich nach mehreren Zwischenstufen das Zielformat erzeugt wird.\nNachfolgend betrachten wir verschiedene Beispiele, wie das Zwischenformat aussehen kann.\nAST als Zwischencode (Beispiel Pandoc) Häufig wird der AST selbst als Zwischencode verwendet. Ein Beispiel dafür ist Pandoc.\nDies ist ein Absatz mit * einem Stichpunkt, und * einem zweiten Stichpunkt. {\"blocks\":[{\"t\":\"Para\",\"c\":[{\"t\":\"Str\",\"c\":\"Dies\"}, {\"t\":\"Space\"}, {\"t\":\"Str\",\"c\":\"ist\"}, {\"t\":\"Space\"}, {\"t\":\"Str\",\"c\":\"ein\"}, {\"t\":\"Space\"}, {\"t\":\"Str\",\"c\":\"Absatz\"}, {\"t\":\"Space\"}, {\"t\":\"Str\",\"c\":\"mit\"}]}, {\"t\":\"BulletList\",\"c\":[ [{\"t\":\"Plain\",\"c\":[{\"t\":\"Str\",\"c\":\"einem\"}, {\"t\":\"Space\"}, {\"t\":\"Str\",\"c\":\"Stichpunkt,\"}, {\"t\":\"Space\"}, {\"t\":\"Str\",\"c\":\"und\"}]}], [{\"t\":\"Plain\",\"c\":[{\"t\":\"Str\",\"c\":\"einem\"}, {\"t\":\"Space\"}, {\"t\":\"Str\",\"c\":\"zweiten\"}, {\"t\":\"Space\"}, {\"t\":\"Str\",\"c\":\"Stichpunkt.\"}]}]]}], \"pandoc-api-version\":[1,17,0,4],\"meta\":{}} Der Pandoc-AST spiegelt direkt die Dokumentstruktur wider. Im obigen Beispiel haben wir einen Absatz mit dem Text \"Dies ist ein Absatz mit\", der als Para repräsentiert wird mit einer Liste von Strings (Str) und Leerzeichen (Space).\nDie Stichpunktliste besteht pro Stichpunkt aus einem Plain-Knoten mit dem eigentlichen Inhalt (wieder Strings und Leerzeichen).\nDieser AST ist der Dreh- und Angelpunkt in Pandoc. Verschiedene Reader können unterschiedliche Textformate parsen und in einen AST überführen.\nAuf diesem kann man mit Filtern Transformationen vornehmen.\nAnschließend können diverse Writer den AST in das gewünschte Zielformat überführen.\nKonsole: pandoc hello.md -s -t native Zwischenformat: Drei-Adressen-Code Eine weitere häufig eingesetzte Zwischenform kurz vor der Code-Generierung ist der sogenannte \"Drei-Adressen-Code\". Dieser besteht jeweils aus einer Operation auf bis zu drei Adressen.\nIm Prinzip handelt es sich hier um eine Art \"High-Level Assembler\" mit beliebig vielen Registern ...\nAdressen sind dabei Namen, Konstanten oder vom Compiler generierte temporäre Werte. Die typische Form ist x = y op z (binäre Operationen) oder x = op z (unäre Operationen). Werte werden mit x = y kopiert. Jeder Teilausdruck erhält typischerweise eine eigene temporäre Variable zur Speicherung des Ergebnisses. Weiterhin gibt es bedingte und unbedingte Sprünge und Prozedur-Aufrufe.\nIndex-Zugriffe werden über Pointerarithmetik aufgelöst (s.u.).\nEine Spezialform ist die sogenannte \"Static Single-Assignment\"-Form (SSA). Hierbei wird für jede Zuweisung eine neue temporäre Variable generiert, d.h. jede im IR-Code verwendete Adresse (temporäre Variable) hat genau eine Zuweisung. Dies wirkt sich günstig auf spezielle Optimierungen aus.\ni = i+1; if (a[i] \u003e= v) { i = 0; } t1 = i + 1 i = t1 t2 = i * 8 t3 = a + t2 if t3 \u003e= v goto L1 goto L2 L1: i = 0 L2: ... Im obigen Beispiel wurde davon ausgegangen, dass die Einträge im Array a 8 Bit breit sind. Das muss der Compiler wissen, um jeweils den korrekten Offset zu benutzen.\nAußerdem könnte man den Code gleich noch optimieren und die Anzahl der Sprünge reduzieren:\nt1 = i + 1 i = t1 t2 = i * 8 t3 = a + t2 if t3 \u003c v goto L i = 0 L: ... LLVM IR Low Level Virtual Machine\nint main() { int x = 7; int y = x + 35; return 0; } define i32 @main() #0 { %1 = alloca i32, align 4 %2 = alloca i32, align 4 %3 = alloca i32, align 4 store i32 0, i32* %1, align 4 store i32 7, i32* %2, align 4 %4 = load i32, i32* %2, align 4 %5 = add nsw i32 %4, 35 store i32 %5, i32* %3, align 4 ret i32 0 } Beispiel: clang -emit-llvm -S -o - hello.c Der obige Output ist auf die relevanten Zeilen gekürzt; der gesamte Output im LLVM-Format sieht wie folgt aus:\n; ModuleID = 'hello.c' source_filename = \"hello.c\" target datalayout = \"e-m:e-i64:64-f80:128-n8:16:32:64-S128\" target triple = \"x86_64-pc-linux-gnu\" ; Function Attrs: noinline nounwind optnone uwtable define i32 @main() #0 { %1 = alloca i32, align 4 %2 = alloca i32, align 4 %3 = alloca i32, align 4 store i32 0, i32* %1, align 4 store i32 7, i32* %2, align 4 %4 = load i32, i32* %2, align 4 %5 = add nsw i32 %4, 35 store i32 %5, i32* %3, align 4 ret i32 0 } attributes #0 = { noinline nounwind optnone uwtable \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"less-precise-fpmad\"=\"false\" \"no-frame-pointer-elim\"=\"true\" \"no-frame-pointer-elim-non-leaf\" \"no-infs-fp-math\"=\"false\" \"no-jump-tables\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+fxsr,+mmx,+sse,+sse2,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" } !llvm.module.flags = !{!0} !llvm.ident = !{!1} !0 = !{i32 1, !\"wchar_size\", i32 4} !1 = !{!\"clang version 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\"} Es werden drei \"virtuelle Register\" (Variablen) %1, %2 und %3 auf dem Stack angelegt (32-bit Integer; align 4: alle Adressen sind Vielfache von 4).\nMit store i32 0, ... wird in %1 der Wert 0 geschrieben (vergleichbar mit *p = 0). In %2 wird analog der Wert 7 geschrieben (x=7).\nDann wird der Wert aus %2 in eine neue Variable %4 geladen und das Ergebnis der Addition aus %4 und dem Wert 35 in eine weitere neue Variable %5 geschrieben. Der Wert dieser Variablen wird dann auf dem Stack in %3 gespeichert (y = x+35).\nVgl. auch LLVM Language Reference Manual und blog.regehr.org/archives/1453.\nBytecode (Beispiel Python) x = 7 y = x + 35 1 0 LOAD_CONST 0 (7) 3 STORE_NAME 0 (x) 2 6 LOAD_NAME 0 (x) 9 LOAD_CONST 1 (35) 12 BINARY_ADD 13 STORE_NAME 1 (y) 16 LOAD_CONST 2 (None) 19 RETURN_VALUE Beispiel: python -m dis hello.py Python pflegt 3 Listen: co_names für die Namen plus co_values für die dazugehörigen Werte sowie co_consts für Konstanten. Die Listen der Namen und Werte sind gleich lang, ein Index bezieht sich jeweils auf das selbe Symbol. Werte werden über einen Stack verarbeitet. Die Opcodes stehen in einer weiteren Liste co_code. (Die Opcodes sind oben der besseren Lesbarkeit halber als Text ausgegeben, LOAD_CONST hat beispielsweise den Wert 100.)\nNach dem Laden des Programms ist x in co_names[0], y in co_names[1]. Der Wert 7 steht in co_const[0], die 35 in co_const[1].\nDas LOAD_CONST 0 (co_code[0]) lädt den Inhalt von co_consts[0] auf den Stack (push()), d.h. der Wert 7 wird auf den Stack gepusht. Mit STORE_NAME 0 (co_code[3]) wird der Inhalt des obersten Stackeintrags in co_values[0] geschrieben und der Eintrag vom Stack entfernt (pop()). Dies entspricht Zeile 1 im Quellcode: x = 7.\nLOAD_NAME 0 pusht co_values[0] auf den Stack (Wert von x), gefolgt von der 35 per LOAD_CONST 1 (co_const[1]). Das BINARY_ADD entfernt die beiden obersten Einträge, addiert die Werte und pusht das Ergebnis wieder auf den Stack. Mit STORE_NAME 1 wird der Wert in co_values[1] geschrieben, d.h. y bekommt den Wert zugewiesen.\nBytecode (Beispiel Java) public class Hello { void wuppie() { int x = 7; int y = x + 35; } } Compiled from \"Hello.java\" public class Hello { public Hello(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"\u003cinit\u003e\":()V 4: return void wuppie(); Code: 0: bipush 7 2: istore_1 3: iload_1 4: bipush 35 6: iadd 7: istore_2 8: return } Beispiel: javac Hello.java \u0026\u0026 javap -c Hello.class Für jeden Methodenaufruf wird ein entsprechender Frame auf den Stack gepusht. Dieser enthält ein Array mit den lokalen Variablen, durchnummeriert von 0 bis n-1. (long und double bekommen je 2 lokale Variablen) Zusätzlich gibt es im Frame einen Operandenstack, auf dem Funktionsparameter und -rückgabewerte übergeben werden und auf dem die Operanden für die auszuführenden Operationen sowie deren Zwischenergebnisse hinterlegt werden.\nbipush 7: Pushe den Integer-Wert 7 auf den Stack istore_1: Poppe den ersten Wert vom Stack und speichere ihn in der lokalen Integer-Variable mit Index 1 (x=7) iload_1: Pushe lokale Integer-Variable mit Index 1 auf den Stack (x) bipush 35: Pushe den Integer-Wert 35 auf den Stack iadd: Führe Integer-Addition aus mit den beiden obersten Werten auf Stack und ersetze diese mit dem Ergebnis istore_2: Poppe den ersten Wert vom Stack und speichere ihn in der lokalen Integer-Variable mit Index 2 (y=x+35) Die Konstanten n für iconst_ funktionieren nur für kleinere Integer. Größere Werte muss man mit bipush auf den Stack pushen.\nVgl. auch dzone.com/articles/introduction-to-java-bytecode und www.beyondjava.net/java-programmers-guide-java-byte-code.\nAssembler int main() { int x = 7; int y = x + 35; return 0; } .file \"hello.c\" .text .globl main .type main, @function main: .LFB0: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 movl $7, -8(%rbp) movl -8(%rbp), %eax addl $35, %eax movl %eax, -4(%rbp) movl $0, %eax popq %rbp .cfi_def_cfa 7, 8 ret .cfi_endproc .LFE0: .size main, .-main .ident \"GCC: (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\" .section .note.GNU-stack,\"\",@progbits Beispiel: gcc -S -o - hello.c Die Ausgabe unterscheidet sich je nach Architektur, auf dem der C-Code in Assembler-Code compiliert wird!\nMit .text beginnt das Textsegment. main: ist eine Sprungmarke, die hier auch als Startpunkt für das Programm dient.\nAuf X86-64 stehen %rbp und %rsp für 8-Byte-Register. Mit %eax greift man auf die Bytes 0 bis 3 des 8-Byte-Registers %rax zu.\nDa in %rbp Werte übergeben werden (können), wird das Register mit pushq %rbp auf den Stack gesichert und am Ende mit popq %rbp wiederhergestellt.\nAnsonsten kann man die Bedeutung erraten: movl $7, -8(%rbp) entspricht mem[rbp-8] = 7, movl -8(%rbp), %eax entspricht eax = mem[rbp-8], addl $35, %eax entspricht eax = eax + 35, movl %eax, -4(%rbp) entspricht mem[rbp-4] = eax.\nVgl. auch cs.brown.edu/courses/cs033/docs/guides/x64_cheatsheet.pdf und en.wikibooks.org/wiki/X86_Assembly/GAS_Syntax.\nWrap-Up Compiler generieren aus AST Zwischencode (\"IC\" oder \"IR\") Kein allgemein definiertes Format, große Bandbreite: AST als IR LLVM IR Drei-Adressen-Code Diverse Arten von Bytecode Assemblercode",
    "description": "Einordnung Die Schritte in der letzten Phase der Compiler-Pipeline können sehr unterschiedlich ausfallen.\nBeispielsweise könnte direkt aus dem AST der Ziel-Machine-Code erzeugt werden. Auf der anderen Seite könnte aus dem AST ein Zwischenformat erzeugt werden, darauf Optimierungen vorgenommen werden, daraus ein weiteres Zwischenformat erzeugt werden, darauf weitere Optimierungen vorgenommen werden, ..., bis schließlich nach mehreren Zwischenstufen das Zielformat erzeugt wird.",
    "tags": [],
    "title": "Überblick Zwischencode",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/04-intermediate/intro-ir.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Zwischencode",
    "content": "Motivation Es ist ein neuer Prozessor entwickelt worden mit einem neuen Befehlssatz, und es sollen für zwei Programmiersprachen Compiler entwickelt werden, die diesen Befehlssatz als Ziel haben.\nWas tun?\nThema für heute: Ein Zwischencodeformat für verschiedene Programmiersprachen und Prozessoren Hier entsteht ein Tafelbild.\nLLVM - Ein Überblick Was ist LLVM? ursprünglich: Low Level Virtual Machine Open-Source-Framework zur modularen Entwicklung von Compilern u. ä. für Frontends für beliebige Programmiersprachen für Backends für beliebige Befehlssatzarchitekturen \"Macht aus dem Zwischencode LLVR IR automatisch Maschinencode oder eine VM.\"\nKernstücke des LLVM: ein virtueller Befehlssatz ein virtuelle Maschine LLVM IR: eine streng typisierte Zwischensprache ein flexibel konfigurierbarer Optimierer ein Codegenerator für zahlreiche Architekturen LMIR: mit Dialekten des IR arbeiten Was kann man damit entwickeln? Debugger JIT-Systeme (virtuelle Maschine) AOT-Compiler virtuelle Maschinen Optimierer Systeme zur statischen Analyse etc. mit entkoppelten Komponenten, die über APIs kommunizieren (Modularität)\nWie arbeitet man damit? (mit Generatoren) ein Frontend entwickeln, das Programme über einen AST in LLVM IR übersetzt mit LLVM den Zwischencode optimieren mit LLVM Maschinencode oder VM-Code generieren Was bringt uns das? n Sprachen für m Architekturen übersetzen:\nn Frontends entwickeln Optimierungen spezifizieren m Codegeneratoren spezifizieren statt n x m Compiler zu schreiben.\nWer setzt LLVM ein? Adobe AMD Apple ARM Google\nIBM Intel Mozilla Nvidia Qualcomm\nSamsung ...\nExterne LLVM-Projekte Für folgende Sprachen gibt es Compiler oder Anbindungen an LLVM (neben Clang):\nCrack Go Haskell Java Julia Kotlin\nLua Numba Python Ruby Rust Swift ...\nFür weitere Projekte siehe Projects built with LLVM\nUnterstützte Prozessorarchitekturen x86 AMD64 PowerPC PowerPC 64Bit Thumb\nSPARC Alpha CellSPU PIC16 MIPS\nMSP430 System z XMOS Xcore ...\nEinige Komponenten von LLVM Einige Komponenten (Projekte) von LLVM Der LLVM-Kern incl. Optimierer MLIR für IR-Dialekte Der Compiler Clang Die Compiler-Runtime-Bibliothek Der LLVM-Kern LLVM Core: Optimierer und Codegenerator für viele CPU- und auch GPU-Architekturen\nOptimierer arbeitet unabhängig von der Zielarchitektur (nur auf der LLVM IR) sehr gut dokumentiert verwendete Optimierungspässe fein konfigurierbar Optimierer auch einzeln als Tool opt aufrufbar wird für eigene Sprachen als Optimierer und Codegenerator eingesetzt Wozu ein Optimierer? zur Reduzierung der Codegröße zur Generierung von möglichst schnellem Code Zur Generierung von Code, der möglichst wenig Energie verbraucht Allgegenwärtig in LLVM: Der Optimierer Der Optimierer in LLVM Teil von LLVM Core kann zur Compilezeit, Linkzeit und Laufzeit eingesetzt werden nutzt auch Leerlaufzeit des Prozessors läuft in einzelnen unabhängig konfigurierbaren Pässen über den Code Einige Optimierungen in LLVM Dead Code Elimination Aggressive Dead Code Elimination Dead Argument Elimination Dead Type Elimination Dead Instruction Elimination Dead Store Elimination Dead Global Elimination MLIR Framework zur Definition eigener Zwischensprachendialekte zur high-level Darstellung spezieller Eigenschaften der zu übersetzenden Sprache erleichtert die Umsetzung des AST in Zwischencode z. B. für domänenspezifische Sprachen (DSLs) z. B. für bestimmte Hardware mehrere Abstraktionen gleichzeitig benutzbar Der Compiler Clang Clang: schneller C/C++/Objective-C - Compiler auf Basis von LLVM mit aussagekräftigen Fehlermeldungen und Warnungen\nDie Sanitizer in der Compiler-Runtime-Bibliothek Sanitizer: Methoden zur Instrumentierung (Code der in das kompilierte Programm eingebettet wird) zur Erleichterung der Lokalisierung und Analyse verschiedenster Fehlerquellen, z. B.:\nSpeicherfehler und Speicherlecks (z. B. use-after-free) Race Conditions undefiniertes Verhalten (Overflows, Benutzung von Null-Pointern) Benutzung von nicht-initialisierten Variablen Wrap-Up LLVM ist eine (fast) komplette Infrastruktur zur Entwicklung von Compilern und compilerähnlichen Programmen.\nDie wichtigsten Bestandteile:\nder Zwischencode LLVM IR der LLVM Optimierer der Codegenarator mit Sanitizern",
    "description": "Motivation Es ist ein neuer Prozessor entwickelt worden mit einem neuen Befehlssatz, und es sollen für zwei Programmiersprachen Compiler entwickelt werden, die diesen Befehlssatz als Ziel haben.\nWas tun?\nThema für heute: Ein Zwischencodeformat für verschiedene Programmiersprachen und Prozessoren Hier entsteht ein Tafelbild.\nLLVM - Ein Überblick Was ist LLVM? ursprünglich: Low Level Virtual Machine Open-Source-Framework zur modularen Entwicklung von Compilern u. ä. für Frontends für beliebige Programmiersprachen für Backends für beliebige Befehlssatzarchitekturen \"Macht aus dem Zwischencode LLVR IR automatisch Maschinencode oder eine VM.\"",
    "tags": [],
    "title": "LLVM als IR",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/04-intermediate/llvm-ir.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25)",
    "content": "Ein Interpreter erzeugt keinen Code, sondern führt Source-Code (interaktiv) aus. Die einfachste Möglichkeit ist der Einsatz von attributierten Grammatiken, wo der Code bereits beim Parsen ausgeführt wird (\"syntaxgesteuerte Interpretation\"). Mehr Möglichkeiten hat man dagegen bei der Traversierung des AST, beispielsweise mit dem Visitor-Pattern. Auch die Abarbeitung von Bytecode in einer Virtuellen Maschine (VM) zählt zur Interpretation.\n(Register- und Stack-basierte Interpreter betrachten wir im Rahmen der Veranstaltung aktuell nicht.)\nAST-basierte Interpreter: Basics AST-basierte Interpreter: Funktionen und Klassen",
    "description": "Ein Interpreter erzeugt keinen Code, sondern führt Source-Code (interaktiv) aus. Die einfachste Möglichkeit ist der Einsatz von attributierten Grammatiken, wo der Code bereits beim Parsen ausgeführt wird (\"syntaxgesteuerte Interpretation\"). Mehr Möglichkeiten hat man dagegen bei der Traversierung des AST, beispielsweise mit dem Visitor-Pattern. Auch die Abarbeitung von Bytecode in einer Virtuellen Maschine (VM) zählt zur Interpretation.\n(Register- und Stack-basierte Interpreter betrachten wir im Rahmen der Veranstaltung aktuell nicht.)\nAST-basierte Interpreter: Basics AST-basierte Interpreter: Funktionen und Klassen",
    "tags": [],
    "title": "Interpreter",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/06-interpretation.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Interpreter",
    "content": "Aufgaben im Interpreter Im Allgemeinen reichen einfache syntaxgesteuerte Interpreter nicht aus. Normalerweise simuliert ein Interpreter die Ausführung eines Programms durch den Computer. D.h. der Interpreter muss über die entsprechenden Eigenschaften verfügen: Prozessor, Code-Speicher, Datenspeicher, Stack ...\nint x = 42; int f(int x) { int y = 9; return y+x; } x = f(x); Aufbauen des AST ... =\u003e Lexer+Parser\nAuflösen von Symbolen/Namen ... =\u003e Symboltabellen, Resolving\nType-Checking und -Inference ... =\u003e Semantische Analyse (auf Symboltabellen)\nSpeichern von Daten: Name+Wert vs. Adresse+Wert (Erinnerung: Data-Segment und Stack im virtuellen Speicher)\nAusführen von Anweisungen Text-Segment im virtuellen Speicher; hier über den AST\nAufruf von Funktionen und Methoden Kontextwechsel nötig: Was ist von wo aus sichtbar?\nAST-basierte Interpreter: Visitor-Dispatcher def eval(self, AST t): if t.type == Parser.BLOCK : block(t) elif t.type == Parser.ASSIGN : assign(t) elif t.type == Parser.RETURN : ret(t) elif t.type == Parser.IF : ifstat(t) elif t.type == Parser.CALL : return call(t) elif t.type == Parser.ADD : return add(t) elif t.type == Parser.MUL : return mul(t) elif t.type == Parser.INT : return Integer.parseInt(t.getText()) elif t.type == Parser.ID : return load(t) else : ... # catch unhandled node types return None; Nach dem Aufbau des AST durch Scanner und Parser und der semantischen Analyse anhand der Symboltabellen müssen die Ausdrücke (expressions) und Anweisungen (statements) durch den Interpreter ausgewertet werden. Eine Möglichkeit dazu ist das Traversieren des AST mit dem Visitor-Pattern. Basierend auf dem Typ des aktuell betrachteten AST-Knotens wird entschieden, wie damit umgegangen werden soll. Dies erinnert an den Aufbau der Symboltabellen ...\nDie eval()-Methode bildet das Kernstück des (AST-traversierenden) Interpreters. Hier wird passend zum aktuellen AST-Knoten die passende Methode des Interpreters aufgerufen.\nHinweis: Im obigen Beispiel wird nicht zwischen der Auswertung von Ausdrücken und Anweisungen unterschieden, es wird die selbe Methode eval() genutzt. Allerdings liefern Ausdrücke einen Wert zurück (erkennbar am return im jeweiligen switch/case-Zweig), während Anweisungen keinen Wert liefern.\nIn den folgenden Beispielen wird davon ausgegangen, dass ein komplettes Programm eingelesen, geparst, vorverarbeitet und dann interpretiert wird.\nFür einen interaktiven Interpreter würde man in einer Schleife die Eingaben lesen, parsen und vorverarbeiten und dann interpretieren. Dabei würde jeweils der AST und die Symboltabelle ergänzt, damit die neuen Eingaben auf frühere verarbeitete Eingaben zurückgreifen können. Durch die Form der Schleife \"Einlesen -- Verarbeiten -- Auswerten\" hat sich auch der Name \"Read-Eval-Loop\" bzw. \"Read-Eval-Print-Loop\" (REPL) eingebürgert.\nAuswertung von Literalen und Ausdrücken Typen mappen: Zielsprache =\u003e Implementierungssprache\nDie in der Zielsprache verwendeten (primitiven) Typen müssen auf passende Typen der Sprache, in der der Interpreter selbst implementiert ist, abgebildet werden.\nBeispielsweise könnte man den Typ nil der Zielsprache auf den Typ null des in Java implementierten Interpreters abbilden, oder den Typ number der Zielsprache auf den Typ Double in Java mappen.\nLiterale auswerten:\nINT: [0-9]+ ; elif t.type == Parser.INT : return Integer.parseInt(t.getText()) Das ist der einfachste Teil ... Die primitiven Typen der Zielsprache, für die es meist ein eigenes Token gibt, müssen als Datentyp der Interpreter-Programmiersprache ausgewertet werden.\nAusdrücke auswerten:\nadd: e1=expr \"+\" e2=expr ; def add(self, AST t): lhs = eval(t.e1()) rhs = eval(t.e2()) return (double)lhs + (double)rhs # Semantik! Die meisten möglichen Fehlerzustände sind bereits durch den Parser und bei der semantischen Analyse abgefangen worden. Falls zur Laufzeit die Auswertung der beiden Summanden keine Zahl ergibt, würde eine Java-Exception geworfen, die man an geeigneter Stelle fangen und behandeln muss. Der Interpreter soll sich ja nicht mit einem Stack-Trace verabschieden, sondern soll eine Fehlermeldung präsentieren und danach normal weiter machen ...\nKontrollstrukturen ifstat: 'if' expr 'then' s1=stat ('else' s2=stat)? ; def ifstat(self, AST t): if eval(t.expr()): eval(t.s1()) else: if t.s2(): eval(t.s2()) Analog können die anderen bekannten Kontrollstrukturen umgesetzt werden, etwa switch/case, while oder for.\nDabei können erste Optimierungen vorgenommen werden: Beispielsweise könnten for-Schleifen im Interpreter in while-Schleifen transformiert werden, wodurch im Interpreter nur ein Schleifenkonstrukt implementiert werden müsste.\nZustände: Auswerten von Anweisungen int x = 42; float y; { int x; x = 1; y = 2; { int y = x; } } Das erinnert nicht nur zufällig an den Aufbau der Symboltabellen :-)\nUnd so lange es nur um Variablen ginge, könnte man die Symboltabellen für das Speichern der Werte nutzen. Allerdings müssen wir noch Funktionen und Strukturen bzw. Klassen realisieren, und spätestens dann kann man die Symboltabelle nicht mehr zum Speichern von Werten einsetzen. Also lohnt es sich, direkt neue Strukturen für das Halten von Variablen und Werten aufzubauen.\nDetail: Felder im Interpreter Eine mögliche Implementierung für einen Interpreter basierend auf einem ANTLR-Visitor ist nachfolgend gezeigt.\nHinweis: Bei der Ableitung des BaseVisitor\u003cT\u003e muss der Typ T festgelegt werden. Dieser fungiert als Rückgabetyp für die Visitor-Methoden. Entsprechend können alle Methoden nur einen gemeinsamen (Ober-) Typ zurückliefern, weshalb man sich an der Stelle oft mit Object behilft und dann manuell den konkreten Typ abfragen und korrekt casten muss.\nclass Interpreter(BaseVisitor\u003cObject\u003e): __init__(self, AST t): BaseVisitor\u003cObject\u003e.__init__(self) self.root = t self.env = Environment() Quelle: Eigener Code basierend auf einer Idee nach Interpreter.java by Bob Nystrom on Github.com (MIT)\nAusführen einer Variablendeklaration varDecl: \"var\" ID (\"=\" expr)? \";\" ; def varDecl(self, AST t): # deklarierte Variable (String) name = t.ID().getText() value = None; # TODO: Typ der Variablen beachten (Defaultwert) if t.expr(): value = eval(t.expr()) self.env.define(name, value) return None Wenn wir bei der Traversierung des AST mit eval() bei einer Variablendeklaration vorbeikommen, also etwa int x; oder int x = wuppie + fluppie;, dann wird im aktuellen Environment der String \"x\" sowie der Wert (im zweiten Fall) eingetragen.\nAusführen einer Zuweisung assign: ID \"=\" expr; def assign(self, AST t): lhs = t.ID().getText() value = eval(t.expr()) self.env.assign(lhs, value) # Semantik! } class Environment: def assign(self, String n, Object v): if self.values[n]: self.values[n] = v elif self.enclosing: self.enclosing.assign(n, v) else: raise RuntimeError(n, \"undefined variable\") Quelle: Eigener Code basierend auf einer Idee nach Environment.java by Bob Nystrom on Github.com (MIT)\nWenn wir bei der Traversierung des AST mit eval() bei einer Zuweisung vorbeikommen, also etwa x = 7; oder x = wuppie + fluppie;, dann wird zunächst im aktuellen Environment die rechte Seite der Zuweisung ausgewertet (Aufruf von eval()). Anschließend wird der Wert für die Variable im Environment eingetragen: Entweder sie wurde im aktuellen Environment früher bereits definiert, dann wird der neue Wert hier eingetragen. Ansonsten wird entlang der Verschachtelungshierarchie gesucht und entsprechend eingetragen. Falls die Variable nicht gefunden werden kann, wird eine Exception ausgelöst.\nAn dieser Stelle kann man über die Methode assign in der Klasse Environment dafür sorgen, dass nur bereits deklarierte Variablen zugewiesen werden dürfen. Wenn man stattdessen wie etwa in Python das implizite Erzeugen neuer Variablen erlaubten möchte, würde man statt Environment#assign einfach Environment#define nutzen ...\nAnmerkung: Der gezeigte Code funktioniert nur für normale Variablen, nicht für Zugriffe auf Attribute einer Struct oder Klasse!\nBlöcke: Umgang mit verschachtelten Environments block: '{' stat* '}' ; def block(self, AST t): prev = self.env try: self.env = Environment(self.env) for s in t.stat(): eval(s) finally: self.env = prev return None; Quelle: Eigener Code basierend auf einer Idee nach Interpreter.java by Bob Nystrom on Github.com (MIT)\nBeim Interpretieren von Blöcken muss man einfach nur eine weitere Verschachtelungsebene für die Environments anlegen und darin dann die Anweisungen eines Blockes auswerten ...\nWichtig: Egal, was beim Auswerten der Anweisungen in einem Block passiert: Es muss am Ende die ursprüngliche Umgebung wieder hergestellt werden (finally-Block).\nWrap-Up Interpreter simulieren die Programmausführung\nNamen und Symbole auflösen Speicherbereiche simulieren Code ausführen: Read-Eval-Loop Traversierung des AST: eval(AST t) als Visitor-Dispatcher\nScopes mit Environment (analog zu Symboltabellen)\nInterpretation von Blöcken und Variablen (Deklaration, Zuweisung)",
    "description": "Aufgaben im Interpreter Im Allgemeinen reichen einfache syntaxgesteuerte Interpreter nicht aus. Normalerweise simuliert ein Interpreter die Ausführung eines Programms durch den Computer. D.h. der Interpreter muss über die entsprechenden Eigenschaften verfügen: Prozessor, Code-Speicher, Datenspeicher, Stack ...\nint x = 42; int f(int x) { int y = 9; return y+x; } x = f(x); Aufbauen des AST ... =\u003e Lexer+Parser\nAuflösen von Symbolen/Namen ... =\u003e Symboltabellen, Resolving\nType-Checking und -Inference ... =\u003e Semantische Analyse (auf Symboltabellen)",
    "tags": [],
    "title": "AST-basierte Interpreter: Basics",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/06-interpretation/astdriven-part1.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Interpreter",
    "content": "Funktionen int foo(int a, int b, int c) { print a + b + c; } foo(1, 2, 3); def makeCounter(): var i = 0 def count(): i = i + 1 print i return count; counter = makeCounter() counter() # \"1\" counter() # \"2\" Die Funktionsdeklaration muss im aktuellen Kontext abgelegt werden, dazu wird der AST-Teilbaum der Deklaration benötigt.\nBeim Aufruf muss man das Funktionssymbol im aktuellen Kontext suchen, die Argumente auswerten, einen neuen lokalen Kontext anlegen und darin die Parameter definieren (mit den eben ausgewerteten Werten) und anschließend den AST-Teilbaum des Funktionskörpers im Interpreter mit eval() auswerten ...\nAusführen einer Funktionsdeklaration funcDecl : type ID '(' params? ')' block ; funcCall : ID '(' exprList? ')' ; def funcDecl(self, AST t): fn = Fun(t, self.env) self.env.define(t.ID().getText(), fn) Quelle: Eigener Code basierend auf einer Idee nach LoxFunction.java by Bob Nystrom on Github.com (MIT)\nMan definiert im aktuellen Environment den Funktionsnamen und hält dazu den aktuellen Kontext (aktuelles Environment) sowie den AST-Knoten mit der eigentlichen Funktionsdefinition fest.\nFür Closures ist der aktuelle Kontext wichtig, sobald man die Funktion ausführen muss. In [Parr2010, S.236] wird beispielsweise einfach nur ein neuer Memory-Space (entspricht ungefähr hier einem neuen lokalen Environment) angelegt, in dem die im Funktionskörper definierten Symbole angelegt werden. Die Suche nach Symbolen erfolgt dort nur im Memory-Space (Environment) der Funktion bzw. im globalen Scope (Environment).\nAusführen eines Funktionsaufrufs funcDecl : type ID '(' params? ')' block ; funcCall : ID '(' exprList? ')' ; def funcCall(self, AST t): fn = (Fun)eval(t.ID()) args = [eval(a) for a in t.exprList()] prev = self.env; self.env = Environment(fn.closure) for i in range(args.size()): self.env.define(fn.decl.params()[i].getText(), args[i]) eval(fn.decl.block()) self.env = prev Quelle: Eigener Code basierend auf einer Idee nach LoxFunction.java by Bob Nystrom on Github.com (MIT)\nZunächst wird die ID im aktuellen Kontext ausgewertet. In der obigen Grammatik ist dies tatsächlich nur ein Funktionsname, aber man könnte über diesen Mechanismus auch Ausdrücke erlauben und damit Funktionspointer bzw. Funktionsreferenzen realisieren ... Im Ergebnis hat man das Funktionsobjekt mit dem zugehörigen AST-Knoten und dem Kontext zur Deklarationszeit.\nDie Argumente der Funktion werden nacheinander ebenfalls im aktuellen Kontext ausgewertet.\nUm den Funktionsblock auszuwerten, legt man einen neuen temporären Kontext über dem Closure-Kontext der Funktion an und definiert darin die Parameter der Funktion samt den aktuellen Werten. Dann lässt man den Interpreter über den Visitor-Dispatch den Funktionskörper evaluieren und schaltet wieder auf den Kontext vor der Funktionsauswertung zurück.\nFunktionsaufruf: Rückgabewerte def funcCall(self, AST t): ... eval(fn.decl.block()) ... return None # (Wirkung) class ReturnEx(RuntimeException): __init__(self, v): self.value = v def return(self, AST t): raise ReturnEx(eval(t.expr())) def funcCall(self, AST t): ... erg = None try: eval(fn.decl.block()) except ReturnEx as r: erg = r.value ... return erg; Quelle: Eigener Code basierend auf einer Idee nach Return.java und LoxFunction.java by Bob Nystrom on Github.com (MIT)\nRückgabewerte für den Funktionsaufruf werden innerhalb von block berechnet, wo eine Reihe von Anweisungen interpretiert werden, weshalb block ursprünglich keinen Rückgabewert hat. Im Prinzip könnte man block etwas zurück geben lassen, was durch die möglicherweise tiefe Rekursion relativ umständlich werden kann.\nAn dieser Stelle kann man den Exceptions-Mechanismus missbrauchen und bei der Auswertung eines return mit dem Ergebniswert direkt zum Funktionsaufruf zurück springen. In Methoden, wo man einen neuen lokalen Kontext anlegt und die globale env-Variable temporär damit ersetzt, muss man dann ebenfalls mit try/catch arbeiten und im finally-Block die Umgebung zurücksetzen und die Exception erneut werfen.\nNative Funktionen class Callable: def call(self, Interpreter i, List\u003cObject\u003e a): pass class Fun(Callable): ... class NativePrint(Fun): def call(self, Interpreter i, List\u003cObject\u003e a): for o in a: print a # nur zur Demo, hier sinnvoller Code :-) # Im Interpreter (Initialisierung): self.env.define(\"print\", NativePrint()) def funcCall(self, AST t): ... # prev = self.env; self.env = Environment(fn.closure) # for i in range(args.size()): ... # eval(fn.decl.block()); self.env = prev fn.call(self, args) ... Quelle: Eigener Code basierend auf einer Idee nach LoxCallable.java und LoxFunction.java by Bob Nystrom on Github.com (MIT)\nNormalerweise wird beim Interpretieren eines Funktionsaufrufs der Funktionskörper (repräsentiert durch den entsprechenden AST-Teilbaum) durch einen rekursiven Aufruf von eval ausgewertet.\nFür native Funktionen, die im Interpreter eingebettet sind, klappt das nicht mehr, da hier kein AST vorliegt.\nMan erstellt ein neues Interface Callable mit der Hauptmethode call() und leitet die frühere Klasse Fun davon ab: class Fun(Callable). Die Methode funcCall() des Interpreters ruft nun statt der eval()-Methode die call()-Methode des Funktionsobjekts auf und übergibt den Interpreter (== Zustand) und die Argumente. Die call()-Methode der Klasse Fun muss nun ihrerseits im Normalfall den im Funktionsobjekt referenzierten AST-Teilbaum des Funktionskörpers mit dem Aufruf von eval() interpretieren ...\nFür die nativen Funktionen leitet man einfach eine (anonyme) Klasse ab und speichert sie unter dem gewünschten Namen im globalen Kontext des Interpreters. Die call()-Methode wird dann entsprechend der gewünschten Funktion implementiert, d.h. hier erfolgt kein weiteres Auswerten des AST.\nKlassen und Instanzen I classDef : \"class\" ID \"{\" funcDecl* \"}\" ; def classDef(self, AST t): methods = HashMap\u003cString, Fun\u003e() for m in t.funcDecl(): fn = Fun(m, self.env) methods[m.ID().getText()] = fn clazz = Clazz(methods) self.env.define(t.ID().getText(), clazz) Quelle: Eigener Code basierend auf einer Idee nach Interpreter.java by Bob Nystrom on Github.com (MIT)\nAnmerkung: In dieser Darstellung wird der Einfachheit halber nur auf Methoden eingegangen. Für Attribute müssten ähnliche Konstrukte implementiert werden.\nKlassen und Instanzen II class Clazz(Callable): __init__(self, Map\u003cString, Fun\u003e methods): self.methods = methods def call(self, Interpreter i, List\u003cObject\u003e a): return Instance(self) def findMethod(self, String name): return self.methods[name] class Instance: __init__(self, Clazz clazz): self.clazz = clazz def get(self, String name): method = self.clazz.findMethod(name) if method != None: return method.bind(self) raise RuntimeError(name, \"undefined method\") Quelle: Eigener Code basierend auf einer Idee nach LoxClass.java und LoxInstance.java by Bob Nystrom on Github.com (MIT)\nInstanzen einer Klasse werden durch den funktionsartigen \"Aufruf\" der Klassen angelegt (parameterloser Konstruktor). Eine Instanz hält die Attribute (hier nicht gezeigt) und eine Referenz auf die Klasse, um später an die Methoden heranzukommen.\nZugriff auf Methoden (und Attribute) getExpr : obj \".\" ID ; def getExpr(self, AST t): obj = eval(t.obj()) if isinstance(obj, Instance): return ((Instance)obj).get(t.ID().getText()) raise RuntimeError(t.obj().getText(), \"no object\") Beim Zugriff auf Attribute muss das Objekt im aktuellen Kontext evaluiert werden. Falls es eine Instanz von Instance ist, wird auf das Feld per interner Hash-Map zugriffen; sonst Exception.\nMethoden und this oder self class Fun(Callable): def bind(self, Instance i): e = Environment(self.closure) e.define(\"this\", i) e.define(\"self\", i) return Fun(self.decl, e) Quelle: Eigener Code basierend auf einer Idee nach LoxFunction.java by Bob Nystrom on Github.com (MIT)\nNach dem Interpretieren von Klassendefinitionen sind die Methoden in der Klasse selbst gespeichert, wobei der jeweilige closure auf den Klassenkontext zeigt.\nBeim Auflösen eines Methodenaufrufs wird die gefundene Methode an die Instanz gebunden, d.h. es wird eine neue Funktion angelegt, deren closure auf den Kontext der Instanz zeigt. Zusätzlich wird in diesem Kontext noch die Variable \"this\" definiert, damit man damit auf die Instanz zugreifen kann.\nIn Python wird das in der Methodensignatur sichtbar: Der erste Parameter ist eine Referenz auf die Instanz, auf der diese Methode ausgeführt werden soll ...\nWrap-Up Interpreter simulieren die Programmausführung\nNamen und Symbole auflösen Speicherbereiche simulieren Code ausführen: Read-Eval-Loop Traversierung des AST: eval(AST t) als Visitor-Dispatcher\nScopes mit Environment (analog zu Symboltabellen)\nInterpretation von Funktionen (Deklaration/Aufruf, native Funktionen)\nInterpretation von Klassen und Instanzen",
    "description": "Funktionen int foo(int a, int b, int c) { print a + b + c; } foo(1, 2, 3); def makeCounter(): var i = 0 def count(): i = i + 1 print i return count; counter = makeCounter() counter() # \"1\" counter() # \"2\" Die Funktionsdeklaration muss im aktuellen Kontext abgelegt werden, dazu wird der AST-Teilbaum der Deklaration benötigt.\nBeim Aufruf muss man das Funktionssymbol im aktuellen Kontext suchen, die Argumente auswerten, einen neuen lokalen Kontext anlegen und darin die Parameter definieren (mit den eben ausgewerteten Werten) und anschließend den AST-Teilbaum des Funktionskörpers im Interpreter mit eval() auswerten ...",
    "tags": [],
    "title": "AST-basierte Interpreter: Funktionen und Klassen",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/06-interpretation/astdriven-part2.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25)",
    "content": "Unterschiedliche Programmiersprachen weisen nicht nur verschiedene Syntaxelemente auf, sondern haben eine teilweise stark unterschiedliche Semantik. Beides hat Auswirkungen auf die Bausteine eines Compilers.\nEinführung in C++ (Erinnerungen an C) C++: Pointer und Referenzen C++: Klassen C++: Big 3 C++: Operatoren C++: Vererbung und Polymorphie C++: Templates",
    "description": "Unterschiedliche Programmiersprachen weisen nicht nur verschiedene Syntaxelemente auf, sondern haben eine teilweise stark unterschiedliche Semantik. Beides hat Auswirkungen auf die Bausteine eines Compilers.\nEinführung in C++ (Erinnerungen an C) C++: Pointer und Referenzen C++: Klassen C++: Big 3 C++: Operatoren C++: Vererbung und Polymorphie C++: Templates",
    "tags": [],
    "title": "Programmiersprachen und -konzepte",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/99-languages.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Programmiersprachen",
    "content": "Warum? C++ erlaubt ressourcenschonende Programmierung Objektorientierter \"Aufsatz\" auf C Verbreitet bei hardwarenaher und/oder rechenintensiver Software Sie werden C++ im Modul \"Computergrafik\" brauchen!\nGeschichte\n1971-73: Ritchie entwickelt die Sprache C Ab 1979: Entwicklung von C++ durch Bjarne Stroustrup bei AT\u0026T Erweiterung der prozeduralen Sprache C Ursprünglich \"C mit Klassen\", später \"C++\" (Inkrement-Operator) Bis heute: Fortlaufende Erweiterungen: alle 3 Jahre neuer Standard (C++11, C++14, ...) C/C++ vs. Java Java: Fokus auf Sicherheit und Robustheit Diverse Sicherheitschecks durch Compiler und VM (zb. Array-Zugriff) Speicherverwaltung (Garbage Collection), kein Speicherzugriff über Pointer Automatische Initialisierung von Variablen C/C++: Fokus auf Effizienz (Speicher, Laufzeit) für korrekte Programme Vergleichsweise schwache Sicherheitschecks durch Compiler, keine VM (d.h. keine Prüfung von Array-Indizes u.a.) Keine Garbage Collection, Programmierer hat direkten Zugriff auf Speicher Keine automatische Initialisierung von Variablen Hello World! /* * HelloWorld.cpp (g++ -Wall HelloWorld.cpp) */ #include \u003ccstdio\u003e #include \u003ciostream\u003e #include \u003ccstdlib\u003e using namespace std; int main() { printf(\"Hello World from C++ :-)\\n\"); cout \u003c\u003c \"Hello World from C++ :-)\" \u003c\u003c endl; std::cout \u003c\u003c \"Hello World from C++ :-)\" \u003c\u003c std::endl; return EXIT_SUCCESS; } Beobachtungen Jedes (ausführbare) C++-Programm hat genau eine main()-Funktion. Die main()-Funktion ist keine Methode einer Klasse: In C/C++ gibt es Funktionen auch außerhalb von Klassen.\nIn C++ gibt es Namespaces (dazu später mehr). Die aus der Standardbibliothek importierten Funktionen sind in der Regel im Namespace std definiert. Mit using namespace std; können Sie auf die Elemente direkt zugreifen. Wenn Sie das using namespace std; weglassen, müssten Sie bei jeder Verwendung eines Symbols den Namensraum explizit dazu schreiben std::cout \u003c\u003c \"Hello World from C++ :-)\" \u003c\u003c std::endl;.\nSie können im C++-Code auch Funktionen aus C benutzen, d.h. Sie können für die Ausgabe beispielsweise printf nutzen (dazu müssen Sie den Header \u003ccstdio\u003e importieren). Die \"richtige\" Ausgabe in C++ ist aber die Nutzung des Ausgabestreams cout und des Ausgabeoperators \u003c\u003c. Das endl sorgt für einen zum jeweiligen Betriebssystem passenden Zeilenumbruch.\nDer Rückgabewert signalisiert Erfolg bzw. Fehler der Programmausführung. Dabei steht der Wert 0 traditionell für Erfolg (Konvention!). Besser Makros nutzen: EXIT_SUCCESS bzw. EXIT_FAILURE (in cstdlib).\nPräprozessor Der Präprozessor transformiert den Quellcode vor dem Compiler-Lauf. Zu den wichtigsten Aufgaben gehören dabei die Makrosubstitution (#define Makroname Ersatztext) und das Einfügen von Header-Dateien (und anderen Dateien) per #include. Es gibt dabei zwei Formen, die an unterschiedlichen Orten nach der angegebenen Datei suchen:\n#include \"dateiname\" sucht im aktuellen Ordner #include \u003cdateiname\u003e sucht im Standardverzeichnis Das #include kann wie in C genutzt werden, aber es gibt auch die Form ohne die Dateiendung \".h\". Da es in C keine Funktionsüberladung gibt (in C++ dagegen schon), müssen die C-Header speziell markiert sein, um sie in C++ verwenden zu können. Für die Standard-Header ist dies bereits erledigt, Sie finden diese mit einem \"c\" vorangestellt:\nInclude in C: #include \u003cstdio.h\u003e Include in C++: #include \u003ccstdio\u003e Übersetzen, Linken, Ausführen C++-Dateien werden üblicherweise mit der Endung \".cpp\" oder \".cxx\" oder \".cc\" abgespeichert, Header-Dateien mit den Endungen \".hpp\" oder \".hxx\" oder \".hh\".\nZum Übersetzen und Linken in einem Arbeitsschritt rufen Sie den Compiler auf: g++ HelloWorld.cpp bzw. besser g++ -Wall -o helloworld HelloWorld.cpp. Die Option -Wall sorgt dafür, dass alle Warnungen aktiviert werden.\nAusführen können Sie das erzeugte Programm in der Konsole mit: ./helloworld. Der aktuelle Ordner ist üblicherweise (aus Sicherheitsgründen) nicht im Suchpfad für ausführbare Dateien enthalten. Deshalb muss man explizit angeben, dass ein Programm im aktuellen Ordner (.) ausgeführt werden soll.\nKonsole: HelloWorld.cpp Variablen, Operatoren, Kontrollfluss Im Wesentlichen wie von C und Java gewohnt ... :-)\nWichtig(st)e Abweichung:\nIm booleschen Kontext wird int als Wahrheitswert interpretiert: Alle Werte ungleich 0 entsprechen true (!)\nAnmerkung: Dies steht im Widerspruch zu den Werten, die in der main-Funktion per return zurückgeliefert werden: Hier bedeutet 0 in der Regel, dass alles OK war.\n=\u003e Vorsicht mit\nint c; if (c=4) { ... } Ein- und Ausgabe mit printf und cin/cout printf(formatstring, ...)\nstring foo = \"fluppie\"; printf(\"hello world : %s\\n\", foo.c_str()); Einbinden über #include \u003ccstdio\u003e\nFormat-String: Text und Formatierung der restlichen Parameter: %[flags][width][.precision]conversion\nflags: hängt von der konkreten Ausgabe ab\nwidth: Feldbreite\nprecision: Anzahl der Dezimalstellen\nconversion: (Beispiele)\nc Zeichen (Char) d Integer (dezimal) f Gleitkommazahl Standardkanäle: cin (Standardeingabe), cout (Standardausgabe), cerr (Standardfehlerausgabe)\nGenauer: cout ist ein Ausgabestrom, auf dem der Operator \u003c\u003c schreibt Einbinden über #include \u003ciostream\u003e Implementierung der Ein- und Ausgabeoperatoren (\u003e\u003e, \u003c\u003c) für Basistypen und Standardklassen vorhanden Automatische Konvertierungen für Basistypen und Standardklassen // Ausgabe, auch verkettet string foo = \"fluppie\"; cout \u003c\u003c \"hello world : \" \u003c\u003c foo \u003c\u003c endl; // liest alle Ziffern bis zum ersten Nicht-Ziffernzeichen // (fuehrende Whitespaces werden ignoriert!) int zahl; cin \u003e\u003e zahl; // Einzelne Zeichen (auch Whitespaces) lesen char c; cin.get(c); Beispiel: cin.cpp Sichtbarkeit und Gültigkeit und Namespaces Wie in Java:\nNamen sind nur nach Deklaration und innerhalb des Blockes, in dem sie deklariert wurden, gültig Namen sind auch gültig für innerhalb des Blockes neu angelegte innere Blöcke Namen in inneren Blöcken können Namen aus äußeren Scopes überdecken Zusätzlich gibt es noch benannte Scopes und einen Scope-Operator.\nC++ enthält den Scope-Operator :: =\u003e Zugriff auf global sichtbare Variablen\nint a=1; int main() { int a = 10; cout \u003c\u003c \"lokal: \" \u003c\u003c a \u003c\u003c \"global: \" \u003c\u003c ::a \u003c\u003c endl; } Alle Namen aus XYZ zugänglich machen: using namespace XYZ;\nusing namespace std; cout \u003c\u003c \"Hello World\" \u003c\u003c endl; Alternativ gezielter Zugriff auf einzelne Namen: XYZ::name\nstd::cout \u003c\u003c \"Hello World\" \u003c\u003c std::endl; Namensraum XYZ deklarieren\nnamespace XYZ { ... } Beispiel: cppScope.cpp Arrays und Vektoren in C++ Syntax: Typ Name[AnzahlElemente];\nint myArray[100]; int myArray2[] = {1, 2, 3, 4}; Compiler reserviert sofort Speicher auf dem Stack =\u003e statisch: im Programmlauf nicht änderbar\nZugriff über den Indexoperator []\nAchtung: \"roher\" Speicher, d.h. keinerlei Methoden\nGröße nachträglich bestimmen mit sizeof:\nint myArray[100], i; int cnt = sizeof(myArray)/sizeof(myArryay[0]); Guter Stil: Anzahl der Elemente als Konstante deklarieren: Statt int myArray[100]; besser\n#define LENGTH 100 int myArray[LENGTH]; Vordefinierter Vektor-Datentyp vector\nEinbinden über #include \u003cvector\u003e Parametrisierter Datentyp (C++: Templates) - Nutzung analog wie in Java (Erstellung von Templateklassen und -methoden aber deutlich anders!) Anlegen eines neuen Arrays mit 10 Elementen für Integer: vector\u003cint\u003e v(10); vector\u003cdouble\u003e meinVektor = {1.1, 2.2, 3.3, 4.4}; meinVektor.push_back(5.5); cout \u003c\u003c meinVektor.size() \u003c\u003c endl; Zugriff auf Elemente: cout \u003c\u003c v[0] \u003c\u003c endl; // ohne Bereichspruefung! cout \u003c\u003c v.at(1000) \u003c\u003c endl; // mit interner Bereichspruefung Zuweisung (mit Kopieren): vector\u003cdouble\u003e andererVektor; andererVektor = meinVektor; Dynamische Datenstruktur: vector\u003cint\u003e meineDaten; // initiale Groesse: 0 meineDaten.push_back(123); // Wert anhaengen meineDaten.pop_back(); // Wert loeschen meineDaten.empty(); // leer? Vorsicht! vector\u003cint\u003e arr(); ist kein Vektor der Länge 0, sondern deklariert eine neue Funktion!\nAlias-Namen für Typen mit typedef und using Syntax: typedef existTyp neuerName; (C, C++)\ntypedef unsigned long uint32; uint32 x, y, z; Im Beispiel ist uint32 ein neuer Name für den existierenden Typ unsigned long, d.h. die Variablen x, y und z sind unsigned long.\nSyntax: using neuerName = existTyp; (C++)\ntypedef unsigned long uint32; // C, C++ using uint32 = unsigned long; // C++11 typedef std::vector\u003cint\u003e foo; // C, C++ using foo = std::vector\u003cint\u003e; // C++11 typedef void (*fp)(int,double); // C, C++ using fp = void (*)(int,double); // C++11 Seit C++11 gibt es das Schlüsselwort using für Alias-Deklarationen (analog zu typedef). Dieses funktioniert im Gegensatz zu typedef auch für Templates mit (teilweise) gebundenen Template-Parametern.\nErinnerungen an C - Vergleich mit C++ Erinnerungen an C - Vergleich mit C++ Expand me… Basisdatentypen char Zeichen (ASCII, 8 Bit bzw. 1 Byte) int Ganze Zahl (16, 32 oder 64 Bit) float Gleitkommazahl (typ. 32 Bit) double Doppelt genaue Gleitkommazahl (typ. 64 Bit) void Ohne/kein Wert bool true, false Außerdem sind Arrays und Pointer mit diesen Typen möglich.\nTypmodifikatoren ändern Bedeutung Vorangestellte Modifikatoren ändern Bedeutung:\nLänge im Speicher\nshort Speicher: halbe Wortlänge long Speicher: doppelte/dreifache Wortlänge Vorzeichen\nsigned mit Vorzeichen (Default bei Zahlen) unsigned ohne Vorzeichen Anwendung auf ganze Zahlen:\nshort und long sind Synonyme für short int und long int long long ist typischerweise eine ganze Zahl mit 8 Byte unsigned char sind Zahlen von 0, ..., 255 (1 Byte) zusätzlich: long double (nur diese Form) Sie können short, long und long long nur für ganze Zahlen (int) nutzen, mit der Ausnahme long double. Dagegen können signed und unsigned sowohl für char als auch für int benutzt werden.\nvgl. en.wikipedia.org/wiki/C_data_types\nGröße eines Datentyps ist maschinenabhängig Der reservierte Speicherbereich und damit auch der Zahlenbereich für einen einfachen Typ in C/C++ ist maschinenabhängig!\nZahlenbereiche für konkrete Implementierung in Header-Files definiert\nlimits.h und float.h: Konstanten INT_MAX, INT_MIN, ...\nAlternativ Herausfinden der Größe in Bytes: Operator sizeof\nSyntax: sizeof(Typ)\nEs gilt in C/C++:\nsizeof(unsigned char) $=$ 1 sizeof(short int) $=$ 2 sizeof(short int) $\\le$ sizeof(int) $\\le$ sizeof(long int) sizeof(float) $\\le$ sizeof(double) $\\le$ sizeof(long double) Hinweis Arrays: sizeof gibt immer die Anzahl der Bytes für einen Typ oder eine Variable zurück. Bei Array ist das nicht unbedingt die Anzahl der Elemente im Array!\nBeispiel:\nchar a[10]; double b[10]; sizeof(a) würde den Wert 10 als Ergebnis liefern, da ein char in C/C++ immer exakt ein Byte benötigt und entsprechend 10 char 10 Byte. sizeof(b) ist maschinenabhängig und liefert die Anzahl der Bytes, die man für die Darstellung von 10 Double-Werten benötigt.\nWenn man die Anzahl der Elemente im Array mit sizeof herausfinden will, muss man den Gesamtwert für das Array noch durch den Speicherbedarf eines Elements teilen, also beispielsweise sizeof(b)/sizeof(b[0]).\n(Beispiele für) Schleifen und Kontrollstrukturen in C/C++ int x=5, y=1; if (x\u003e5) { x++; } else if(y\u003c=1) { y = y-x; } else { y = 2*x; } while (y\u003e0) { y--; } for (x=0; x\u003c10; x++) { y = y*y; } Funktionen in C und C++ Funktionen sind mit Methoden in Java vergleichbar\n=\u003e sind aber unabhängig von Klassen bzw. Objekten\nSyntax:\nRueckgabetyp Funktionsname(Parameterliste) { Anweisungen (Implementierung) } Aufruf: Nennung des Namens (mit Argumenten) im Programmcode\nint x = foo(42); Anmerkung: Unterschied \"Parameter\" und \"Argument\":\nFunktion hat \"Parameter\" in ihrer Parameterliste, auch \"formale Parameter\" genannt Beim Aufruf werden \"Argumente\" übergeben, auch \"aktuelle Parameter\" genannt In der Praxis verwendet man beide Begriffe i.d.R. synonym.\nFunktionen: Deklaration vs. Definition Deklaration: (Funktions-) Prototyp: Festlegen von Signatur (d.h. Funktionsname und Anzahl, Typ, Reihenfolge der Parameter) u. Rückgabetyp\nvoid machWas(int, int); Definition: Implementierung der Funktion\nvoid machWas(int a, int b) { cout \u003c\u003c \"a: \" \u003c\u003c a \u003c\u003c \", b: \" \u003c\u003c b \u003c\u003c endl; } Compiler \"liest\" Quellcode von oben nach unten\nFunktionen müssen (wie alle anderen Symbole auch) vor ihrer Verwendung zumindest deklariert sein, d.h. es muss zumindest ihre Signatur bekannt sein (siehe nächste Folie)\nDeklaration: Variablennamen können weggelassen werden\nDeklaration vs. Definition Deklaration: Macht einen Namen bekannt und legt den Typ der Variablen bzw. die Schnittstelle der Funktionen fest. Definition: Deklaration plus Reservierung von Speicherplatz für die Variable oder Implementierung einer Funktion/Struktur/... Konsole: simplefunction.cpp One Definition Rule (für Funktionen) Jede Funktion darf im gesamten Programm nur einmal definiert sein!\nFunktionen und Parameter Funktionen \"ohne\" Parameter:\nLeere Parameter-Liste[^1] oder Schlüsselwort void\nvoid fkt(); void fkt(void); Funktionen mit Parameter:\nDeklaration: Variablennamen können weggelassen werden Definition: Variablennamen müssen angegeben werden void fkt(int, char); void fkt(int a, char b); void fkt(int a, char b) { ... } Leere Parameterliste in C Wenn eine Funktion keine Parameter hat, können Sie wie in C die Parameterliste entweder einfach leer lassen (int fkt();) oder das Schlüsselwort void nutzen (int fkt(void);).\nBetrachten Sie folgendes Beispiel:\n// Legal in C int wuppie(); // Deklaration: \"Ich verrate Dir nicht, wieviele Parameter wuppie() hat.\" int wuppie(int x) { return x; } // Aufruf mit Argumenten =\u003e ist okay // Fehler in C int fluppie(void); // Deklaration: fluppie() hat KEINE Parameter! int fluppie(int x) { return x; } // Aufruf mit Argumenten =\u003e Compiler-Fehler Wenn Sie eine mit leerer Parameterliste deklarierte Funktion definieren bzw. aufrufen, akzeptiert der C-Compiler dennoch alle übergebenen Parameter. Dies kann zu schwer verständlichen Fehlern führen! Sobald eine Funktion explizit mit dem Schlüsselwort void in der Parameterliste deklariert wird, muss diese dann auch ohne Parameter aufgerufen werden.\n=\u003e Bevorzugen Sie in C die Variante mit dem Schlüsselwort void!\nLeere Parameterliste in C++ Keine Parameter: Leere Liste und Schlüsselwort void gleichwertig\nvoid fkt(); void fkt(void); Defaultparameter in C++ Parameter mit Defaultwerten am Ende der Parameterliste Bei Trennung von Deklaration und Definition: Defaultparameter nur in Deklaration // Deklaration void f(int i, int j=1, int k=2); // Definition void f(int i, int j, int k) { ... } Überladen von Funktionen Funktionen im gleichen Gültigkeitsbereich können überladen werden Zu beachten: Funktionsname identisch Signatur (Anzahl, Typen der Parameter) muss unterschiedlich sein Rückgabewert darf variieren =\u003e Warnung: Überladene Funktionen sollten gleichartige Operationen für unterschiedliche Datentypen bereitstellen!\nProbleme beim Überladen von Funktionen Defaultparameter\nint maximum(int, int); int maximum(int, int, int=10); Identische Signatur, Unterschied nur im Rückgabewert\nint maximum(int, int); double maximum(int, int); Überladen nur für Funktionen des selben Gültigkeitsbereichs!\n#include \u003ciostream\u003e using namespace std; void f(char c) { cout \u003c\u003c \"f(char): \" \u003c\u003c c \u003c\u003c endl; } void f(int i) { cout \u003c\u003c \"f(int): \" \u003c\u003c i \u003c\u003c endl; } int main() { void f(int i); // f(char) nicht mehr sichtbar! f('a'); return 0; } Parameterübergabe in C/C++: Call-by-Value int add_5(int x) { x += 5; return x; } int main() { int erg, i=0; erg = add_5(i); } Aufrufer-Sicht i erg +-----+ +-----+ | | | | +--+--+ +--^--+ | | | | --------------+-----------------------+----- Kopie bei | Kopie | Aufruf | bei | | return | +--v--+ | | +--------------------+ +-----+ x Funktionssicht Default in C/C++ ist die call-by-value Semantik: Argumente werden bei Übergabe kopiert Ergebniswerte werden bei Rückgabe kopiert Folgen: Keine Seiteneffekte durch Verändern von übergebenen Strukturen Negative Auswirkungen auf Laufzeit bei großen Daten Ausnahme: Übergabe von C++-Referenzen oder Pointern (wobei Pointer streng genommen auch kopiert werden, also per call-by-value übergeben werden ...)\nUnterschiedliche Variablenarten Lokale Variablen (\"automatische Variablen\") int b = 1; void f() { int b = 42; } int main() { int b = 3; { int b = 7; } } Innerhalb einer Funktion (oder Blockes) definierte Variablen\nGilt auch für Variablen aus Parameterliste\nÜberdecken globale Variablen gleichen Namens\nSichtbarkeit:\nAußerhalb der Funktion/Blockes nicht zugreifbar Beim Betreten der Funktion Reservierung von Speicherplatz für lokale Variablen Dieser wird beim Verlassen des Blockes/Funktion automatisch wieder freigegeben Namen sind nur nach Deklaration und innerhalb des Blockes, in dem sie deklariert wurden, gültig Namen sind auch gültig für innerhalb des Blockes neu angelegte innere Blöcke Software Engineering: Vermeiden Sie lokale Namen, die Namen aus einem äußeren Scope überdecken!\n=\u003e Werden auch als automatische Variablen bezeichnet\nGlobale Variablen (\"externe Variablen\") /* ======== Datei main.cpp (einzeln kompilierbar) ======== */ int main() { extern int global; // Deklaration } int global; // Definition /* ======== Datei foo.cpp (einzeln kompilierbar) ======== */ extern int global; // Deklaration void foo() { global = 45; } Globale Variablen: Außerhalb jeder Funktion definierte Variablen Globale Variablen gelten in allen Teilen des Programms Auch in anderen Dateien! =\u003e müssen bei Nutzung in Funktionen als extern deklariert werden Existieren die gesamte Programmlebensdauer über =\u003e Werden auch als externe Variablen bezeichnet\nDie Dateien sind einzeln kompilierbar (extern sagt dem Compiler, dass die Variable woanders definiert ist) =\u003e erst der Linker löst das auf.\nHinweis: Bei globalen Konstanten in C++ brauchen Sie zusätzlich auch bei der Definition ein \"extern\", da die Konstante sonst nur in ihrer Datei sichtbar ist.\nStatische lokale Variablen void foo() { static int x = 42; x++; } int main() { foo(); foo(); foo(); } Lokale Variablen mit \"Gedächtnis\": Definition mit dem vorangestellten Schlüsselwort \"static\"\nstatic int callCount; Eigenschaften:\nWert bleibt für die folgenden Funktionsaufrufe erhalten Wert kann in der Funktion verändert werden Dennoch: lokale Variable, d.h. von außen nicht sichtbar/gültig Hinweis: static für globale Variablen bedeutet etwas anderes! (s.u. \"Sichtbarkeit\")\nInitialisierung von Variablen (Automatische) Initialisierung von Variablen hängt von ihrer Speicherklasse ab!\nAutomatisch Werden nicht automatisch initialisiert (!) Bei vorgegebenem Wert ab Aufruf der Funktion Extern Mit dem Wert 0 oder vorgegebenem Wert Bereits vor Programmstart (im Code enthalten) Statisch Mit dem Wert 0 oder vorgegebenem Wert Ab erstem Aufruf der Funktion Sichtbarkeit globaler Variablen (und Funktionen) beschränken Beschränkung der Gültigkeit von globalen Variablen auf die Datei, wo sie definiert sind: Schlüsselwort static werden (weiterhin) automatisch mit 0 initialisiert sind nun nur in der Datei sichtbar/gültig, wo sie definiert sind dient zur Vermeidung von Namenskonflikten bei globalen Variablen Sichtbarkeitsbeschränkung gilt auch für Funktionen static für globale Variablen beschränkt deren Sichtbarkeit auf die Datei, wo sie definiert sind. D.h. man kann diese dann nicht in einer anderen Datei nutzen, nicht mal mit extern ...\nstatic für Funktionen beschränkt deren Sichtbarkeit ebenfalls auf die Datei, wo sie definiert sind. Man kann sie dann nur in anderen Funktionen, die ebenfalls in der selben Datei definiert werden, nutzen. In anderen Dateien sind die static Funktionen nicht sichtbar. D.h. es macht auch keinen Sinn, sie in einer Header-Datei zu deklarieren! (In der Praxis liefert der gcc dann sogar einen Fehler!). Das ist mit private Methoden vergleichbar.\nGlobale Konstanten In C funktionieren globale Konstanten wie globale Variablen Definition in einer Übersetzungseinheit ohne \"extern\"\n=\u003e Definition als \"extern\" wird in C mit einer Warnung quittiert!\nNutzung in anderen Übersetzungseinheiten durch (erneute) Deklaration als \"extern\"\nBeispiel:\n/* ======== Datei main.c ======== */ const int PI=123; // Definition OHNE \"extern\" (C) int main() { fkt_a1(); int x = PI; ... } /* ======== Datei a.c ======== */ extern const int PI; // (erneute) Deklaration mit \"extern\" void fkt_a1() { int x = PI; ... } In C++ sind globale Konstanten per Default nur in ihrer Definitionsdatei sichtbar! Abhilfe: Definieren und Deklarieren mit extern\nBeispiel:\n/* ======== Datei main.cpp ======== */ extern const int PI=123; // Definition MIT \"extern\" (C++) int main() { fkt_a1(); int x = PI; ... } /* ======== Datei a.cpp ======== */ extern const int PI; // (erneute) Deklaration mit \"extern\" void fkt_a1() { int x = PI; ... } Alternativ: In beiden Sprachen Konstanten vorwärts deklarieren Folgende Definition und (Vorwärts-) Deklaration der Konstanten PI funktioniert sowohl in C als auch in C++:\n/* ======== Datei main.c ======== */ extern const int PI; // (Vorwärts-) Deklaration mit \"extern\" const int PI=123; // Definition OHNE \"extern\" int main() { fkt_a1(); int x = PI; ... } /* ======== Datei a.c ======== */ extern const int PI; // (erneute) Deklaration mit \"extern\" void fkt_a1() { int x = PI; ... } Automatisieren der Buildvorgänge: GNU Make Makefile: Textdatei mit Regeln für das Programm make Abläufe automatisieren: Kompilieren, testen, Pakete bauen, aufräumen, ... Java: ant, C/C++: make Achtung: Verschiedene Make-Dialekte! Wir nutzen GNU Make! # Kommentar Ziel1: AbhaengigkeitenListe1 Aktionen1 Ziel2: AbhaengigkeitenListe2 Aktionen2 # ... und so weiter :-) # ACHTUNG: # Vor den Aktionen \u003cTAB\u003e benutzen, keine Leerzeichen!!! # Vorsicht mit Editor-Einstellungen! Bedeutung: Um das Ziel Ziel1 zu erzeugen, müssen alle Abhängigkeiten der Liste AbhaengigkeitenListe1 erfüllt sein. Dann werden die Aktionen in Aktionen1 durchgeführt, um Ziel1 zu erzeugen. Aber nur, falls das Ziel Ziel1 nicht existiert oder veraltet ist!\nFalls die Abhängigkeiten nicht erfüllt sind, wird nach Regeln gesucht, um diese zu erzeugen. Das bedeutet, dass u.U. zunächst weitere Targets \"gebaut\" werden, bevor die Aktionenliste ausgeführt wird.\nDie Ziele und Abhängigkeiten sind i.d.R. Dateien (müssen es aber nicht sein).\nMakefiles: Fiktives Beispiel Annahme: Projekt besteht aus der Datei main.cpp, daraus soll das Programm \"tollesProgramm\" erzeugt werden\nPassendes Makefile:\nCXXFLAGS = -Wall .PHONY: all all: tollesProgramm tollesProgramm: main.o $(CXX) $(LDFLAGS) $\u003c $(LDLIBS) -o $@ %.o: %.cpp $(CXX) $(CXXFLAGS) -c $\u003c -o $@ .PHONY: clean clean: rm -rf tollesProgramm *.o *.~ Bedeutung: Um das Ziel all zu erzeugen, muss die Abhängigkeit tollesProgramm erfüllt sein. Beachten Sie, dass im Beispiel all kein Dateiname ist, tollesProgramm dagegen schon.\nUm tollesProgramm zu erzeugen, muss die Datei main.o vorhanden sein. Falls sie es nicht ist, wird sie mit Hilfe des dritten Targets erzeugt. Das % ist dabei ein Patternmatcher, d.h. wenn nach einem main.o gesucht ist, matcht %.o (das % bindet sich dabei an \"main\") und auf der rechten Seite des Targets steht als Abhängigkeit main.cpp.\nDie Variablen CXX, CXXFLAGS, LDFLAGS und LDLIBS sind vordefinierte Variablen:\nCXX: C++-Compiler, Default: g++ CXXFLAGS Extra Flags für den C++-Compiler (nur für Kompilieren) LDFLAGS: Extra Flags, die für das Linken genutzt werden (Beispiel: -L.; nicht -lm) LDLIBS: Bibliotheken, die für das Linken genutzt werden (Beispiel: -lm -lfoo; nicht -L.) Die Variablen $\u003c, $^ und $@ lösen auf das Ziel bzw. die Abhängigkeiten eines Targets auf:\n$\u003c =\u003e gibt die erste Abhängigkeit an $^ =\u003e gibt alle Abhängigkeiten an $@ =\u003e gibt das Ziel an Falls die Datei tollesProgramm nicht existiert oder aber älter ist als main.o, wird die Regel des Targets tollesProgramm ausgeführt, um die Datei tollesProgramm zu erzeugen: g++ main.o -o tollesProgramm.\nHinweis: Das Beispiel entspricht den minimalen Kenntnissen, die Sie über Make haben müssen.\nMakefiles: Typische Aufrufe make Sucht nach Datei mit dem Namen \"GNUmakefile\", \"makefile\" oder \"Makefile\" und erzeugt das erste Ziel in der Datei\nKonvention: Das erste Ziel hat den Namen all\nmake -f \u003cdatei\u003e Sucht die Datei mit dem angegebenen Namen, erzeugt das erste Ziel in der Datei\nmake -f \u003cdatei\u003e \u003cziel\u003e Sucht die Datei mit dem angegebenen Namen, erzeugt das Ziel \u003cziel\u003e\nmake \u003cziel\u003e Sucht nach Datei mit dem Namen \"GNUmakefile\", \"makefile\" oder \"Makefile\" und erzeugt das Ziel \u003cziel\u003e\nWrap-Up C/C++ sind enge Verwandte: kompilierte Sprachen, C++ fügt OO hinzu\nFunktionsweise einfachster Make-Files\nWichtigste Unterschiede zu Java\nKontrollfluss wie in Java Basisdatentypen vorhanden Typ-Modifikatoren zur Steuerung des Speicherbedarfs/Wertebereich Integer können im booleschen Kontext ausgewertet werden Operator sizeof zur Bestimmung des Speicherbedarfs Alias-Namen für existierende Typen mit typedef definierbar Funktionen mit Default-Parametern und Überladung",
    "description": "Warum? C++ erlaubt ressourcenschonende Programmierung Objektorientierter \"Aufsatz\" auf C Verbreitet bei hardwarenaher und/oder rechenintensiver Software Sie werden C++ im Modul \"Computergrafik\" brauchen!\nGeschichte\n1971-73: Ritchie entwickelt die Sprache C Ab 1979: Entwicklung von C++ durch Bjarne Stroustrup bei AT\u0026T Erweiterung der prozeduralen Sprache C Ursprünglich \"C mit Klassen\", später \"C++\" (Inkrement-Operator) Bis heute: Fortlaufende Erweiterungen: alle 3 Jahre neuer Standard (C++11, C++14, ...) C/C++ vs. Java Java: Fokus auf Sicherheit und Robustheit Diverse Sicherheitschecks durch Compiler und VM (zb. Array-Zugriff) Speicherverwaltung (Garbage Collection), kein Speicherzugriff über Pointer Automatische Initialisierung von Variablen C/C++: Fokus auf Effizienz (Speicher, Laufzeit) für korrekte Programme Vergleichsweise schwache Sicherheitschecks durch Compiler, keine VM (d.h. keine Prüfung von Array-Indizes u.a.) Keine Garbage Collection, Programmierer hat direkten Zugriff auf Speicher Keine automatische Initialisierung von Variablen Hello World! /* * HelloWorld.cpp (g++ -Wall HelloWorld.cpp) */ #include \u003ccstdio\u003e #include \u003ciostream\u003e #include \u003ccstdlib\u003e using namespace std; int main() { printf(\"Hello World from C++ :-)\\n\"); cout \u003c\u003c \"Hello World from C++ :-)\" \u003c\u003c endl; std::cout \u003c\u003c \"Hello World from C++ :-)\" \u003c\u003c std::endl; return EXIT_SUCCESS; } Beobachtungen Jedes (ausführbare) C++-Programm hat genau eine main()-Funktion. Die main()-Funktion ist keine Methode einer Klasse: In C/C++ gibt es Funktionen auch außerhalb von Klassen.",
    "tags": [],
    "title": "Einführung in C++ (Erinnerungen an C)",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/99-languages/cpp0-basics.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Programmiersprachen",
    "content": "Virtueller Speicher +-----------------------------------------+ | Text | 0x0000 | | | |-----------------------------------------| | | Heap (Data) | | | | | |--------------------+--------------------| | | | | | | v | | | | | | | v | ^ | | | | |--------------------+--------------------| | | | Stack | +-----------------------------------------+ Kernel weist jedem Prozess seinen eigenen virtuellen Speicher zu Linearer Adressbereich, beginnend mit Adresse 0 bis zu einer maximalen Adresse Verwaltung durch MMU (Memory Management Unit) MMU bildet logische Adressen aus virtuellem Speicher auf den physikalischen Speicher ab Transparent für den Prozess Segmente des virtuellen Speichers: Text (read-only) Programm Code Konstanten, String Literale zusätzlich (nicht in Abbildung dargestellt):\nBereich initialisierter Daten (globale und static Variablen (explizit initialisiert)) Bereich uninitialisierter Daten (globale und static Variablen (uninitialisiert) =\u003e Wert 0) Segmente des virtuellen Speichers: Stack Dynamisch wachsend und schrumpfend Stackframe je Funktionsaufruf: Lokale Variablen (\"automatische\" Variablen) Argumente und Return-Werte Automatische Pflege Nach Funktionsrückkehr wird der Stackpointer (\"Top of Stack\") weiter gesetzt Dadurch \"Bereinigung\": Speicher der lokalen Variablen wird freigegeben Segmente des virtuellen Speichers: Data (Heap) Dynamisch wachsend und schrumpfend Bereich für dynamischen Speicher (Allokation während der Laufzeit) Zugriff und Verwaltung aus laufendem Programm =\u003e Pointer malloc()/calloc()/free() (C) new/delete (C++) typischerweise Pointer KEINE automatische Pflege - Programmierer ist selbst verantwortlich! Konzept eines Pointers int i = 99; int *iptr; iptr = \u0026i; /* Wert von iptr ist gleich Adresse von i */ *iptr = 2; /* Deferenzierung von iptr =\u003e Veränderung von i */ Variable Speicheraddresse Inhalt | | +----------+ i 10125 | 99 | \u003c--+ +----------+ | | | | .... .... | | | | +----------+ | iptr 27890 | 10125 | ---+ +----------+ | | Pointer sind Variablen haben Namen und Wert können mit Operatoren verändert werden sind einer Speicheradresse im virtuellen Speicher zugeordnet Im Beispiel:\nVariable i: Name: \"i\" Wert: 99 Speicherzelle (Adresse): 10125 Variable iptr: Name: \"iptr\" Wert: 10125 Speicherzelle (Adresse): 27890 Pointer sind besondere Variablen Der Wert eines Pointers wird als Adresse im Speicher behandelt\nDer Wert von iptr ist nicht ein beliebiger Integer, sondern eine Adresse. In diesem Fall handelt es sich um die Adresse im virtuellen Speicher, wo die Variable i abgelegt ist.\nWirkung/Interpretation: Variable iptr \"zeigt\" auf die Adresse von Variable i.\nPointer und Adressen (Syntax) Deklaration\nTyp * Name; Zuweisung einer Adresse über den \u0026-Operator:\nint i = 99; int *iptr; iptr = \u0026i; /* Wert von iptr ist gleich Adresse von i */ iptr ist ein Pointer auf eine (beliebige) Speicherzelle mit Inhalt vom Typ int\nNach Zuweisung: iptr ist ein Pointer auf die Speicherzelle der Variablen i\nDereferenzierung: Zugriff auf Ziel Dereferenzierung mit *:\nint i = 99; int *iptr; iptr = \u0026i; *iptr = 2; // Zugriff auf verwiesene Speicherzelle i Pointer: Schreibweisen Position des * zwischen Typ und Name beliebig\n/* aequivalente Schreibweisen */ int* iptr; int * iptr; int *iptr; /* Vorsicht Mehrfachdeklaration */ int* iptr, ptr2; /* ptr2 ist nur ein int! */ Dereferenzierung von Pointern auf Klassen/Structs: Operator -\u003e\n/* aequivalente Schreibweisen */ (*iptr).attribut; iptr-\u003eattribut; Pointer: Zuweisungen an andere Pointer int i=99, *iptr, *ptr2; iptr = \u0026i; ptr2 = iptr; *ptr2 = 2; Jetzt zeigen zwei Pointer auf die Speicherzelle von Variable i: iptr (wegen iptr = \u0026i), und weil der Wert von iptr in ptr2 kopiert wurde (ptr2 = iptr), zeigt nun auch ptr2 auf i.\nDer Wert von iptr ist die Adresse von i. Wenn dieser Wert kopiert oder zugewiesen wird, ändert sich an dieser Adresse nichts. ptr2 bekommt diesen Wert zugewiesen, d.h. bei einer Dereferenzierung von ptr2 würde auf die Adresse von i zugriffen werden und dort gelesen/geschrieben werden.\nPointer und Scopes Nicht auf Variablen außerhalb ihres Scopes zugreifen!\nint i=9; int *ip = \u0026i; *ip = 8; { /* neuer Block */ int j=7; ip = \u0026j; } *ip = 5; /* AUTSCH!!! */ int* murks() { int i=99; return \u0026i; /* AUTSCH!!! */ } Hotelzimmer-Analogie Wenn Sie in ein Hotel einchecken, bekommen Sie den Schlüssel zu Ihrem Zimmer Pointer == Schlüssel Variable auf die Pointer zeigt == Zimmer Wenn Sie auschecken, geben Sie normalerweise Ihr Zimmer auf und den Schlüssel ab Pointer wird ungültig Variable wird ungültig Wenn Sie beim Auschecken den Schlüssel nicht abgeben, gehört das Zimmer dennoch nicht mehr Ihnen Sie haben noch den Pointer Die Variable, auf die der Pointer zeigt, ist ungültig Wenn Sie jetzt auf das Zimmer gehen, kommen Sie (evtl.) noch rein Evtl. ist das Zimmer noch nicht wieder belegt, und Sie finden Ihr vergessenes Handy Bei Dereferenzierung erhalten Sie noch den alten Wert der Variablen Evtl. wurde das Zimmer bereits wieder vergeben =\u003e Sie \"brechen\" bei einem Fremden ein! Bei Dereferenzierung greifen Sie auf \"fremde\" Variablen (Speicherbereiche) zu! Pointer und Initialisierung Pointer werden vom Compiler nicht initialisiert!\nZeigen ohne explizite Initialisierung auf zufällige Adresse Dereferenzierung uninitialisierter Pointer problematisch Explizite Null-Pointer:\nWert 0 zuweisen Besser: Symbolische Konstante NULL aus stdio.h bzw. cstdio bzw. in C++ nullptr Speicherverwaltung C: Funktionen zur Verwaltung dynamischen Speichers: malloc(), free(), ... (in \u003cstdlib.h\u003e)\nvoid* malloc(size_t size) Alloziert size Bytes auf dem Heap und liefert Adresse zurück Pointer auf void, da Typ unbekannt - vor Nutzung auf korrekten Typ umcasten Im Fehlerfall wird ein Null-Pointer zurückgeliefert: NULL Achtung: Speicher ist nicht initialisiert! int *p = (int*) malloc(sizeof(int)); int *pa = (int*) malloc(4*sizeof(int)); free(p); free(pa); C++: Operatoren: new und delete\nDirekte Angabe des Zieltyps Rückgabe eines Pointers auf diesen Typ Exception, wenn kein Speicher verfügbar Form mit []-Operator für Arrays Mit new allozierter Speicher muss mit delete freigegeben werden Mit new [] allozierter Speicher muss mit delete [] freigegeben werden int *p = new int; int *pa = new int[4]; delete p; delete [] pa; Speicher allozieren: Standardidiom In C müssen Sie die Rückgabe von malloc prüfen:\nint *i, *x; i = (int *) malloc(sizeof(int)); x = (int *) malloc(sizeof(*x)); /* Stern wichtig */ if (!i) { /* Fehlerbehandlung */ } else { /* mach was */ } In C++ bekommen Sie eine Exception, falls new nicht erfolgreich war:\nint *i; try { i = new int; /* mach was */ } catch (...) { /* Fehlerbehandlung */ } Hinweis: Pointer-Variablen i und x liegen auf Stack, angeforderter Speicher im Heap!\nPointer und Typen Typ eines Zeigers relevant, wird vom Compiler geprüft Zuweisung ohne expliziten Cast nur an allgemeinere Typen/Oberklassen Jeder Zeiger auf Typ T kann automatisch zum void-Pointer konvertiert werden\nFür Zuweisung von void-Pointern an Pointer auf Typ T expliziter Cast nach T* nötig (siehe auch nachfolgenden Hinweis zu C11)\nchar *cp; void *vp; vp = cp; /* OK */ cp = vp; /* problematisch */ cp = (char *) vp; /* OK */ Fallstricke dynamischer Speicherverwaltung Nur new und delete kombinieren bzw. malloc und free delete darf nur auf mit new erzeugte Objekte angewendet werden\nVorsicht bei Pointern auf Stack-Variablen! NIE mischen mit malloc()/calloc()/free()! int *p = (int *) malloc(sizeof(int)); delete p; // FEHLER! Absturzgefahr delete[] genau nur bei new[] delete[] darf nur auf mit new[] erzeugte Objekte angewendet werden (und muss dort auch angewendet werden)\ndelete auf mit new[] erzeugtes Array würde nur erstes Element freigeben!\nVorsicht mit Pointern auf lokale Variablen Funktioniert technisch, ist aber gefährlich:\nint* murks() { int i=99; return \u0026i; /* SO NICHT: Pointer auf lokale Variable! */ } Etwas besser:\nint* wenigerMurks() { int *p = (int *) malloc(sizeof(int)); /* neuer Speicher */ *p=99; return p; /* das geht */ } Warum nur \"etwas besser\"? Jetzt haben Sie aber ein neues Problem: Der Aufrufer der Funktion muss wissen, dass diese Speicher alloziert und muss sich selbst um die Freigabe kümmern. Dies ist unschön, da die Allokation und Freigabe in unterschiedlicher Verantwortung liegen! Dadurch können sehr schnell Fehler passieren.\nBesser wäre, wenn der Aufrufer einen Pointer übergibt, mit dem dann in der Funktion gearbeitet wird. Dann liegt die Verantwortung für die Erstellung und Freigabe des Pointers komplett in der Hand des Aufrufers.\nMemory Leaks Pointer-Variablen unterliegen den Gültigkeitsregeln für Variablen\nMit malloc() reservierter Speicher existiert bis Programmende\n{ int *i; i = (int *) malloc(sizeof(*i)); *i = 99; } /* hier existiert die Variable i nicht mehr */ /* aber der Speicher auf dem Heap bleibt belegt */ /* ist aber nicht mehr zugreifbar -\u003e SPEICHERLOCH! */ Double Free und Stale Pointer free() darf nur einmal pro Objekt aufgerufen werden Hintergrund: Intern wird eine Freispeicherliste verwaltet Nach free() ist der Zeiger undefiniert: Zeigt immer noch in den Heap (alte Adresse!) Ist nicht gleich NULL oder 0 Zugriff ist möglich, aber gefährlich: Speicher kann wieder vergeben und überschrieben werden (Hotelzimmer-Analogie) Mehrere Pointer auf ein Objekt: Einmal free() reicht! Die anderen Pointer dürfen anschließend aber auch nicht mehr dereferenziert werden (stale/dangling pointer) Beispiel Stale Pointer int *i, *k; i = (int *) malloc(sizeof(*i)); k = i; free(i); free(i); /* EINMAL reicht! */ *k = 42; /* Speicher ist bereits frei - stale pointer */ free(k); /* Speicher ist bereits frei - double free */ *i = 99; /* Speicher ist bereits frei */ Anmerkung: Anwendung auf NULL-Pointer bewirkt nichts und ist unschädlich\nDereferenzieren von \"Bad Pointern\" Der klassische Scanf-Bug :)\nint i; scanf(\"%d\", i); Show Me Tipp: i ist kein Pointer :)\nAuslesen von nicht-initialisiertem Speicher Wenn Programmierer denken, dass irgendwer den Heap zwischendurch immer mal wieder auf 0 setzt ...\n/* return y = Ax */ int *matvec(int **A, int *x, int N) { int *y = malloc(N*sizeof(int)); for (int i=0; i\u003cN; i++) { for (int j=0; j\u003cN; j++) { y[i] += A[i][j] * x[j]; } } return y; } Show Me Tipp: y[i] += ... setzt sinnvolle Werte in y[i] voraus ...\nÜberschreiben von Speicher I Allokation von falschen Größen\nint *p; p = malloc(N*sizeof(int)); for (int i=0; i\u003cN; i++) { p[i] = malloc(M*sizeof(int)); } Show Me Tipp: Jedes p[i] kann einen int speichern, bekommt aber einen Pointer zugewiesen (könnte deutlich breiter im Speicher sein als ein int) ...\nÜberschreiben von Speicher II Indexberechnung kaputt, sogenannte \"off-by-one-errors\"\nint **p; p = malloc(N*sizeof(int)); for (int i=0; i\u003c=N; i++) { p[i] = malloc(M*sizeof(int)); } Show Me Tipp: Hier läuft i um einen Platz zu weit ...\nÜberschreiben von Speicher III Einlesen von Strings, zu kleine Buffer\nchar s[8]; gets(s); Show Me Tipp: Wenn hier mehr als 7 Zeichen eingegeben werden, gibt es Probleme :)\nÜberschreiben von Speicher IV Pointerarithmetik falsch verstanden\nint *search(int *p, int val) { while (*p \u0026\u0026 *p != val) p += sizeof(int); return p; } Show Me Tipp: Jeder Pointer hat einen Typ, und der Ausdruck \"Pointer + 1\" rutscht um so viele Bytes im Speicher weiter, wie der Typ breit ist. D.h. mit einem \"Pointer + 1\" gelangt man zum nächsten Element, während der obige Ausdruck p += sizeof(int); um sizeof(int) Elemente weiterspringt!\nPointer und Arrays Ein Array-Name ist wie ein konstanter Pointer auf Array-Anfang: a[i] == *(a+i)\nEin Array-Name ist nur ein Label, welches der Adresse des ersten Array-Elements entspricht. Die Wirkung ist entsprechend die eines konstanten Pointers auf den Array-Anfang.\n=\u003e Der Compiler übersetzt Array-Zugriffe per Indexoperator in Pointerarithmetik: a[i] wird zu *(a+i) ...\nVgl. auch die Diskussion in eli.thegreenplace.net/2009/10/21/are-pointers-and-arrays-equivalent-in-c\nchar a[6], c, *cp; \u0026a[0] == a; cp = a; c = a[5]; c = *(a+5); c = *(cp+5); c = cp[5]; a = cp; /* FEHLER */ a = \u0026c; /* FEHLER */ Iteration durch Arrays (Varianten) int a[10], *pa=a; for (int k=0; k\u003c10; k++) /* Iteration, Variante 1 */ printf(\"%d \", a[k]); for (int k=0; k\u003c10; k++) /* Iteration, Variante 2 */ printf(\"%d \", *(a+k)); pa = a; for (int k=0; k\u003c10; k++) /* Iteration, Variante 3 */ printf(\"%d \", *pa++); /* Iteration, KEINE Variante */ for (int k=0; k\u003c10; k++) printf(\"%d \", *a++); /* DAS GEHT NICHT */ *pa++: Operator ++ hat Vorrang vor *, ist aber die Postfix-Variante. D.h. ++ wirkt auf pa (und nicht auf *pa), aber zunächst wird für die Ausgabe *pa ausgewertet ...\n*a++ ist nicht erlaubt, weil dadurch der Name des Arrays (== Adresse des ersten Array-Elements == konstanter Zeiger auf den Anfang des Arrays) verändert würde.\nArray-Namen sind wie konstante Pointer Array-Namen können NICHT umgebogen werden!\nint a[], *pa=a, k; /* erlaubt */ a + k; pa++; /* VERBOTEN */ a++; Selbsttest: Was bedeutet was, was ist erlaubt/nicht erlaubt, was kommt raus? Warum? int a[10], *pa, *pb, x; pa = a; pb = (int*) malloc(sizeof(int)); x = a[1]; x = *(a+1); x = *(a++); x = pa[1]; x = *(pa+1); x = *(pa++); x = pb[1]; x = *(pb+1); x = *(pb++); =\u003e Arrays können wie konstante Pointer behandelt werden.\n=\u003e Pointer dürfen nicht immer wie Arrays behandelt werden! (Syntaktisch zulässig, semantisch normalerweise nicht!)\nPointerarithmetik: Typen beachten Pointer zeigen auf Objekte mit einem bestimmten Typ Typen haben unterschiedliche Speicherbreite Inkrementierung/Dekrementierung: Pointer zeigt nicht auf nächste Speicheradresse, sondern auf die Adresse des nächsten Werts! double d[10]; double *d1 = \u0026d[2]; double *d2 = d1; d2++; printf(\"%ld\\n\", d2-d1); // ergibt 1 printf(\"%ld\\n\", (long)d2 - (long)d1); // double -\u003e zB. 8 Bytes printf(\"%ld\\n\", sizeof(d1)); // Breite Pointervariable printf(\"%ld\\n\", sizeof(*d1)); // Breite Pointerdatentyp Referenzen in C++ Typ \u0026 Name = Objekt;\nint i=2; int j=9; int \u0026r=i; // Referenz: neuer Name fuer i r=10; // aendert i: i==10 r=j; // aendert i: i==9 int \u0026s=r; // aequivalent zu int \u0026s = i; Referenzen bilden Alias-Namen int i = 99; int *iptr = \u0026i; int \u0026iref = i; // Referenz: neuer Name fuer i Variable Speicheraddresse Inhalt | | +----------+ i, iref 10125 | 99 | \u003c--+ +----------+ | | | | .... .... | | | | +----------+ | iptr 27890 | 10125 | ---+ +----------+ | | Referenz bildet Alias-Namen für ein Objekt Objekt hat damit mehrere Namen, über die es ansprechbar ist Referenzen in C++ mit Hilfe des \u0026-Operators deklarieren Eigenschaften von Referenzen in C++ Referenzen müssen bei Deklaration initialisiert werden\nReferenzen können nicht um-assigned werden\nReferenzen brauchen keinen eigenen Speicherplatz\nVorsicht bei gleichzeitiger Deklaration mehrerer Referenzen:\nint i=2; int j=9; int\u0026 r=i, s=j; // SO NICHT!!! int \u0026r=i, \u0026s=j; // korrekt Referenzen als Funktionsparameter Signatur:\nvoid fkt(int\u0026, char); void fkt(int \u0026a, char b); // a per Referenz Aufruf: ganz normal (ohne extra \u0026) ...\nint x=3; char y='a'; fkt(x, y); // x per Referenz Im Beispiel werden die Variablen x und y an die Funktion fkt übergeben. Der erste Parameter wird per Referenz (call-by-reference), der zweite per Kopie (call-by-value) übergeben.\nDer Funktionsparameter a bindet sich an x, ist eine Referenz auf/für x - jeder Zugriff auf a ist wie ein Zugriff auf x. Änderungen von a sind also Änderungen von x.\nDer zweite Parameter bindet sich an den Wert von y, d.h. b hat den Wert 'a'. Zwar kann auch b verändert werden, das hat dann aber nur Auswirkungen innerhalb der Funktion und nicht auf die Variable y im äußeren Scope.\nCall-by-Reference Semantik in C++ Variante A: Pointer (C und C++) Mit Hilfe von Pointern lässt sich die Call-by-Reference Semantik in C und in C++ simulieren.\nBei der Übergabe eines Pointers wird der Wert des Pointers kopiert (call-by-value!). Im Inneren der Funktion kann diese Adresse dereferenziert werden und so auf das außerhalb der Funktion \"lebende\" Objekt zugegriffen werden. Damit bekommt man in der Wirkung call-by-reference.\nvoid add_5(int *x) { *x += 5; } int main() { int i=0, *ip=\u0026i; add_5(ip); add_5(\u0026i); } Pointer wird nach wie vor per call-by-value übergeben: Wert wird bei Übergabe kopiert (hier Adresse von i) Kopierter Wert ist immer noch ein Pointer (hier Pointer auf i, da Adresse von i) Dereferenzierung des kopierten Pointers: Zugriff auf das Original-Objekt (hier i) Variante B: Referenzen (nur C++) Referenzen müssen bei der Deklaration initialisiert werden und binden sich an das dabei genutzte Objekt. Sie stellen letztlich lediglich einen neuen Namen für das Objekt dar.\nBei der Übergabe von Variablen an Referenz-Parameter einer Funktion binden sich diese Parameter an die übergebenen Objekte. Jeder Zugriff innerhalb der Funktion auf einen Referenz-Parameter bewirken einen Zugriff auf das ursprüngliche Objekt.\nint add_5(int \u0026x) { x += 5; return x; } int main() { int i=0, erg; erg = add_5(i); } Funktionsparameter x ist eine Referenz Bei Aufruf der Funktion wird dieser Parameter initialisiert - die Referenz x bindet sich im Beispiel an die Variable i Zugriffe auf x in der Funktion sind also Zugriffe auf das Original-Objekt i - x += 5 ist nichts anderes als i += 5 Bei weiteren Aufrufen wird x dann neu gebunden Call-by-Reference: const Nachteil bei Call-by-Reference:\nÜbergebenes Objekt könnte durch die Funktion (unbeabsichtigt) verändert werden\nAbhilfe: Deklaration der Parameter als konstant (Schlüsselwort const):\nvoid fkt(const int\u0026, char); void fkt(const int \u0026a, char b); // a wird per Referenz uebergeben, darf aber in der Funktion nicht veraendert werden =\u003e const-heit ist Bestandteil der Signatur!\nArbeiten Sie (wo möglich/sinnvoll) mit (konstanten) Referenzen!\nRückgabe von Werten per Referenz Normalerweise per call-by-value (Kopie) Mit Referenzen oder Pointern auch als call-by-reference int \u0026fkt1(const int \u0026, const char *); int *fkt2(const int \u0026, const char *); Vorsicht mit lokalen Variablen (Gültigkeit)!\nint \u0026fkt1(const int \u0026i, const char *j) { int erg = i+1; return erg; // Referenz auf lokale Variable! } int *fkt2(const int \u0026i, const char *j) { int erg = i+2; return \u0026erg; // Pointer auf lokale Variable! } int main() { int \u0026x = fkt1(2, \"a\"); // AUTSCH!!! int *y = fkt2(2, \"b\"); // AUTSCH!!! int z = fkt1(2, \"c\"); // OK } Die Zuweisung int \u0026x = fkt1(2, \"a\"); ist syntaktisch erlaubt. Semantisch aber nicht: Die Referenz x bindet sich an das zurückgelieferte lokale erg - dieses existiert aber nicht mehr, da der Scope von erg beendet ist ...\n=\u003e Nur Pointer auf Speicher zurückliefern, der nach Beendigung des Funtionsaufrufes noch existiert! (Dies könnte beispielsweise Speicher aus malloc oder new oder ein Pointer auf das eigene Objekt (*this) sein.)\nDie Zuweisung int *y = fkt2(2, \"b\"); ist syntaktisch erlaubt. Semantisch aber nicht: Der Pointer y übernimmt die zurückgelieferte Adresse des lokalen erg - dieses existiert aber nicht mehr, da der Scope von erg beendet ist ...\n=\u003e Nur Referenzen zurückliefern, die nach Beendigung des Funtionsaufrufes noch gültig sind! (Dies könnten beispielsweise Referenz-Inputparameter oder eine Referenz auf das eigene Objekt (*this) sein.)\nDie Zuweisung int z = fkt1(2, \"c\"); ist unbedenklich, da z eine normale Integervariable ist und hier das übliche Kopieren der Rückgabe von ftk1 in die Variable stattfindet.\nDiskussion In C++ können Sie Call-by-Reference über Pointer und/oder über Referenzen erreichen.\nIn den obigen Beispielen wurde dies für die Parameter einer Funktion gezeigt - es sind aber auch Pointer und/oder Referenzen als Rückgabetypen möglich. Beachten Sie dabei, ob das jeweils wirklich Sinn ergibt! Eine Referenz oder ein Pointer auf eine lokale Variable ist eine große Fehlerquelle.\nIn C++ werden Referenzen über Pointer bevorzugt. Wenn Sie die Wahl zwischen den beiden Signaturen bar foo(wuppie\u0026, bar) und bar foo(wuppie*, bar) haben, sollten Sie sich für bar foo(wuppie\u0026, bar) entscheiden.\nVergleich Pointer mit Referenzen Referenzen Pointer Alias-Name für Objekte/Variablen, kein eigener Speicherplatz \"Echte\" Variablen mit eigenem Speicherplatz (für den Wert des Pointers) Können nicht auf andere Objekte \"umgebogen\" werden Können auf andere Objekte zeigen (falls nicht const) Operationen agieren direkt auf dem referenzierten Objekt Operationen auf referenzierten Objekt als auch auf dem Pointer selbst Nur in C++ In C und in C++ Mit Pointern ist dynamische Speicherverwaltung möglich: Manipulation von Speicherbereichen im Heap Wrap-Up Virtueller Speicher: Kernel stellt Prozessen linearen Adressraum bereit, Segmente: Text, Stack, Heap\nPointer sind Variablen, deren Wert als Adresse interpretiert wird\nDeklaration mit * zwischen Typ und Name Adressoperator \u0026 liefert die Adresse eines Objekts Dereferenzierung eines Pointers mit * vor dem Namen Verwandtschaft zw. Arrays und Pointern: Array-Name ist konstanter Pointer auf Array-Anfang\nPointer haben Typ: Pointerarithmetik berücksichtigt Speicherbreite des Typs\nC++-Referenzen als Alias-Namen für ein Objekt\nDeklaration: Typ \u0026ref = obj; Fest mit Objekt verbunden Zugriff auf Referenz: Direkter Zugriff auf das Objekt",
    "description": "Virtueller Speicher +-----------------------------------------+ | Text | 0x0000 | | | |-----------------------------------------| | | Heap (Data) | | | | | |--------------------+--------------------| | | | | | | v | | | | | | | v | ^ | | | | |--------------------+--------------------| | | | Stack | +-----------------------------------------+ Kernel weist jedem Prozess seinen eigenen virtuellen Speicher zu Linearer Adressbereich, beginnend mit Adresse 0 bis zu einer maximalen Adresse Verwaltung durch MMU (Memory Management Unit) MMU bildet logische Adressen aus virtuellem Speicher auf den physikalischen Speicher ab Transparent für den Prozess Segmente des virtuellen Speichers: Text (read-only) Programm Code Konstanten, String Literale zusätzlich (nicht in Abbildung dargestellt):",
    "tags": [],
    "title": "C++: Pointer und Referenzen",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/99-languages/cpp1-pointer.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Programmiersprachen",
    "content": "OOP in C++ public abstract class Dummy { public Dummy(int v) { value = v; } public abstract int myMethod(); private int value; } class Dummy { public: Dummy(int v = 0); int myMethod(); virtual ~Dummy(); private: int value; }; OOP in C++: Unterschiede zu Java Klassendefinition muss mit Semikolon beendet werden Sichtbarkeit wird immer blockweise eingestellt (per Default immer private) Wie bei Funktionen: Deklaration muss vor Verwendung (= Aufruf) bekannt sein this ist keine Referenz, sondern ein Pointer auf das eigene Objekt Objektlayout: Java vs. C++ Java: Referenzen auf Objekte class Student { String name; Date birthday; double credits; } In Java werden im Objektlayout lediglich die primitiven Attribute direkt gespeichert.\nFür Objekte wird nur eine Referenz auf die Objekte gehalten. Die Attribute selbst liegen aber außerhalb der Klasse, dadurch benötigt das Objekt selbst nur relativ wenig Platz im Speicher.\nC++: Alles direkt im Objekt class Student { string name; Date birthday; double credits; }; In C++ werden alle Attribute innerhalb des Objektlayouts gespeichert. Ein Objekt mit vielen oder großen Feldern braucht also auch entsprechend viel Platz im Speicher.\nWollte man eine Java-ähnliche Lösung aufbauen, müsste man in C++ entsprechend Pointer einsetzen:\nclass Student { private: string *name; Date *birthday; double credits; } Warum nicht Referenzen?\nObjekte erzeugen mit Konstruktoren class Dummy { public: Dummy(int c=0) { credits = c; } private: int credits; }; Erzeugen neuer Objekte:\nDummy a; Dummy b(37); Dummy c=99; =\u003e Kein Aufruf von new!\n(new würde zwar auch ein neues Objekt anlegen, aber auf dem Heap!)\nDefault-Konstruktoren Der C++-Compiler generiert einen parameterlosen Defaultkonstruktor - sofern man nicht selbst mindestens einen Konstruktor definiert.\nDieser parameterlose Defaultkonstruktor wendet für jedes Attribut dessen parameterlosen Konstruktor an, für primitive Typen erfolgt keine garantierte Initialisierung!\nAchtung: Default-Konstruktor wird ohne Klammern aufgerufen!\nDummy a; // Korrekt Dummy a(); // FALSCH!!! (Deklaration einer Funktion `a()`, die ein `Dummy` zurueckliefert) C++: Trennung .h und .cpp // .h class Dummy { public: Dummy(int c=0); private: int credits; }; // .cpp Dummy::Dummy(int c) { credits = c; } Klassenname ist der Scope für die Methoden\nKonstruktoren: Normale (Java-like) Initialisierung class Student { public: Student(const string \u0026n, const Date \u0026d, double c) { name = n; birthday = d; credits = c; } private: string name; Date birthday; double credits; }; Hier erfolgt die Initialisierung in zwei Schritten:\nAttribut wird angelegt und mit Defaultwert/-konstruktor des Datentyps initialisiert Anschließend wird die Zuweisung im Body des Konstruktors ausgeführt Das klappt natürlich nur, wenn es einen parameterlosen Konstruktor für das Attribut gibt.\nBeispiel oben: Beim Anlegen von birthday im Speicher wird der Defaultkonstruktor für Date aufgerufen. Danach wird im Body der übergebene Datumswert zugewiesen.\nKonsole: studiInitBody.cpp Konstruktoren: Initialisierungslisten class Student { public: Student(const string \u0026n, const Date \u0026d, double c) : name(n), birthday(d), credits(c) {} private: string name; Date birthday; double credits; }; In diesem Fall erfolgt die Initialisierung in nur einem Schritt:\nAttribut wird angelegt und direkt mit übergebenen Wert (Kopie) initialisiert Das klappt natürlich nur, wenn ein passender Konstruktor für das Attribut existiert.\nAchtung: Die Reihenfolge der Auswertung der Initialisierungslisten wird durch die Reihenfolge der Attribut-Deklarationen in der Klasse bestimmt!!!\nBeispiel oben: Beim Anlegen von birthday im Speicher wird direkt der übergebene Wert kopiert.\nKonsole: studiInitListe.cpp (ohne/mit -Wall) Zwang zu Initialisierungslisten In manchen Fällen muss man die Initialisierung der Attribute per Initialisierungsliste durchführen.\nHier einige Beispiele:\nAttribut ohne parameterfreien Konstruktor\nBei \"normaler\" Initialisierung würde zunächst der parameterfreie Konstruktor für das Attribut aufgerufen, bevor der Wert zugewiesen wird. Wenn es keinen parameterfreien Konstruktor für das Attribut gibt, bekommt man beim Kompilieren einen Fehler.\nKonstante Attribute\nBei \"normaler\" Initialisierung würde das Attribut zunächst per parameterfreiem Konstruktor angelegt (s.o.), danach existiert es und ist konstant und darf nicht mehr geändert werden (müsste es aber, um die eigentlich gewünschten Werte im Body zu setzen) ...\nAttribute, die Referenzen sind\nReferenzen müssen direkt beim Anlegen initialisiert werden.\nC++11 und delegierende Konstruktoren class C { // 1: Normaler Konstruktor C(int x) { } // 2: Delegiert zu (1) C() : C(42) { } // 3: Rekursion mit (4) C(char c) : C(42.0) { } // 4: Rekursion mit (3) C(double d) : C('a') { } }; Delegierende Konstruktoren gibt es ab C++11:\nVor C++11: Ein Objekt ist fertig konstruiert, wenn der Konstruktor durchgelaufen ist Ab C++11: Ein Objekt ist fertig konstruiert, wenn der erste Konstruktor fertig ausgeführt ist =\u003e Jeder weitere aufgerufene Konstruktor agiert auf einem \"fertigen\" Objekt. Vorsicht mit rekursiven Aufrufen: Compiler kann warnen, muss aber nicht. C++ und explizite Konstruktoren Implizite Konvertierung mit einelementigen Konstruktoren:\nclass Dummy { public: Dummy(int c=0); }; Dummy a; a = 37; // Zuweisung(!) Auf der linken Seite der Zuweisung steht der Typ Dummy, rechts ein int. Der Compiler sucht nach einem Weg, aus einem int einen Dummy zu machen und hat durch die Gestaltung des Konstruktors von Dummy diese Möglichkeit. D.h. in dieser Zuweisung wird implizit aus der 37 ein Objekt vom Typ Dummy gebaut (Aufruf des Konstruktors) und dann die Zuweisung ausgeführt.\nDieses Verhalten ist in vielen Fällen recht praktisch, kann aber auch zu unerwarteten Problemen führen. Zur Abhilfe gibt es das Schlüsselwort explicit.\nFalls unerwünscht: Schlüsselwort explicit nutzen\nexplicit Dummy(int c=0); Wrap-Up Klassendefinition mit Semikolon abschließen (!) Sichtbarkeiten blockweise, keine für Klasse Daten liegen direkt im Objekt (anderenfalls Pointer nutzen) Attribute sind echte Objekte: Initialisieren mit NULL nicht möglich Konstruktoren: Kein new nötig (würde Objekt auf Heap anlegen und Pointer liefern)",
    "description": "OOP in C++ public abstract class Dummy { public Dummy(int v) { value = v; } public abstract int myMethod(); private int value; } class Dummy { public: Dummy(int v = 0); int myMethod(); virtual ~Dummy(); private: int value; }; OOP in C++: Unterschiede zu Java Klassendefinition muss mit Semikolon beendet werden Sichtbarkeit wird immer blockweise eingestellt (per Default immer private) Wie bei Funktionen: Deklaration muss vor Verwendung (= Aufruf) bekannt sein this ist keine Referenz, sondern ein Pointer auf das eigene Objekt Objektlayout: Java vs. C++ Java: Referenzen auf Objekte class Student { String name; Date birthday; double credits; }",
    "tags": [],
    "title": "C++: Klassen",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/99-languages/cpp2-classes.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Programmiersprachen",
    "content": "Big Three Neben dem eigentlichen Konstruktor existieren in C++ weitere wichtige Konstruktoren/Operatoren: die sogenannten \"Big Three\":\nCopy-Konstruktor Destruktor: Gegenstück zum Konstruktor Zuweisungsoperator (operator=) Anmerkung: Für Fortgeschrittenere sei hier auf die in C++11 eingeführte und den Folgeversionen verbesserte und verfeinerte Move-Semantik und die entsprechenden Varianten der Konstruktoren und Operatoren verwiesen. Man spricht deshalb mittlerweile auch gern von den \"Big Five\" bzw. der \"rule of five\".\nclass Dummy { public: Dummy(int a=0); Dummy(const Dummy \u0026d); ~Dummy(); Dummy \u0026operator=(const Dummy \u0026d); private: int value; }; Dummy::Dummy(int a): value(a) {} Dummy::Dummy(const Dummy \u0026d): value(d.value) {} Dummy::~Dummy() {} Dummy::Dummy \u0026operator=(const Dummy \u0026d) { if (this != \u0026d) { value = d.value; } return *this; } Big Three: Destruktor Syntax: Dummy::~Dummy(); (Konstruktor mit vorgesetzter Tilde) Wird aufgerufen: wenn ein Objekt seinen Scope verlässt, oder wenn explizit delete für einen Pointer auf ein Objekt (auf dem Heap!) aufgerufen wird Default-Destruktor ruft Destruktoren der Objekt-Attribute auf Konsole: destruktor.cpp Big Three: Copy-Konstruktor Syntax: Dummy::Dummy(const Dummy \u0026); Wird aufgerufen bei: Deklaration mit Initialisierung mit Objekt Objektübergabe und -rückgabe mit Call-by-Value Nicht bei Zuweisung Default-Copy-Konstruktor kopiert einfach elementweise =\u003e bei Pointern also nur flache Kopie \"Merkregel\": Linke Seite unfertiges Objekt (noch zu bauen), rechte Seite fertiges Objekt.\nKonsole: copyKonstruktor.cpp Big Three: Zuweisungsoperator Syntax: Dummy \u0026Dummy::operator=(const Dummy \u0026) Wird aufgerufen: bei Zuweisung bereits initialisierter Objekte Default-Zuweisungsoperator kopiert einfach elementweise =\u003e bei Pointern also nur flache Kopie \"Merkregel\": Linke Seite fertiges Objekt, rechte Seite fertiges Objekt.\nKonsole: zuweisungsOperator.cpp Big Three: Defaults Analog zum Default-Konstruktor kann der Compiler auch Defaults für die Big Three (Copy-Konstruktor, Destruktor, Zuweisungsoperator) generieren. Das funktioniert nur, so lange Sie nicht selbst einen Copy-Konstruktor, Destruktor oder Zuweisungsoperator definiert haben.\nDiese Defaults passen normalerweise, wenn die Data-Member vom Typ int, double, vector\u003cint\u003e, string, vector\u003cstring\u003e o.ä. sind.\nProblematisch wird es, wenn Pointer dabei sind: Dann werden flache Kopien erzeugt bzw. Speicher auf dem Heap nicht oder mehrfach freigegeben! Sobald Sie für die Attribute Pointer verwenden, sollten Sie eigene Konstruktoren, Copy-Konstruktoren, Destruktoren und Zuweisungsoperatoren definieren!\nHier ein Beispiel für die Wirkung:\nclass Dummy { public: Dummy(int initValue = 0) { value = new int(initValue); } int getValue() { return *value; } void setValue(int a) { *value = a; } private: int *value; }; void main() { // oberer Teil der Abbildung Dummy a(2); Dummy b = a; Dummy c; // unterer Teil der Abbildung c=b; a.setValue(4); } Analyse:\nEs sind Pointer im Spiel. Es wurde ein eigener Konstruktor definiert, aber kein Copy-Konstruktor, d.h. diesen \"spendiert\" der Compiler. Beim Anlegen von a wird auf dem Heap Speicher für einen int reserviert und dort der Wert 2 hineingeschrieben. Beim Anlegen von b wird der Default-Copy-Konstruktor verwendet, der einfach elementweise kopiert. Damit zeigt der Pointer value in b auf den selben Speicher wie der Pointer value in a. Der Ausdruck c=b ist eine Zuweisung (warum?). Auch hier wird der vom Compiler bereitgestellte Default genutzt (elementweise Zuweisung). Damit zeigt nun auch der Pointer value in c auf den selben Speicher wie die value-Pointer in a und b. Hinweis Abarbeitungsreihenfolge Dummy a(0); Dummy b(1); Dummy c(2); Dummy d(3); a = b = c = d; // entspricht: a.operator=(b.operator=(c.operator=(d))); delete this? Erinnerung:\nthis ist ein Pointer auf das eigene Objekt delete darf nur für Pointer auf Objekte, die mit new angelegt wurden, aufgerufen werden =\u003e Freigabe von Objekten auf dem Heap! delete ruft den Destruktor eines Objekts auf ... Frage: Ist das folgende Konstrukt sinnvoll? Ist es überhaupt erlaubt? Was passiert dabei?\nclass Foo { public: ~Foo() { delete this; } }; Analyse: Wir haben hier gleich zwei Probleme:\ndelete ruft den Destruktor des verwiesenen Objekts auf. Da this ein Pointer auf das eigene Objekt ist, ruft delete this; den eigenen Destruktor auf, der dann wiederum delete this; aufruft und so weiter. =\u003e Endlosschleife!\nAußerdem wissen wir im Destruktor bzw. im Objekt gar nicht, ob das Objekt wirklich mit new auf dem Heap angelegt wurde! D.h. wenn wir nicht in die Endlosschleife eintreten würden, würde das Programm abstürzen.\nDer Destruktor wird aufgerufen, wenn ein Objekt zerstört wird, d.h. wenn ein Objekt seine Lebensdauer beendet (Verlassen des Scopes, in dem das Objekt definiert wurde) bzw. wenn explizit ein delete auf das Objekt aufgerufen wird (d.h. delete auf einen Pointer auf das Objekt, wobei dieses mit new angelegt wurde).\nIm Destruktor sollten durch das Objekt verwaltete Resourcen freigegeben werden, d.h. sämtliche im Objekt mit new oder malloc allozierten Resourcen auf dem Heap müssen freigegeben werden. Außerdem sollten ggf. offene Verbindungen (offene Dateien, Datenbankverbindungen, Kommunikation, ...) geschlossen werden, wenn sie durch das Objekt geöffnet wurden bzw. in der Verantwortung des Objekts stehen. Einfache Datentypen oder Objekte, die nicht per Referenz oder Pointer im Objekt verwaltet werden, werden automatisch freigegeben (denken Sie an das Speichermodell - diese Daten \"stehen\" direkt im Speicherbereich des Objekts).\nDer Speicherbereich für das Objekt selbst wird nach Beendigung des Destruktors automatisch freigegeben (auf dem Stack wegen des Verlassen des Scopes (=\u003e automatische Variable), auf dem Heap durch das vorherige Aufrufen von delete auf den Pointer auf das Objekt im Heap), d.h. Sie brauchen im Destruktor kein delete auf \"sich selbst\" (das ist wie oben demonstriert sogar schädlich)!\nWarnung Auch wenn es zunächst irgendwie sinnvoll aussieht - rufen Sie niemals nie delete this im Destruktor auf!\nKonsole: deletethis.cpp C++11: default und delete class Dummy { public: Dummy() = default; Dummy(int a) { value = a; } Dummy(const Dummy \u0026a) = delete; private: int value; Dummy \u0026operator=(const Dummy \u0026d); }; C++ erzeugt etliche triviale Methoden/Operatoren, sofern man diese nicht selbst definiert: Methoden: Standardkonstruktor Copy-Konstruktor Zuweisungsoperator Destruktor Operatoren: Operator new Operator delete Adresse von Indirektion Elementzugriff Elementindirektion Vor C++11: Default-Methode/-Operator verbieten: Sichtbarkeit auf private setzen (Definition nicht nötig) Ab C++11: Schlüsselwort delete: Entfernt Default-Methode/-Operator C++11: Default-Methode/-Operator zusätzlich zu selbst implementierten: Schlüsselwort default Statische Methoden und Attribute class Studi { static int getCount(); static int count; }; int Studi::count = 0; int Studi::getCount() { return Studi::count; } Deklaration als static nicht in Implementierung wiederholen Statische Attribute: Initialisierung immer außerhalb der Klasse! Konsole: Studi.cpp (static) Konstante Methoden und Kontexte class Studi { int getCredits() const; int getCredits(); }; int Studi::getCredits() const { return credits; } int Studi::getCredits() { return credits; } Das const gehört zur Signatur der Methode!\nSo wie im Beispiel gezeigt, gibt es jetzt zwei Methoden getCredits() - eine davon ist konstant. Konstante Methoden dürfen auf konstanten Objekten/Referenzen aufgerufen werden.\nWas passiert, wenn das const auf der linken Seite steht? Dann bezieht es sich auf den Rückgabewert:\nconst foo wuppie(foo\u0026, foo\u0026); Hier darf der Rückgabewert nicht als L-Wert benutzt werden: wuppie(a,b) = c; ist verboten.\nKonsole: Studi.cpp (const) Wrap-Up Klassen: Destruktoren, Copy-Konstruktor, Zuweisungsoperator Vorsicht mit Default-*struktoren/-operatoren Statische Methoden und Attribute: Deklaration als static nicht in Implementierung wiederholen Statische Attribute: Initialisierung außerhalb der Klasse! Konstante Methoden und Kontexte const gehört zur Signatur der Methode! Konstante Methoden dürfen auf konstanten Objekten/Referenzen aufgerufen werden",
    "description": "Big Three Neben dem eigentlichen Konstruktor existieren in C++ weitere wichtige Konstruktoren/Operatoren: die sogenannten \"Big Three\":\nCopy-Konstruktor Destruktor: Gegenstück zum Konstruktor Zuweisungsoperator (operator=) Anmerkung: Für Fortgeschrittenere sei hier auf die in C++11 eingeführte und den Folgeversionen verbesserte und verfeinerte Move-Semantik und die entsprechenden Varianten der Konstruktoren und Operatoren verwiesen. Man spricht deshalb mittlerweile auch gern von den \"Big Five\" bzw. der \"rule of five\".\nclass Dummy { public: Dummy(int a=0); Dummy(const Dummy \u0026d); ~Dummy(); Dummy \u0026operator=(const Dummy \u0026d); private: int value; }; Dummy::Dummy(int a): value(a) {} Dummy::Dummy(const Dummy \u0026d): value(d.value) {} Dummy::~Dummy() {} Dummy::Dummy \u0026operator=(const Dummy \u0026d) { if (this != \u0026d) { value = d.value; } return *this; } Big Three: Destruktor Syntax: Dummy::~Dummy(); (Konstruktor mit vorgesetzter Tilde) Wird aufgerufen: wenn ein Objekt seinen Scope verlässt, oder wenn explizit delete für einen Pointer auf ein Objekt (auf dem Heap!) aufgerufen wird Default-Destruktor ruft Destruktoren der Objekt-Attribute auf Konsole: destruktor.cpp Big Three: Copy-Konstruktor Syntax: Dummy::Dummy(const Dummy \u0026); Wird aufgerufen bei: Deklaration mit Initialisierung mit Objekt Objektübergabe und -rückgabe mit Call-by-Value Nicht bei Zuweisung Default-Copy-Konstruktor kopiert einfach elementweise =\u003e bei Pointern also nur flache Kopie \"Merkregel\": Linke Seite unfertiges Objekt (noch zu bauen), rechte Seite fertiges Objekt.",
    "tags": [],
    "title": "C++: Big 3",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/99-languages/cpp3-big3.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Praktikum",
    "content": "Zusammenfassung Ziel dieses Aufgabenblattes ist die Erstellung eines Tree-Walking-Interpreter mit ANTLR für eine Lisp-artige Sprache.\nMethodik Sie finden im Sample Project zwei Grammatiken (MiniLispA, MiniLispB), die (teilweise) zu der Zielsprache auf diesem Blatt passen. Analysieren Sie beide Grammatiken und entscheiden Sie sich für eine der beiden Varianten. Vervollständigen Sie diese bzw. passen Sie diese an.\nErstellen Sie mit dieser Grammatik und ANTLR wieder einen Lexer und Parser.\nEs ist empfehlenswert, den Interpreter dreistufig zu realisieren:\nEinlesen aus einer Datei mit Lisp-Code und Parsen der Inhalte Aufbauen der Symboltabelle und Durchführung der semantischen Analyse Ablaufen des Parse-Tree/AST und Auswerten der Ausdrücke (Interpretation) Sprachdefinition Ein Programm besteht aus einem oder mehreren Ausdrücken (Expressions). Die Ausdrücke haben eine spezielle Form: Sie sind sogenannte S-Expressions. Dies sind entweder Literale der Form x oder einfache listenartige Gebilde der Form (. x y), wobei der . eine Operation (oder Funktion) darstellt und x und y selbst wieder S-Expressions sind.\nDie einfachste Form sind dabei Literale mit konkreten Werten der drei Datentypen Integer, String und Boolean:\n42 ;; Integer \"hello\" ;; String true ;; Boolean false ;; Boolean Für eine Variable foo wäre das Folgende ebenfalls eine S-Expression:\nfoo ;; Variable foo (Über ;; wird ein Kommentar eingeleitet, der bis zum Ende der Zeile geht.)\nKomplexere Ausdrücke werden über die Listenform gebildet:\n(+ 1 1) ;; 1 + 1 (/ 10 3) ;; 10 / 3 (+ 1 2 3 4) ;; 1 + 2 + 3 + 4 (+ (+ (+ 1 2) 3) 4) ;; (((1 + 2) + 3) + 4) (/ (+ 10 2) (+ 2 4)) ;; ((10 + 2) / (2 + 4)) In der listenartigen Form ist der erste Eintrag der Liste immer eine Operation (oder ein Funktionsname), danach kommen je nach Operation/Funktion (die Arität muss passen!) entsprechende Einträge, die als Parameter für die Operation oder Funktion zu verstehen sind.\nDie Ausdrücke sind implizit von links nach rechts geklammert, d.h. der Ausdruck (+ 1 2 3 4) ist syntactic sugar für (+ (+ (+ 1 2) 3) 4).\nEingebaute Funktionen Es gibt zwei Funktionen, die fest in der Sprache integriert sind.\nMit der eingebauten Funktion print kann der Wert eines Ausdrucks auf der Konsole ausgegeben werden:\n(print \"hello world\") (print \"wuppie\\nfluppie\\nfoo\\nbar\") Die eingebaute Funktion str verknüpft ihre Argumente und bildet einen String. Falls nötig, werden die Argumente vorher in einen String umgewandelt.\n(str 42) ;; liefert \"42\" zurück (str \"wuppie\" \"fluppie\" \"foo\" \"bar\") ;; liefert \"wuppiefluppiefoobar\" zurück (str \"one: \" 1 \", two: \" 2) ;; liefert \"one: 1, two: 2\" zurück Operatoren Es gibt nur wenige vordefinierte Operatoren, diese mit der üblichen Semantik.\nVergleichsoperatoren Operation Operator Gleichheit = Größer \u003e Kleiner \u003c Die Operanden müssen jeweils beide den selben Typ haben. Dabei sind String und Integer zulässig. Das Ergebnis ist immer vom Typ Boolean.\nArithmetische Operatoren Operation Operator Addition + Subtraktion - Multiplikation * Division / Die Operanden müssen jeweils beide den selben Typ haben. Dabei sind String und Integer zulässig. Das Ergebnis ist vom Typ der Operanden.\nKontrollstrukturen (If-Else) Die if-then-else-Abfrage gibt es mit und ohne den else-Zweig:\n(if boolean-form then-form optional-else-form) (if (\u003c 1 2) (print \"true\") ;; then (print \"false\")) ;; else Dabei kann jeweils nur genau eine S-Expression genutzt werden. Wenn man mehrere Dinge berechnen möchte, nutzt man do:\n(do (print \"wuppie\") (print \"fluppie\") (print \"foo\") (print \"bar\")) Beispiel:\n(if (\u003c 1 2) (do (print \"true\") (print \"WUPPIE\")) (print \"false\")) oder anders formatiert:\n(if (\u003c 1 2) (do (print \"true\") (print \"WUPPIE\")) (print \"false\")) Variablen: Bindings mit def anlegen (def x 42) ;; definiert eine neue Variable mit dem Namen \"x\" und dem Wert 42 x ;; liefert 42 (+ x 7) ;; liefert 49 Funktionen mit defn definieren ;; name params body (defn hello (n) (str \"hello \" n)) ;; Definition einer Funktion \"hello\" mit einem Parameter (hello \"world\") ;; Aufruf der Funktion \"hello\" mit dem Argument \"world\" Lokale Scopes mit let ;; bindings use names here (let (name value) (code that uses name)) (def x 99) ;; globale Variable x (def y 101) ;; globale Variable y (def z 42) ;; globale Variable z (let (x 1 ;; lokales x mit Wert 1(verdeckt globales x) y 2) ;; lokales y mit Wert 2 (+ x y z)) ;; 1+2+42 (defn hello (n) (let (l 42) ;; l is valid in this scope (str \"hello \" n \": \" l) ) ;; end of local scope ) ;; end of function definition Mit let können lokale Variablen erzeugt werden, die dann in dem jeweiligen Scope genutzt werden können. Dies funktioniert wie in anderen Sprachen mit Scopes.\nRekursion (defn fac (n) (if (\u003c n 2) 1 (* n (fac (- n 1))))) Da es kein while oder for gibt, müssen Schleifen über rekursive Aufrufe abgebildet werden.\nDatenstrukturen In unserer Sprache gibt es Listen:\n(1 2 3) ;; Fehler! (def v (1 2 3)) ;; Fehler! Das Problem daran ist, dass unsere S-Expressions zwar bereits listenartige Strukturen sind, der erste Eintrag aber als Operator oder Funktion interpretiert wird. Der Ausdruck oben würde beim Auswerten versuchen, die \"Funktion\" 1 auf den Argumenten 2 und 3 aufzurufen ...\nMan braucht also eine Notation, die ein sofortiges Auswerten verhindert und nur die Liste an sich zurückliefert. Dies erreicht man durch die Funktion list:\n(list 1 2 3) ;; (1 2 3) (def v (list 1 2 3)) ;; v = (1 2 3) v ;; (1 2 3) Mit der Funktion nth kann man auf das n-te Element einer Liste zugreifen:\n(nth (list \"abc\" false 99) 2) ;; 99 Zusätzlich gibt es die beiden Funktionen head und tail, die das erste Element einer Liste bzw. die restliche Liste ohne das erste Element zurückliefern:\n(head (list 1 2 3)) ;; 1 (tail (list 1 2 3)) ;; (2 3) Aufgaben A5.1: Grammatik und ANTLR (3P) Erstellen Sie zunächst einige Programme in der Zielsprache. Diese sollten von einfachsten Ausdrücken bis hin zu komplexeren Programmen reichen. Definieren Sie beispielsweise eine Funktion, die rekursiv die Länge einer Liste berechnet.\nDefinieren Sie neben gültigen Programmen auch solche, die in der semantischen Analyse zurückgewiesen werden sollten. Welche Fehlerkategorien könnte es hier geben?\nDefinieren Sie für die obige Sprache eine geeignete ANTLR-Grammatik. Sie können dabei die Grammatik MiniLispA oder MiniLispB im Sample Project als Ausgangspunkt nutzen und diese anpassen und vervollständigen. Erzeugen Sie mithilfe der Grammatik und ANTLR einen Lexer und Parser.\nFühren Sie die semantische Analyse durch: Sind alle Symbole bekannt, passen die Scopes?\nA5.2: Tree-Walking-Interpreter (5P) Bauen Sie einen Tree-Walking-Interpreter in Ihr Projekt ein.\nRealisieren Sie die eingebauten Funktionen print und str dabei als native Funktionen. Realisieren Sie list, nth, head und tail sowie def, let, defn, do und die Operatoren und die Kontrollstrukturen geeignet.\nLösen Sie die als \"syntactic sugar\" bezeichneten Ausdrücke auf und transformieren Sie den AST entsprechend: (+ 1 2 3 4) soll zu (+ (+ (+ 1 2) 3) 4) umgeformt werden. Analog für die anderen Operatoren der Sprache (Vergleiche, Arithmetik).\nAchten Sie auf die Datentypen. Die Typen von Variablen etc. sind erst zur Laufzeit bekannt und müssen dann passen.\nLesen Sie den zu interpretierenden Code aus einer Datei ein.\nTesten Sie Ihren Interpreter mit Ihren Beispielprogrammen.\nA5.3: Auswirkungen der Grammatik auf den Interpreter (2P) Sie haben sich vermutlich für eine der beiden Grammatiken (MiniLispA, MiniLispB) entschieden und auf der Basis Ihren Interpreter erstellt.\nWelche Auswirkungen hat die Grammatik auf den Interpreter? Machen Sie ein Gedankenexperiment: Überlegen Sie, was Sie alles in Ihrer Implementierung ändern müssten, wenn Sie die jeweils andere Grammatik-Variante nutzen würden.\nBonus: Interaktiver Interpreter (3P) Bauen Sie eine REPL ein, d.h. geben Sie nach dem Start des Interpreters einen Prompt aus und verarbeiten Sie die Eingaben interaktiv. Wie müssen Sie hier mit der Symboltabelle umgehen?",
    "description": "Zusammenfassung Ziel dieses Aufgabenblattes ist die Erstellung eines Tree-Walking-Interpreter mit ANTLR für eine Lisp-artige Sprache.\nMethodik Sie finden im Sample Project zwei Grammatiken (MiniLispA, MiniLispB), die (teilweise) zu der Zielsprache auf diesem Blatt passen. Analysieren Sie beide Grammatiken und entscheiden Sie sich für eine der beiden Varianten. Vervollständigen Sie diese bzw. passen Sie diese an.\nErstellen Sie mit dieser Grammatik und ANTLR wieder einen Lexer und Parser.\nEs ist empfehlenswert, den Interpreter dreistufig zu realisieren:",
    "tags": [],
    "title": "Blatt 05: Interpreter",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/homework/sheet05.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Programmiersprachen",
    "content": "Überladen von Operatoren in Klassen MyString a, b(\"hallo\"); a = b; // ??? a.operator=(b); Aufruf a=b ist äquivalent zu a.operator=(b)\nÜberladen ähnlich wie bei Methoden:\nclass MyString { MyString \u0026operator=(const MyString \u0026s) { if (this != \u0026s) { // mach was :-) } return *this; } }; Analog weitere Operatoren, etwa operator==, operator+, ... überladen\nÜberladen von Operatoren außerhalb von Klassen MyString a(\"hallo\"); cout \u003c\u003c a \u003c\u003c endl; class MyString { ostream \u0026operator\u003c\u003c(ostream \u0026o) { return o \u003c\u003c str; } }; So funktioniert das leider nicht!\nErinnerung: cout \u003c\u003c a entspricht cout.operator\u003c\u003c(a) Operator kann nicht in MyString überladen werden! Klasse ostream müsste erweitert werden =\u003e Geht aber nicht, da System-weite Klasse! =\u003e Lösung: Operator außerhalb der Klasse überladen =\u003e 2 Parameter\nÜberladen von Operatoren außerhalb von Klassen (cnt.) Operator außerhalb der Klasse überladen =\u003e 2 Parameter\nostream \u0026operator\u003c\u003c(ostream \u0026out, const MyString \u0026s) { return out \u003c\u003c s.str; } Nachteil: Benötigt Zugriff auf Klassen-Interna entweder umständlich über Getter-Funktionen\noder als friend der Klasse MyString deklarieren\nAlternativ Zugriffsmethoden (aka Getter) nutzen wie toString() ...\nAnmerkung: Rückgabe der Referenz auf den Stream erlaubt die typische Verkettung: cout \u003c\u003c s1 \u003c\u003c s2 \u003c\u003c endl;\nMeine Freunde dürfen in mein Wohnzimmer void test(); class TestDummy { int ganzTolleMethode(); }; class Dummy { private: int *value; friend class TestDummy; friend int TestDummy::ganzTolleMethode(); friend void test(); }; (Fast) alle Operatoren lassen sich überladen Alle normalen arithmetischen Operatoren\nZuweisung, Vergleich, Ein-/Ausgabe\nIndex-Operator [], Pointer-Dereferenzierung * und -\u003e, sowie (), new und delete (auch in []-Form)\nAusnahmen:\n. :: ?: sizeof Anmerkungen:\nBeim Überladen muss die Arität erhalten bleiben Nur existierende Operatoren lassen sich überladen =\u003e Es lassen sich keine neuen Operatoren erschaffen Vgl. Tabelle 9.1 (S. 318) im [Breymann2011]\nImplizite Typkonvertierungen bei Aufruf MyString s; s != \"123\"; // ??? \"123\" != s; // ??? Operatoren in Klasse überladen: Typ der linken Seite muss exakt passen\nclass MyString { public: MyString(const char *s = \"\"); bool operator!=(const MyString\u0026); }; MyString s; s != \"123\"; // impliziter Aufruf des Konstruktors, danach MyString::operator!= \"123\" != s; // KEIN operator!=(char*, MyString\u0026) vorhanden! Das ist letztlich wie bei einem Methodenaufruf: Um die richtige Methode aufzurufen, muss der Typ (die Klasse) des Objekts bekannt sein.\nOperatoren außerhalb überladen: Konvertierung auf beiden Seiten möglich\nclass MyString { public: MyString(const char *s = \"\"); }; bool operator!=(const MyString\u0026, const MyString\u0026); NIEMALS beide Formen gleichzeitig für einen Operator implementieren!\nAnmerkung zu \"++\" und \"-$\\,$-\" Operatoren: Präfix und Postfix Präfix: o1 = ++o2;\nObjekt soll vor Auswertung inkrementiert werden Signatur: Typ \u0026operator++() Postfix: o1 = o2++;\nObjekt soll erst nach Auswertung inkrementiert werden Signatur: Typ operator++(int) (=\u003e int dient nur zur Unterscheidung der Präfix-Variante, wird nie benutzt) Weitere Anmerkungen Operatoren werden nicht vom System zusammengesetzt\noperator+ und operator+= sind zwei verschiedene Operatoren! Implementierung ist prinzipiell unabhängig! =\u003e Erwartung: operator+= $\\;==\\;$ (operator+ $\\;+\\;$ operator=) Operatoren lassen sich in C++ verketten:\nDummy a(0); Dummy b(1); Dummy c(2); a = b = c; // a.operator=(b.operator=(c)); Übertreiben Sie nicht!\nFirma f; Person p; f += p; // ??! Nutzen Sie im Zweifel lieber Methoden mit aussagekräftigen Namen!\nWrap-Up Überladen von Operatoren (innerhalb und außerhalb einer Klasse) Innerhalb: 1 Parameter (Objekt auf der rechten Seite) Außerhalb: 2 Parameter Zugriff auf Attribute: friend einer Klasse Implementierung von Post- und Präfix-Operatoren",
    "description": "Überladen von Operatoren in Klassen MyString a, b(\"hallo\"); a = b; // ??? a.operator=(b); Aufruf a=b ist äquivalent zu a.operator=(b)\nÜberladen ähnlich wie bei Methoden:\nclass MyString { MyString \u0026operator=(const MyString \u0026s) { if (this != \u0026s) { // mach was :-) } return *this; } }; Analog weitere Operatoren, etwa operator==, operator+, ... überladen\nÜberladen von Operatoren außerhalb von Klassen MyString a(\"hallo\"); cout \u003c\u003c a \u003c\u003c endl; class MyString { ostream \u0026operator\u003c\u003c(ostream \u0026o) { return o \u003c\u003c str; } }; So funktioniert das leider nicht!",
    "tags": [],
    "title": "C++: Operatoren",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/99-languages/cpp4-operators.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Programmiersprachen",
    "content": "Vererbung: \"IS-A\"-Beziehung zw. Klassen class Student : public Person { ... } Student(const string \u0026name = \"\", double c = 0.0) : Person(name), credits(c) { } Student(const Student \u0026s) : Person(s), credits(s.credits) { } Analog zu Java:\nStudent: abgeleitete Klasse Person: Basisklasse : public: Vererbungsbeziehung (analog zu extends in Java) public-Vererbung: Verhalten wie in Java Hinweis: Es gibt weitere Spielarten (protected, private), vgl. Semesterliteratur Ab C++11: Schlüsselwort override: Die Methode muss eine virtuelle Methode der Klassenhierarchie überschreiben. Schlüsselwort final: Die virtuelle Methode darf nicht in abgeleiteten Klassen überschrieben werden. Vererbung und Konstruktoren Defaultkonstruktoren werden automatisch richtig verkettet zuerst Aufruf des Basisklassen-Konstruktors anschließend Behandlung der zusätzlichen Attribute Eigene Konstruktoren verketten: Zuerst Basisklassen-Konstruktor aufrufen (in Initialisierungsliste!) =\u003e Konkreten Konstruktor nehmen, nicht super wie in Java Vererbung und Destruktoren Defaultdestruktoren werden automatisch richtig verkettet zuerst werden die Destruktoren der zusätzlichen Attribute aufgerufen dann der Destruktor der Basisklasse Eigene Destruktoren werden automatisch verkettet Destruktor abgeleiteter Klasse muss sich nur um zusätzliche Attribute kümmern Vererbung und Operatoren Defaultoperatoren werden automatisch richtig verkettet zuerst Aufruf des Basisklassen-Operators anschließend Behandlung der zusätzlichen Attribute Eigene Operatoren am Beispiel Zuweisungsoperator: Zuerst den Zuweisungsoperator der Basisklasse aufrufen\nZugriff über Superklassennamen und Scope-Operator (nicht mit super!)\nconst Student \u0026operator=(const Student \u0026s) { if (this != \u0026s) { Person::operator=(s); credits = s.credits; } return *this; } Vererbung von Freundschaften Freundschaften werden nicht vererbt! friends der Basisklasse haben keinen Zugriff auf zusätzliche private Attribute/Methoden der Unterklassen Aber: weiterhin Zugriff auf die geerbten privaten Elemente! Abstrakte Klassen Eine Klasse ist abstrakt, wenn sie mindestens eine abstrakte Methode hat Eine Methode ist in C++ abstrakt, wenn sie als virtuell deklariert ist, und der Deklaration ein \"=0\" folgt Abstrakte Methoden können Implementierung haben! =\u003e Implementierung außerhalb der Klassendeklaration\nclass Person { public: virtual string toString() const = 0; ... }; string Person::toString() const { ... } // Implementierung :-) Polymorphie: Was passiert im folgenden Beispiel? IS-A Beziehung: Objekte können als Objekte ihrer Oberklasse behandelt werden\nclass Person { ... } class Student : public Person { ... } Student s(\"Heinz\", \"heizer\"); Person \u0026p = s; cout \u003c\u003c s.toString() \u003c\u003c endl; cout \u003c\u003c p.toString() \u003c\u003c endl; Konsole: polyStat.cpp Antwort: Es wird die falsche Methode aufgerufen!\ns.toString() =\u003e Student::toString() =\u003e wie erwartet p.toString() =\u003e Person::toString() =\u003e unerwartet! Polymorphie: statisch und dynamisch C++ entscheidet zur Kompilierzeit, welche Methode aufgerufen wird\np ist vom Typ Person =\u003e p.toString() =\u003e Person::toString() Dieses Verhalten wird statisches Binden genannt. Von Java her bekannt: dynamisches Binden\nTyp eines Objektes wird zur Laufzeit ausgewertet Dynamisches Binden geht auch in C++ ... Für dynamische Polymorphie müssen in C++ drei Bedingungen erfüllt sein:\nMethoden in Basisklasse als virtuelle Funktion deklarieren =\u003e Schlüsselwort virtual\nVirtuelle Methoden in Subklasse normal überschreiben (gleiche Signatur)\nZusätzlich muss der Rückgabetyp exakt übereinstimmen (Ausnahme: Rückgabe Pointer/Referenz auf abgeleitete Klasse)\nObjekte mittels Basisklassen-Referenzen bzw. -Pointer zugreifen (siehe nächste Folie)\nclass Person { virtual string toString() const { ... } }; Konsole: polyDyn.cpp Vorsicht Slicing Student s(\"Heinz\", 10.0); Person p(\"Holger\"); p = s; cout \u003c\u003c \"Objekt s (Student): \" \u003c\u003c s.toString() \u003c\u003c endl; cout \u003c\u003c \"Objekt p (Person): \" \u003c\u003c p.toString() \u003c\u003c endl; Konsole polySlicing.cpp =\u003e p ist vom Typ Person\nZuweisung von Objekten vom Typ Student ist erlaubt (Polymorphie) p hat aber nur Speicherplatz für genau eine Person =\u003e \"Abschneiden\" aller Elemente, die nicht Bestandteil von Person sind! Slicing passiert immer beim Kopieren/Zuweisen von Objekten =\u003e Dyn. Polymorphie in C++ immer über Referenzen (bzw. Pointer) und virtuelle Methoden\nWir hatten die Methode toString in der Basisklasse Person zwar als virtual deklariert, und wir hatten diese Methode in der ableitenden Klasse Studi passend überschrieben.\nDamit haben wir aber nur zwei der drei Bedingungen für dynamische Polymorphie in C++ erfüllt. Wenn wir Objekte vom Typ Studi über eine normale Variable vom Typ Person handhaben, haben wir immer noch statische Polymorphie - uns stehen also nur die Methoden aus und in Person zur Verfügung.\nZusätzlich haben wir durch die Zuweisung p = s; das Objekt s in den Speicherbereich von p \"gequetscht\". Dieses ist vom Typ Person und hat auch nur (Speicher-) Platz für Elemente dieses Typs. Alles andere wird bei der Zuweisung \"abgeschnitten\", d.h. p ist immer noch ein Objekt vom Typ Person, der zusätzliche Rest aus Studi fehlt ...\nWir könnten das durch Pointer oder Referenzen heilen:\n// Variante mit Basisklassen-Pointer Student s(\"Heinz\", 10.0); Person *p; p = \u0026s; cout \u003c\u003c \"Objekt s (Student): \" \u003c\u003c s.toString() \u003c\u003c endl; cout \u003c\u003c \"Objekt p (Person): \" \u003c\u003c p-\u003etoString() \u003c\u003c endl; Anmerkung: Der Operator -\u003e ist die zusammengefasste Dereferenzierung des Pointers und der nachfolgende Zugriff auf Methoden oder Attribute. Man könnte also entsprechend auch (*p).toString() statt p-\u003etoString() schreiben.\n// Variante mit Basisklassen-Referenz Student s(\"Heinz\", 10.0); Person \u0026p = s; cout \u003c\u003c \"Objekt s (Student): \" \u003c\u003c s.toString() \u003c\u003c endl; cout \u003c\u003c \"Objekt p (Person): \" \u003c\u003c p.toString() \u003c\u003c endl; Erst damit erfüllen wir die dritte Bedingung und haben echte dynamische Polymorphie in C++.\nAnmerkungen zu Polymorphie in C++ Gestaltung der API: Zum Überschreiben gedachte Methoden als virtuell deklarieren Nicht virtuelle Methoden aus der Basisklasse nicht überschreiben Trennung von Deklaration und Implementierung: Deklaration als virtuelle Funktion nur im Deklarationsteil Keine Wiederholung im Implementierungsteil (analog zu Defaultwerten) \"Virtualität vererbt sich\": Virtuelle Funktionen sind virtuell in der Vererbungshierarchie hinab ab der ersten Deklaration als virtuell Virtualität ist \"teuer\": Es muss eine Tabelle aller virtuellen Funktionen aufgebaut werden und zur Laufzeit geprüft werden, welche Funktion genommen werden soll Mehrfachvererbung in C++ class HiWi: public Student, public Angestellter {...}; Hinweis Speicherlayout ... Problem 1: Gleichnamige Methoden aus Basisklassen geerbt Namenskollision bei Mehrfachvererbung auflösen:\nScope-Operator :: nutzen:\nHiWi h(\"Anne\", 23.0, 40.0); cout \u003c\u003c h.Student::toString() \u003c\u003c endl; cout \u003c\u003c h.Angestellter::toString() \u003c\u003c endl; cout \u003c\u003c h.Student::getName() \u003c\u003c endl; cout \u003c\u003c h.Angestellter::getName() \u003c\u003c endl; Methode in abgeleiteter Klasse überschreiben\nHiWi h(\"Anne\", 23.0, 40.0); cout \u003c\u003c h.toString() \u003c\u003c endl; cout \u003c\u003c h.Student::toString() \u003c\u003c endl; cout \u003c\u003c h.Angestellter::toString() \u003c\u003c endl; Konsole vererbungMultiMethoden.cpp Problem 2: Gemeinsam geerbte Attribute sind mehrfach vorhanden Konsole vererbungMultiAttribute.cpp Mehrfachvererbung in C++: Virtuelle Basisklassen class Angestellter: virtual public Person {...}; class Student: virtual public Person {...}; class HiWi: public Student, public Angestellter {...}; Person ist jetzt eine virtuelle Basisklasse Auswirkungen erst in Klasse HiWi Dadurch sind gemeinsam genutzte Anteile nur einfach vorhanden Student s(\"Heinz\", 10.0); // wie vorher: nur EIN name-Feld Angestellter a(\"Holger\", 80.5); // wie vorher: nur EIN name-Feld HiWi h(\"Anne\", 23.0, 40.0); // jetzt auch nur EIN name-Feld Konsole vererbungMultiVirtual.cpp Sonderregeln bei virtueller Ableitung Virtuelle Ableitung: Potentiell Konflikte zwischen Konstruktoren!\nGemeinsam geerbtes Attribut nur noch einmal vorhanden Konstruktoren werden nacheinander aufgerufen, alle wollen das gemeinsame Attribut initialisieren (durch Aufruf des Konstruktors der jeweiligen Basisklasse) Zuletzt aufgerufener Konstruktor würde \"gewinnen\" Deshalb gibt es bei virtueller Ableitung folgende Sonderregeln:\nFür virtuelle Basisklassen ist Mechanismus des Weiterreichens von Initialisierungswerten deaktiviert\nKonstruktor einer virtuellen Basisklasse kann in Initialisierungsliste von indirekten Unterklassen aufgerufen werden\nSonst wird der Defaultkonstruktor der virtuellen Basisklasse genutzt!\nKonsole vererbungMultiVirtual.cpp (Basiskonstruktor) Mehrfachvererbung in C++ ist ein recht kompliziertes Thema Warum ist die Möglichkeit dennoch nützlich?\nIn Java kann man nur von einer Klasse erben, aber viele Interfaces implementieren. In C++ gibt es keine Interfaces ...\n=\u003e Interfaces mit abstrakten Klassen Interfaces simulieren\n=\u003e Mehrfachvererbung!\nTatsächlich dürfen Java-Interfaces mittlerweile auch Verhalten implementieren und vererben, wodurch eine ähnliche Situation wie hier in C++ entsteht und es ausgefeilte Regeln für die Konfliktauflösung braucht. Allerdings ist das in Java auf Verhalten beschränkt, d.h. Attribute (Zustand) ist in Java-Interfaces (noch) nicht erlaubt.\nWrap-Up public-Vererbung in C++: Subklasse : public Superklasse\nKeine gemeinsame Oberklasse wie Object, kein super\nVerkettung von Operatoren und *struktoren\nAbstrakte Klassen in C++\nStatische und dynamische Polymorphie in C++\nMethoden in Basisklasse als virtual deklarieren Dyn. Polymorphie nur mittels Pointer/Referenzen Slicing in C++ (bei Call-by-Value) Konzept der Mehrfachvererbung\nProblem bei rautenförmiger Vererbungsbeziehung: Attribute und Methoden mehrfach vorhanden\nVirtuelle Basisklassen: Gemeinsam genutzte Attribute nur noch einfach vorhanden",
    "description": "Vererbung: \"IS-A\"-Beziehung zw. Klassen class Student : public Person { ... } Student(const string \u0026name = \"\", double c = 0.0) : Person(name), credits(c) { } Student(const Student \u0026s) : Person(s), credits(s.credits) { } Analog zu Java:\nStudent: abgeleitete Klasse Person: Basisklasse : public: Vererbungsbeziehung (analog zu extends in Java) public-Vererbung: Verhalten wie in Java Hinweis: Es gibt weitere Spielarten (protected, private), vgl. Semesterliteratur Ab C++11: Schlüsselwort override: Die Methode muss eine virtuelle Methode der Klassenhierarchie überschreiben. Schlüsselwort final: Die virtuelle Methode darf nicht in abgeleiteten Klassen überschrieben werden. Vererbung und Konstruktoren Defaultkonstruktoren werden automatisch richtig verkettet zuerst Aufruf des Basisklassen-Konstruktors anschließend Behandlung der zusätzlichen Attribute Eigene Konstruktoren verketten: Zuerst Basisklassen-Konstruktor aufrufen (in Initialisierungsliste!) =\u003e Konkreten Konstruktor nehmen, nicht super wie in Java Vererbung und Destruktoren Defaultdestruktoren werden automatisch richtig verkettet zuerst werden die Destruktoren der zusätzlichen Attribute aufgerufen dann der Destruktor der Basisklasse Eigene Destruktoren werden automatisch verkettet Destruktor abgeleiteter Klasse muss sich nur um zusätzliche Attribute kümmern Vererbung und Operatoren Defaultoperatoren werden automatisch richtig verkettet zuerst Aufruf des Basisklassen-Operators anschließend Behandlung der zusätzlichen Attribute Eigene Operatoren am Beispiel Zuweisungsoperator: Zuerst den Zuweisungsoperator der Basisklasse aufrufen",
    "tags": [],
    "title": "C++: Vererbung und Polymorphie",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/99-languages/cpp5-inheritance.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Programmiersprachen",
    "content": "Vergleichsfunktion für zwei Integer? bool cmp(const int \u0026a, const int \u0026b) { return a\u003cb; } Und für double? Und für string? ... =\u003e Präprozessor-Makro?\n=\u003e Funktionen überladen?\nÜberladen von Funktionen: Ähnliche Funktionalität für unterschiedliche Datentypen Mühselig, wenn exakt gleiche Funktionalität! (bessere) Antwort: Funktions-Templates Templates: Funktionen mit parametrisierten Datentypen Deklaration/Definition für (zunächst) unbestimmte Datentypen Bei Verwendung der Funktion: Konkretisierung der Datentypen Compiler erzeugt automatisch passende Funktionsinstanz Definition von Funktions-Templates template \u003ctypename T\u003e bool cmp(const T \u0026a, const T \u0026b) { return a\u003cb; } Statt typename kann auch class geschrieben werden\nKonvention:\ntypename wenn sowohl Klassen als auch Basistypen class falls eher Klassen-Typen =\u003e class gilt als veraltet, deshalb immer typename verwenden!\nBei mehreren Typen \"typename NAME\" wiederholen (Komma-separierte Liste in \u003c und \u003e)\nbeispielsweise so: (Achtung, soll nur die Verwendung demonstrieren, hat sonst keinen Sinn)\ntemplate \u003ctypename T1, typename T2, typename T3\u003e T1 cmp(const T2 \u0026a, const T3 \u0026b) { return a\u003cb; } Vorsicht: Im Beispiel oben muss operator\u003c für die verwendeten Typen T implementiert sein! (sonst Fehler zur Compile-Zeit)\nBestimmung der Template-Parameter I: Typ-Inferenz Das Funktions-Template wird wie eine normale Funktion aufgerufen ... =\u003e Der Compiler inferiert Typen und erzeugt passende Funktionsinstanz(en).\ntemplate \u003ctypename T\u003e bool cmp(const T \u0026a, const T \u0026b) { return a\u003cb; } int main() { cmp(3, 10); // cmp(int, int) cmp(2.2, 10.1); // cmp(double, double) cmp(string(\"abc\"), string(\"ABC\")); // cmp(string, string) cmp(3, 3.4); // Compiler-FEHLER!!! } Vorsicht bei Typ-Inferenz: Typen müssen exakt passen!\nBestimmung der Template-Parameter II: Explizite Angabe template \u003ctypename T\u003e bool cmp(const T \u0026a, const T \u0026b) { return a\u003cb; } int main() { cmp\u003cint\u003e('a', 'A'); // cmp(int, int) cmp\u003cint\u003e(3, 3.4); // cmp(int, int) } Bei expliziter Angabe der Typen beim Aufruf (cmp\u003cint\u003e) kann der Compiler automatisch casten.\nTyp-Inferenz und explizite Bestimmung mischen Compiler nutzt die vorgegebenen Typ-Parameter, ... ... inferiert die restlichen, und ... ... castet notfalls die Parameter template \u003ctypename T1, typename T2, typename T3\u003e void fkt(T2 a, T3 b, T2 c, int d) { ... } int main() { fkt\u003cvoid*, int\u003e(42, \"HUHU\", 'a', 99); } =\u003e In Parameterliste nicht vorkommende Typ-Parameter explizit angeben!\nReihenfolge der Angabe der Typen in spitzen Klammern beim Aufruf wie in Template-Deklaration Wenn ein Typ-Parameter nicht in der Parameterliste der Funktion vorkommt, ist eine Inferenz für den Compiler unmöglich. Deshalb muss dieser Typ beim Aufruf explizit in der Liste mit den spitzen Klammern angegeben werden! Im Beispiel oben: fkt\u003ca, b, c\u003e(...): a wäre der Typ für T1, b für T2, c für T3\nMit fkt\u003c..., int\u003e(...) beim Aufruf wird T2 zu int und damit für Parameter c der Char als int interpretiert (T3 wird inferiert)\nOhne \u003c..., int\u003e beim Aufruf gibt es ein Problem beim Erkennen von T2: int vs. char (a=42, c='a') ...\nTyp-Inferenz funktioniert nicht immer! template \u003ctypename T\u003e T zero() { return 0; } int main() { int x, y; x = zero(); // Fehler: couldn't deduce template parameter 'T' y = zero\u003cint\u003e(); // korrekter Aufruf } Die Funktion hat keine Parameter - der Compiler hat also keine Chance, den Typ T zu inferieren. In diesem Fall muss der Typ beim Aufruf explizit angegeben werden.\nSpezialisierung von Funktions-Templates // Primaeres Template template \u003ctypename T\u003e bool cmp(const T \u0026a, const T \u0026b) { return a\u003cb; } // Spezialisiertes Template template \u003c\u003e bool cmp\u003cint\u003e(const int \u0026a, const int \u0026b) { return abs(a)\u003cabs(b); } Spezialisierte Templates nach \"primärem\" Template definieren\nAchtung: Reihenfolge der Deklaration/Definition ist wichtig. Immer zuerst das allgemeine (\"primäre\") Template definieren, danach dann die Spezialisierungen! Anderenfalls gibt es \"seltsame\" Fehlermeldungen vom Compiler oder sogar seltsames Verhalten.\nAchtung: Im Unterschied zu Klassen-Templates können Funktions-Templates nur vollständig spezialisiert werden (d.h. bei mehreren Template-Parametern müssen dann alle Template-Parameter konkret spezifiziert werden)!\nAnmerkung: Die Angabe der Typen in spitzen Klammern nach dem Funktionsnamen ist freiwillig, so lange alle Typ-Parameter in der Parameterliste der Funktion auftauchen. Man könnte die obige Spezialisierung also auch so schreiben (cmp( statt cmp\u003cint\u003e():\n// Spezialisiertes Template template \u003c\u003e bool cmp(const int \u0026a, const int \u0026b) { return abs(a)\u003cabs(b); } Alternativ: Überladen der Funktions-Templates mit normalen Funktionen Überladen mit normalen Funktionen funktioniert wie bei spezialisierten Templates, d.h. auch hier zuerst das primäre Template definieren, danach eventuelle Spezialisierungen und danach Überladungen mit normalen Funktionen.\nAllerdings gibt es Unterschiede für eventuell nötige Typumwandlungen der Parameter beim Aufruf der Funktionen:\nIn gewöhnlichen Funktionen sind automatische Typumwandlungen möglich In (spezialisierten) Templates sind keine automatischen Typumwandlungen erlaubt (sofern man mit Typ-Inferenz arbeitet, d.h. die Template-Typen nicht beim Aufruf explizit angegeben werden) template \u003ctypename T\u003e bool cmp(T a, T b) { return a\u003cb; } bool cmp(int a, int b) { return abs(a)\u003cabs(b); } int main() { cmp(3, 6); // true: überladene normale Funktion cmp(3, 3.4); // FALSE: überladene normale Funktion (Cast) cmp\u003cint\u003e(3, 3.4); // FALSE: Template } Aufruf: Compiler nimmt die am besten \"passende\" Variante: Keine Template-Parameter beim Aufruf angegeben (d.h. Typ-Inferenz): Zuerst exakt passende normale Funktion, dann passendes spezialisiertes Template (bei mehreren passenden spezialisierten Templates das am meisten spezialisierte Template, ohne Casts), dann das allgemeine (\"primäre\") Template (ohne Casts), ansonsten normale Funktion mit impliziten Casts Template-Parameter beim Aufruf angegeben: am besten passendes Template Hinweis: Durch reine Deklaration von Spezialisierungen (d.h. ohne die entsprechende Implementierung) lässt sich die Instantiierung einer Templatefunktion für bestimmte Typen verhindern. Beispiel:\ntemplate \u003ctypename T\u003e bool cmp(const T \u0026a, const T \u0026b) { return a\u003cb; } template \u003c\u003e bool cmp\u003cint\u003e(const int \u0026a, const int \u0026b); Damit könnte man die cmp-Funktion nicht mehr für int benutzen (Compiler- bzw. Linker-Fehler).\nKonsole: funktionsTemplates.cpp Klassen-Templates in C++ template \u003ctypename T\u003e class Matrix { Matrix(unsigned rows = 1, unsigned cols = 1); vector\u003cvector\u003cT\u003e \u003e xyField; }; Hinweis: Template-Parameter innerhalb von Template-Parametern verursachen bei den schließenden spitzen Klammern u.U. Parser-Probleme. Diese lassen sich durch ein extra Leerzeichen (hat sonst keine Funktion!) umgehen: Statt vector\u003cvector\u003cT\u003e\u003e xyField; besser vector\u003cvector\u003cT\u003e \u003e xyField; schreiben.\nint main() { Matrix\u003cint\u003e m1; Matrix\u003cdouble\u003e m2(12, 3); } Template-Parameter gehören zur Schnittstelle und müssen bei der Instantiierung angegeben werden. Matrix m; würde im obigen Beispiel nicht funktionieren.\ntemplate \u003ctypename T\u003e Matrix\u003cT\u003e::Matrix(unsigned rows, unsigned cols) { ... } Beispiel: matrix.cpp Klassen-Templates in C++ (Variante mit Konstanten) template \u003ctypename T, unsigned rows, unsigned cols\u003e class Matrix { Matrix(); vector\u003cvector\u003cT\u003e \u003e xyField; }; Template-Parameter können neben Typen auch konstante Werte (Basisdatentypen, außer float und double) sein. Innerhalb der Klasse Matrix kann auf die Werte von rows und cols zugegriffen werden.\nAchtung: rows und cols sind keine Attribute der Klasse Matrix!\nHinweis: Konstanten als Template-Parameter funktioniert auch bei Funktions-Templates.\nint main() { Matrix\u003cint, 1, 1\u003e m1; Matrix\u003cdouble, 12, 3\u003e m2; Matrix\u003cstring, 1, 1\u003e m3; } Beispiel: matrix2.cpp Beispiel: Konstanten als Template-Parameter template \u003cint I\u003e void print() { cout \u003c\u003c I; } print\u003c5\u003e(); template \u003cunsigned u\u003e struct MyClass { enum { X = u }; }; cout \u003c\u003c MyClass\u003c2\u003e::X \u003c\u003c endl; Konstante muss explizit übergeben werden Wert muss eine zur Compile-Zeit bekannte Konstante sein Nur aufzählbare Typen für derartige Konstanten erlaubt (z.B. int, aber nicht double) Anmerkung: Durch Konstruktion mit dem anonymen enum in der Klasse MyClass wird der Wert der Konstanten \"gespeichert\" und kann später (von außen) abgefragt werden. (Innerhalb der Klasse selbst können Sie natürlich jederzeit auf den Wert von u zugreifen.)\nWollte man dies über ein normales Attribut erledigen, sähe der Code deutlich komplexer aus (zusätzlich zur oben gezeigten Variante mit dem enum einmal als statisches Attribut Y und einmal als \"normales\" Attribut Z):\ntemplate \u003cunsigned u\u003e struct MyClass { enum { X = u }; static unsigned Y; unsigned Z; MyClass() : Z(u) {} }; template \u003cunsigned u\u003e int MyClass\u003cu\u003e::Y = u; int main() { cout \u003c\u003c MyClass\u003c2\u003e::X \u003c\u003c endl; cout \u003c\u003c MyClass\u003c2\u003e::Y \u003c\u003c endl; cout \u003c\u003c MyClass\u003c2\u003e().Z \u003c\u003c endl; } Falls man mit :: zugreifen wollte, müsste das Attribut static sein und entsprechend außerhalb der Klasse initialisiert werden. Für ein \"normales\" Attribut braucht man dann einen extra Konstruktor und muss den Aufruf dann extra klammern: MyClass\u003c2\u003e().Z statt MyClass\u003c2\u003e.Z.\nDie Variante mit dem enum werden Sie entsprechend sehr häufig in C++ finden!\nKlassen-Templates mit Defaults template \u003ctypename T = int, unsigned rows = 1, unsigned cols = 1\u003e class Matrix { Matrix(); vector\u003cvector\u003cT\u003e \u003e xyField; }; int main() { Matrix\u003c\u003e m1; // Leere spitze Klammern Pflicht! Matrix\u003cdouble, 12, 3\u003e m2; Matrix\u003cstring\u003e m3; } Leere spitze Klammern bei Klassen-Templates mit Default-Parameter Pflicht!\nHinweis: Defaults für Template-Parameter waren zunächst nur für Klassen-Templates erlaubt. Seit C++11 kann man solche Defaults auch bei Funktions-Templates einsetzen.\nBeispiel: matrix3.cpp Klassen-Templates in C++ spezialisieren template \u003ctypename T\u003e class Matrix { Matrix(unsigned rows, unsigned cols); vector\u003c vector\u003cT\u003e \u003e xyField; }; template \u003c\u003e class Matrix\u003cuint\u003e { Matrix(unsigned rows, unsigned cols); vector\u003c vector\u003cuint\u003e \u003e xyField; }; Hinweis auf Implementierung außerhalb der Klasse ACHTUNG: Implementierung außerhalb der Klasse: Bei den Methoden des voll spezialisierten Templates das \"template\u003c\u003e\" weglassen! Alles andere ist ein Syntax-Fehler.\nDer Grund dafür bleibt ein Geheimnis des C++-Standards ... ;-)\n// Implementierung fuer primaeres Template template \u003ctypename T\u003e Matrix\u003cT\u003e::Matrix(unsigned rows, unsigned cols) { ... } // Implementierung fuer vollstaendig spezialisiertes Template Matrix\u003cuint\u003e::Matrix(unsigned rows, unsigned cols) { ... } Partielle Spezialisierung template \u003ctypename T1, typename T2\u003e class Array { Array(); vector\u003cT1\u003e v; vector\u003cT2\u003e w; }; template \u003ctypename T\u003e class Array\u003cT, int\u003e { Array(); vector\u003cT\u003e v; vector\u003cint\u003e w; }; ACHTUNG: Implementierung außerhalb der Klasse: Bei den Methoden des partiell spezialisierten Templates muss das \"template\u003cT\u003e\" wieder benutzt werden!\n// Implementierung fuer primaeres Template template \u003ctypename T1, typename T2\u003e Array\u003cT1, T2\u003e::Array() {} // Implementierung fuer partiell spezialisiertes Template template \u003ctypename T\u003e Array\u003cT, int\u003e::Array() {} Vergleich verschiedene Spezialisierungen Allgemeine Templates vs. partiell spezialisierte Templates vs. vollständig spezialisierte Templates\n// Primaeres (allgemeines) Template template \u003cunsigned line, unsigned column\u003e class Matrix { public: Matrix(); }; // Partiell spezialisiertes Template template \u003cunsigned line\u003e class Matrix\u003cline, 1\u003e { public: Matrix(); }; // Vollstaendig spezialisiertes Template template \u003c\u003e class Matrix\u003c3, 3\u003e { public: Matrix(); }; // Aufrufe int main() { Matrix\u003c3, 4\u003e matrix; // allg. Template Matrix\u003c20, 1\u003e vector; // partiell spez. Templ. Matrix\u003c3, 3\u003e dreiKreuzDrei; // vollst. spez. Templ. } // Implementierung template \u003cunsigned line, unsigned column\u003e Matrix\u003cline, column\u003e::Matrix() { cout \u003c\u003c \"allgemeines Template\" \u003c\u003c endl; } template \u003cunsigned line\u003e Matrix\u003cline, 1\u003e::Matrix() { cout \u003c\u003c \"partiell spezialisiertes Template\" \u003c\u003c endl; } Matrix\u003c3, 3\u003e::Matrix() { cout \u003c\u003c \"vollstaendig spezialisiertes Template\" \u003c\u003c endl; } Regel: Das am meisten spezialisierte Template wird verwendet.\nMischen von Klassen- und Funktions-Templates Sie können innerhalb eines Klassen-Templates auch ein Funktions-Template (Methoden-Template) definieren. Bei der Implementierung außerhalb der Klasse müssen entsprechend alle Template-Deklarationen wiederholt werden!\ntemplate \u003ctypename T, unsigned n\u003e class Array { public: enum { size = n }; template \u003ctypename C \u003e void copy_from(const C \u0026c); private: T data[n]; }; template \u003ctypename T, unsigned n\u003e template \u003ctypename C\u003e void Array\u003cT,n\u003e::copy_from(const C \u0026c) { ... } Templates: Java vs. C++ Templates sind nur Schablonen!\nDie Definitionen der Templates werden nicht in den Object-Code kompiliert! Erst bei der Instantiierung von Templates wird durch den Compiler eine passende Instanz erzeugt und im Object-Code zur Nutzung abgelegt.\nUnterschied zu Java\nC++: Für jeden Aufruf/Typ eine passende Instanz (!) Java: Nur eine Klasse mit gemeinsamen Obertyp Offener Code: Templates im .h-File implementieren!\nOhne die Template-Definition kann der Compiler keine Instanzen anlegen!\nBibliotheken und Templates passen nicht recht\nTemplates werden immer bei der ersten Verwendung instantiiert! Wird ein Template nicht im zu kompilierenden Code verwendet, dann generiert der Compiler auch nichts, was man in den Objektdateien finden könnte ...\nNur instantiierte Templates sind in einer dynamischen/statischen Bibliothek enthalten!\nFalls Einsatz nur für wenige Typen vorgesehen =\u003e Explizite Instantiierung:\nEntweder mit \"template\": template class Matrix\u003c5,5\u003e;, oder\nmit \"typedef\": typedef Matrix\u003c5,5\u003e Matrix5x5;\n=\u003e Dann aber nur in exakt diesen Versionen in der Bibliothek enthalten und entsprechend nur so nutzbar (sofern die Template-Definition nicht zur Verfügung steht)\nWrap-Up Generische Programmierung (Funktions-Templates)\ntemplate \u003ctypename T\u003e der Funktionsdefinition voranstellen Funktions-Templates sind spezialisierbar und überladbar Aufruf: Compiler nimmt die am besten \"passende\" Variante Generische Programmierung (Klassen-Templates)\nFunktionsweise analog zu Funktions-Templates Bei Implementierung außerhalb der Deklaration: Template-Deklaration mitführen! Klassen-Templates lassen sich partiell spezialisieren Compiler stellt je instantiiertes Template eine konkrete Funktion/Klasse bereit",
    "description": "Vergleichsfunktion für zwei Integer? bool cmp(const int \u0026a, const int \u0026b) { return a\u003cb; } Und für double? Und für string? ... =\u003e Präprozessor-Makro?\n=\u003e Funktionen überladen?\nÜberladen von Funktionen: Ähnliche Funktionalität für unterschiedliche Datentypen Mühselig, wenn exakt gleiche Funktionalität! (bessere) Antwort: Funktions-Templates Templates: Funktionen mit parametrisierten Datentypen Deklaration/Definition für (zunächst) unbestimmte Datentypen Bei Verwendung der Funktion: Konkretisierung der Datentypen Compiler erzeugt automatisch passende Funktionsinstanz Definition von Funktions-Templates template \u003ctypename T\u003e bool cmp(const T \u0026a, const T \u0026b) { return a\u003cb; } Statt typename kann auch class geschrieben werden",
    "tags": [],
    "title": "C++: Templates",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/99-languages/cpp6-templates.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Praktikum",
    "content": "Zusammenfassung Ziel dieses Aufgabenblattes ist die praktische Anwendung Ihrer C++-Kenntnisse, insbesondere werden Sie Pointer, Referenzen und Klassen anwenden und vertiefen. Als Anwendungsbeispiel werden Sie bestimmte in der C++-Welt wohlbekannte Smartpointer modellieren sowie einen einfachen Ringpuffer programmieren. Sie lernen mit dem Reference Counting nebenbei eine verbreitete Technik der Garbage Collection kennen.\nMethodik Sie werden auf diesem Blatt vier einfache Klassen in C++ implementieren.\nEs empfiehlt sich, zunächst die Beispiele gründlich zu analysieren, um die gewünschte Funktionsweise der einzelnen Klassen vorab präzise zu verstehen. Sie werden zu einigen Dingen in der C++-Literatur recherchieren müssen.\nImplementieren Sie immer eine Klasse vollständig und testen Sie Ihren Code sowohl mit den vorgegebenen Beispielen als auch mit eigenen Beispielen, bevor Sie sich an die nächste Aufgabe/Klasse setzen.\nSpeicherverwaltung in C/C++ C und C++ erlauben als hardwarenahe Programmiersprachen den direkten Umgang mit dem Programmspeicher (Heap). Ein Programm kann dynamisch zu jeder Zeit weiteren Speicher anfordern und so beispielsweise mitwachsende Datenstrukturen realisieren.\nDa der Heap-Speicher endlich ist, muss man nicht mehr benötigten Speicher auch wieder freigeben. Anderenfalls ist irgendwann der komplette Heap belegt und das Programm kann nicht mehr ordnungsgemäß arbeiten. Für die Freigabe ist man als Programmierer:in selbst zuständig.\nBeispiel für eine Tokenizer-Funktion Im folgenden Programmschnipsel soll eine Funktion next_token() das nächste Token berechnen. So eine Funktion findet sich typischerweise im Lexer. Für die Rückgabe des Tokens hat man in C++ drei Möglichkeiten: als Kopie, als Referenz oder als Pointer.\n// Return as copy Token next_token() { Token wuppie = Token(\"wuppie\", 1, 4); // will be deleted automatically Token bar = Token(\"bar\", 7, 10); // not used, will be deleted automatically return wuppie; } int main() { Token x = next_token(); // copy constructor; no need to free } // Return as pointer Token* next_token() { Token* foo = new Token(\"foo\", 9, 35); // will be free'd manually Token* bar = new Token(\"bar\", 7, 10); // leaves a memory hole!!! return foo; } int main() { Token* x = next_token(); // only the pointer (i.e. address) will be copied ... delete x; // caller needs to free this object } // Return as C++ reference Token\u0026 next_token() { Token* foo = new Token(\"foo\", 9, 35); // will be free'd manually Token* bar = new Token(\"bar\", 7, 10); // leaves a memory hole!!! return *foo; } int main() { Token\u0026 x = next_token(); // no copy, `x` is just a new alias for `foo` ... delete \u0026x; // caller needs to free this object } Die Rückgabe per Kopie (Standardfall in C/C++) würde ein lokales Objekt auf dem Stack (im Beispiel wäre das wuppie) als Kopie zurückgeben.\nVorteil: Der Compiler kümmert sich um die Freigabe der lokalen Variable wuppie, d.h. nach Beendigung des Funktionsaufrufs wird das Objekt automatisch vom Stack entfernt. Da hierbei einfach der Stackpointer zurückgesetzt wird, ist diese \"Freigabe\" eine sehr preiswerte Operation.1 Nachteil: Der Aufrufer darf nicht einfach auf das Objekt auf dem Stack zugreifen (dieses ist ja nach Beendigung der Funktion nicht mehr gültig). Deshalb muss das Objekt bei der Rückgabe kopiert werden (Copy-Konstruktor). Zusätzlich erfolgt beim Aufrufer oft noch eine Zuweisung, bei der die Attribute des Objekts vermutlich erneut kopiert werden. Dies kann (je nach Aufbau der Objekte) sehr teuer sein! Die Rückgabe per Pointer erfordert ein Objekt, welches innerhalb der Funktion erzeugt wird und dessen Lebensdauer über das Funktionsende hinausreicht. Das Objekt muss in diesem Fall also auf dem Heap angelegt werden.\nVorteil: Die Rückgabe erfordert lediglich die Kopie der Adresse des Objekts (also des Pointers). Hier handelt es sich vereinfacht betrachtet um einen Integer, d.h. diese Operation ist relativ preiswert. Nachteil: Das Objekt muss vom Aufrufer wieder freigegeben werden, sobald es nicht mehr benötigt wird. Dies muss man explizit programmieren! Die Rückgabe per C++-Referenz erfordert ebenfalls ein Objekt, welches innerhalb der Funktion erzeugt wird und dessen Lebensdauer über das Funktionsende hinausreicht. Das Objekt muss in diesem Fall also wieder auf dem Heap angelegt werden.\nVorteil: Die Rückgabe erfordert keinerlei Kopien, da sich die Referenz x an das Objekt foo bindet und lediglich einen neuen Alias für dieses Objekt darstellt. Nachteil: Das Objekt muss vom Aufrufer wieder freigegeben werden, sobald es nicht mehr benötigt wird. Dies muss man explizit programmieren! Es hat sich gezeigt, dass der Umgang mit den Heap-Ressourcen sehr fehleranfällig ist. Ein Aspekt dabei ist, dass man häufig die Freigabe der Objekte vergisst oder dass die Programmpfade so unübersichtlich sind, dass man nicht genau weiss, ob und wann man Objekte freigeben soll (denken Sie an Exceptions).\nSmartpointer als Lösung Während man in Sprachen wie Java die Speicherverwaltung komplett dem Compiler überlässt oder wie in Rust mit strikten Ownership-Modellen arbeitet, hat man in C++ die sogenannten Smartpointer erdacht. Diese ersetzen den direkten Umgang mit den einfachen Pointern (auch als raw pointer bezeichnet) und lösen das Problem der Freigabe der verwalteten Ressourcen.2 Es gibt verschiedene Modelle, insbesondere gibt es die Variante unique pointer, bei der immer nur genau ein Smartpointer gleichzeitig eine bestimmte Ressource besitzen darf, und die shared pointer, bei der mehrere Smartpointer gleichzeitig die selbe Ressource verwalten können. Sobald die Lebensdauer des unique pointer oder des letzten shared pointer endet, wird die verwaltete Ressource automatisch vom Smartpointer freigegeben.\nDas folgende Beispiel arbeitet mit einer selbst implementierten Variante der shared pointers. Dabei ist die Klasse SmartToken ein Smartpointer für Objekte vom Typ Token:\nvoid fluppie() { // new smart pointer for token \"wuppie\": // wuppie lives on the stack, the token lives on the heap (`new`) SmartToken wuppie = SmartToken(new Token(\"wuppie\", 1, 4)); if (bla==42) { // fluppie shares resource with wuppie SmartToken fluppie = SmartToken(wuppie); // fluppie2 shares resource with wuppie SmartToken fluppie2(wuppie); // now there are 3 smart pointers sharing the same resource (token \"wuppie\") // new smart pointer for token \"foo\" SmartToken foo = SmartToken(new Token(\"foo\", 9, 35)); } // fluppie, fluppie2, foo will be removed from the stack - foo releases its resource // wuppie is the only smart pointer with shared resource \"wuppie\" } // wuppie will be removed from the stack - wuppie releases its resource Im Beispiel wird mit new Token(\"wuppie\", 1, 4) ein neues Token-Objekt auf dem Heap angelegt. Der Smartpointer wuppie übernimmt die Ressource im Konstruktor und verwaltet den Pointer. Wichtig ist zu beobachten: Das Token wird auf dem Heap angelegt, während der Smartpointer wuppie eine normale lokale (\"automatische\") Variable ist und auf dem Stack liegt.\nIn der Kontrollstruktur werden weitere Smartpointer angelegt. Die ersten beiden (fluppie, fluppie2) teilen sich die Ressource (den Pointer auf das Token) mit wuppie. Es wird kein neues Token angelegt oder kopiert. Der dritte Smartpointer foo verwaltet ein weiteres Token.\nMit der Kontrollstruktur endet auch die Lebensdauer der lokalen Variablen fluppie, fluppie2 und foo, sie werden automatisch vom Stack entfernt. Da foo der letzte Smartpointer ist, der das Token \"foo\" verwaltet, wird hier die Ressource freigegeben. Bei fluppie und fluppie2 werden nur die Smartpointer auf dem Stack entfernt, die verwaltete Ressource (Token \"wuppie\") bleibt erhalten, da die noch von einem anderen Smartpointer verwaltet wird.\nMit dem Ende der Funktion endet auch die Lebensdauer des Smartpointers wuppie. Er wird automatisch vom Stack entfernt, und da er im Beispiel der letzte Smartpointer ist, der das Token \"wuppie\" verwaltet, wird dabei automatisch der Pointer zu \"wuppie\" wieder freigegeben.\nEin Smartpointer soll entsprechend folgende Eigenschaften haben:\nVerwendung soll analog zu normalen Pointern sein (Operatoren * und -\u003e überladen) Smartpointer haben niemals einen undefinierten Wert: entweder sie zeigen auf ein Objekt oder auf nullptr3 Kopieren von (shared) Smartpointern führt dazu, dass sich mehrere Smartpointer das verwiesene Objekt teilen Smartpointer löschen sich selbst (und das verwiesene Objekt, falls kein anderer Smartpointer mehr darauf zeigt), wenn die Smartpointer ungültig werden (bei Verlassen des Scopes bzw. bei explizitem Aufruf von delete auf einen Pointer auf einen Smartpointer) Es gibt keine verwitweten Objekte mehr: Wenn mehrere Smartpointer auf das selbe Objekt zeigen, darf erst der letzte Smartpointer das Objekt aus dem Heap löschen Smartpointer funktionieren nur für mit new erzeugte Objekte Weitere übliche Eigenschaften, die wir auf diesem Blatt aber vereinfachend ignorieren4:\nSmartpointer sollen für beliebige Klassen nutzbar sein (Template-Klasse) Dereferenzierung von nicht existierenden Objekten (d.h. der Smartpointer zeigt intern auf nullptr) führt nicht zum Programmabsturz, sondern zu einer Exception Reference Counting Smartpointer werden erzeugt, indem sie entweder einen Pointer auf die zu verwaltende Ressource bekommen (Konstruktor) oder eine Referenz auf ein anderes Smartpointer-Objekt (Copy-Konstruktor).\nIm Smartpointer wird entsprechend der Pointer auf die zu verwaltende Ressource gespeichert.\nFür die Bestimmung, wie viele Smartpointer sich eine Ressource teilen, muss ein Zähler implementiert werden. Sobald sich ein weiterer Smartpointer die selbe Ressource teilt, muss dort auch der Zähler (per Pointer!) übernommen werden und entsprechend inkrementiert werden. Im Destruktor muss der Zähler dekrementiert werden. Falls dabei der Zähler den Wert 0 erreicht, werden die Pointer auf die Ressource und den Zähler freigegeben.\nBei einer Zuweisung verfährt man analog.\nclass SmartToken { public: /** * Constructor * * Constructs a new smart pointer from a raw pointer, sets the reference * counter to 1. * * @param p is a raw pointer to the token to be shared */ SmartToken(Token* p = nullptr); /** * Copy constructor * * Constructs a new smart pointer from another smart pointer, increments * the reference counter. * * @param sp is another smart pointer */ SmartToken(const SmartToken\u0026 sp); /** * Destructor * * Decrements the reference counter. If it reaches zero, the shared token * will be free'd. */ ~SmartToken(); /** * Assignment * * Changes the shared token, thus we need first to perform something like * the destructor, followed by something like the constructor. * * @param sp is another smart pointer */ SmartToken\u0026 operator=(const SmartToken\u0026 sp); private: Token* pObj; ///\u003c Pointer to the current shared token RefCounter* rc; ///\u003c Pointer to the reference counter (used for the current token) }; class RefCounter { public: /** * Default constructor */ RefCounter(); /** * Increment count */ void inc(); /** * Decrement count */ void dec(); /** * Compare the counter with zero * * @return true if n==0, false otherwise */ bool isZero() const; // Hide copy constructor and assignment operator RefCounter(const RefCounter\u0026) = delete; RefCounter\u0026 operator=(const RefCounter\u0026) = delete; private: unsigned int n; ///\u003c How many SmartToken share ownership of \"our\" object? }; Dereferenzierung von Smartpointern (Anmerkung: Dies ist ein Vorgriff auf die Lektion \"Operatoren\". Betrachten und implementieren Sie die vorgegebenen Operatoren einfach wie normale Methoden.)\nPointer lassen sich dereferenzieren, d.h. man greift direkt auf das verwiesene Objekt zu. Dies lässt sich auch für Smartpointer erreichen, indem die beiden Dereferenzierungsoperatoren überladen werden.\nclass SmartToken { public: /** * Dereferences the smart pointer * * @return a reference to the shared token */ Token\u0026 operator*(); /** * Dereferences the smart pointer * * @return a pointer to the shared token */ Token* operator-\u003e(); }; Damit lässt sich das folgende Verhalten realisieren (Vergleich raw Pointer vs. Smartpointer):\nToken* foo = new Token(\"foo\", 9, 35); // raw pointer foo SmartToken wuppie = SmartToken(new Token(\"wuppie\", 1, 4)); // smart pointer wuppie // Access via token pointer cout \u003c\u003c (*foo).lexem \u003c\u003c endl; // \"foo\" cout \u003c\u003c foo-\u003elexem \u003c\u003c endl; // \"foo\" // Access via smart pointer cout \u003c\u003c (*wuppie).lexem \u003c\u003c endl; // \"wuppie\" cout \u003c\u003c wuppie-\u003elexem \u003c\u003c endl; // \"wuppie\" Dabei ist die Form \"-\u003e\" eine vereinfachte Darstellung von (*ptr)., d.h. ein Pointer (linke Seite des Ausdrucks) wird dereferenziert und man greift auf Attribute oder Methoden des verwiesenen Objekts zu (rechte Seite des Ausdrucks).\nAufgaben A6.1: Klasse für Token (1P) Implementieren Sie in C++ die Klasse Token mit der folgenden Schnittstelle:\nclass Token { public: /** * Constructs a new token object. * * @param l is a pointer to the text of the token (to be copied) * @param r is the row in input where this token was found * @param c is the column in input where this token starts */ Token(const char* l, int r, int c); /** * Destructs the token object and free's the stored lexem. */ ~Token(); private: char* lexem; ///\u003c Pointer to the text of the token int row; ///\u003c Row in input where this token was found int col; ///\u003c Column in input where this token starts }; Trennen Sie Deklaration und Implementierung.\nDer Konstruktor muss den übergebenen char* kopieren, d.h. Sie müssen die Länge des übergebenen C-Strings bestimmen, ausreichend viel Speicher mit new für char* lexem reservieren und danach den String kopieren (C-Funktion).\nSorgen Sie dafür, dass der Speicher beim Vernichten eines Token-Objekts wieder korrekt freigegeben wird.\nBei Bedarf können Sie zusätzliche Attribute und Methoden hinzufügen.\nTesten Sie Ihre Token-Klasse an selbst gewählten Beispielen.\nA6.2: Implementierung eines einfachen Tokenizers (1P) Erstellen Sie eine Funktion void tokenize(const string\u0026 input, vector\u003cToken\u003e\u0026 tokens), die einen gegebenen String als Eingabe erhält und diesen in Tokens (Wörter) splittet. Nutzen Sie Referenzen, um die Token-Liste zu aktualisieren. Testen Sie die Funktion mit verschiedenen Eingabestrings und geben Sie die Tokens aus.\nA6.3: Reference Counter (1P) Implementieren Sie nun die Klasse RefCounter mit der obigen Schnittstelle. Auch hier können Sie bei Bedarf zusätzliche Attribute und Methoden hinzufügen.\nTesten Sie Ihre RefCounter-Klasse an selbst gewählten Beispielen.\nA6.4: Smartpointer (3P) Implementieren Sie nun die Smartpointer für Token-Objekte mit folgender Signatur (wie oben, leicht erweitert):\nclass SmartToken { public: /** * Constructor * * Constructs a new smart pointer from a raw pointer, sets the reference * counter to 1. * * @param p is a raw pointer to the token to be shared */ SmartToken(Token* p = nullptr); /** * Copy constructor * * Constructs a new smart pointer from another smart pointer, increments * the reference counter. * * @param sp is another smart pointer */ SmartToken(const SmartToken\u0026 sp); /** * Destructor * * Decrements the reference counter. If it reaches zero, the shared token * will be free'd. */ ~SmartToken(); /** * Assignment * * Changes the shared token, thus we need first to perform something like * the destructor, followed by something like the constructor. * * @param sp is another smart pointer */ SmartToken\u0026 operator=(const SmartToken\u0026 sp); /** * Dereferences the smart pointer * * @return a reference to the shared token */ Token\u0026 operator*(); /** * Dereferences the smart pointer * * @return a pointer to the shared token */ Token* operator-\u003e(); /** * Comparison * * @param sp is another smart pointer * @return true, if `sp` shares the same token */ bool operator==(const SmartToken\u0026 sp) const; private: Token* pObj; ///\u003c Pointer to the current shared token RefCounter* rc; ///\u003c Pointer to the reference counter (used for the current token) }; Bei Bedarf können Sie zusätzliche Attribute und Methoden hinzufügen.\nTesten Sie Ihre SmartToken-Klasse an selbst gewählten Beispielen sowie an den obigen Beispielen.\nA6.5: Ringpuffer (4P) Ein Ringpuffer ist eine Form der abstrakten Datenstruktur \"Warteschlange\" (Queue), die nur eine beschränkte Anzahl $n$ von Elementen (Datensätzen) aufnehmen kann. Die Daten werden nach dem FIFO-Prinzip über die Funktion writeBuffer() am Ende der Schlange eingefügt und mit der Funktion readBuffer() vom Anfang der Schlange entnommen.\nAus Effizienzgründen wird bei readBuffer() nur das erste Element zurückgeliefert, das gelesene Element wird aber (noch) nicht aus dem Ringpuffer entfernt. Über ein Attribut head merkt man sich stattdessen, wo das nächste zu lesende Element liegt (auf dem Platz hinter dem aktuell gelesenen). Ist der Puffer voll, wird bei writeBuffer() das älteste Element entfernt und das neue Element auf dem frei gewordenen Platz im internen Array elems eingefügt.\nUnser Ringpuffer ist auf Elemente vom Typ SmartToken festgelegt. Es wird davon ausgegangen, dass diese Elemente Smartpointer mit der shared pointer-Semantik sind.5 Da die SmartToken selbst (zum Teil) eine Pointersemantik implementiert haben (man kann die Smartpointer dereferenzieren), vermeiden wir Pointer auf die Smartpointer in der Schnittstelle und arbeiten stattdessen mit C++-Referenzen bzw. Kopien: Bei writeBuffer() wird ein SmartToken per konstanter C++-Referenz übergeben, und bei readBuffer() wird eine Kopie des gelesenen SmartToken zurückgeliefert.\nDer Puffer kann effizient durch ein zur Laufzeit angelegtes Array mit size (Template-Parameter) Plätzen zur Speicherung der Pointer auf die Elemente realisiert werden. Die Ringstruktur wird durch Modulo-Operationen auf den Array-Indizes realisiert.\nImplementieren Sie nun den Ringpuffer für SmartToken-Objekte mit folgender Signatur:\nclass RingBuffer { public: /** * Constructor that creates a new ring buffer for max. `size` elements * * Initialises the attributes and allocates memory for `size` elements * of type `SmartToken` and let the pointer `elems` point to this new * array * * @param size is the max. number of elements that can be stored */ RingBuffer(unsigned int size); /** * Destructor * * free's the dynamically allocated array `elems` */ ~RingBuffer(); /** * Reading the first (oldest) element * * If an element has been read, the `head` points to the next element * and `count` is decremented. The read element is **not** released. * * @return Returns (a copy of) the first (i.e. oldest) element of the * buffer, but does not (yet) release it; returns an empty `SmartToken` * if buffer is empty */ SmartToken readBuffer(); /** * Adding a new element * * Appends the new element to the end of the queue. If the buffer is * full, the oldest element will be overwritten by the new element. The * old element will take care of releasing its memory (smart pointer). * * @param data is a reference to the element to be added */ void writeBuffer(const SmartToken\u0026 data); private: unsigned int count; ///\u003c number of elements currently stored in the buffer unsigned int head; ///\u003c points to the beginning of the buffer (oldest element) unsigned int size; ///\u003c length of array `elems` SmartToken* elems; ///\u003c array with `size` places of type `SmartToken`, dynamically allocated }; Bei Bedarf können Sie zusätzliche Attribute und Methoden hinzufügen.\nTesten Sie Ihre RingBuffer-Klasse an selbst gewählten Beispielen. Überzeugen Sie sich insbesondere vom korrekten Zugriff auf die Ringstruktur und prüfen Sie, ob die Smartpointer wie gewünscht arbeiten. Prüfen Sie hierzu auch die RefCounter der beteiligten Smartpointer. Welche Sonderfälle können Sie identifizieren?\nAnmerkung: Man spricht trotzdem von \"Freigabe\" des Objekts, obwohl lediglich der Stackpointer zurückgesetzt wird und das Objekt zunächst auf dem Stack noch vollständig ist. Es kann und wird aber im weiteren Verlauf des Programms überschrieben. ↩︎\nDereferenzierung von Null-Pointern oder nicht initialisierten Pointern, Nutzung von delete für Pointer, die nicht mit new erstellt wurden, mehrfaches delete, Speicherlöcher durch Vergessen von delete, Dangling Pointer, verwitwete Objekte, ... ↩︎\nSie müssen für nullptr den g++ auf C++11 oder höher umstellen (--std=c++11) und den Header \u003ccstddef\u003e includen. ↩︎\nTemplates haben wir hier noch nicht behandelt, Exceptions werden wir gar nicht betrachten ↩︎\nWenn Sie die obigen Aufgaben richtig gelöst haben, haben Sie genau diese Semantik vorliegen. ↩︎",
    "description": "Zusammenfassung Ziel dieses Aufgabenblattes ist die praktische Anwendung Ihrer C++-Kenntnisse, insbesondere werden Sie Pointer, Referenzen und Klassen anwenden und vertiefen. Als Anwendungsbeispiel werden Sie bestimmte in der C++-Welt wohlbekannte Smartpointer modellieren sowie einen einfachen Ringpuffer programmieren. Sie lernen mit dem Reference Counting nebenbei eine verbreitete Technik der Garbage Collection kennen.\nMethodik Sie werden auf diesem Blatt vier einfache Klassen in C++ implementieren.\nEs empfiehlt sich, zunächst die Beispiele gründlich zu analysieren, um die gewünschte Funktionsweise der einzelnen Klassen vorab präzise zu verstehen. Sie werden zu einigen Dingen in der C++-Literatur recherchieren müssen.",
    "tags": [],
    "title": "Blatt 06: C++",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/homework/sheet06.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Praktikum",
    "content": "Aufgaben Bearbeiten Sie die auf Blatt 07 definierten Aufgaben. Ergänzend sollen noch Pointer und dynamische Speicherverwaltung in Java realisiert werden (vgl. Vorarbeiten auf Blatt 06x).",
    "description": "Aufgaben Bearbeiten Sie die auf Blatt 07 definierten Aufgaben. Ergänzend sollen noch Pointer und dynamische Speicherverwaltung in Java realisiert werden (vgl. Vorarbeiten auf Blatt 06x).",
    "tags": [],
    "title": "Blatt 07x: Mini-Projekt C++ (IFM 5.21 CB PO18, 5. Semester)",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/homework/sheet07x.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Praktikum",
    "content": "Aufgaben Betrachten Sie die auf Blatt 04 definierte Sprache. Ergänzen Sie diese Sprache um Arrays und Pointer. Benutzen Sie dabei die aus C/C++ bekannte Syntax.\nLösen Sie mit dieser erweiterten Sprachdefinition die auf Blatt 04 gestellten Aufgaben.\nAnmerkung: Hier sind nur die syntaktischen Elemente und ihre semantischen Auswirkungen interessant, d.h. (Funktionen/Operatoren für die) dynamische Speicherverwaltung brauchen Sie nicht implementieren!\nVorstellung (Station I der Parcoursprüfung) Stellen Sie Ihre Konzepte und Lösungen im Rahmen eines Vortrags vor. Fokussieren Sie sich dabei auf die Auswirkungen der oben beschriebenen Erweiterung der Sprache auf die Grammatik und die semantische Analyse. Der Vortrag soll 20 Minuten dauern.\nDie Vorträge werden im Praktikum am 27.11. bzw. am 04.12. durchgeführt. Wir werden dazu die Teams entsprechend aufteilen, Sie bekommen eine Mail. Abgabe der Lösung und des Vortrags im ILIAS ist für alle Teams aber bereits der 27.11. ...\nBewertungskriterien Inhalt (25 Punkte)\nThemenverständnis (15 Punkte): Wurde das Thema klar und umfassend dargestellt? Wurde das Fachwissen adäquat vermittelt? Argumentation und Nachvollziehbarkeit (10 Punkte): Sind die Konzepte logisch und schlüssig aufgebaut? Werden die Aussagen durch relevante Beispiele gestützt? Struktur (15 Punkte)\nAufbau (5 Punkte): Gibt es eine klare Einleitung, einen strukturierten Hauptteil und einen prägnanten Schluss? Gestaltung (5 Punkte): Wurden geeignete und ansprechende visuelle Hilfsmittel eingesetzt (Diagramme, Abbildungen)? Unterstützen diese die Inhalte oder lenken sie eher ab? Roter Faden (5 Punkte): Wird der rote Faden während des gesamten Vortrags beibehalten? Ist der Zusammenhang zwischen den einzelnen Punkten nachvollziehbar? Präsentation (10 Punkte)\nGestik, Mimik und Sprache (5 Punkte): Ist die Sprache klar, verständlich und angemessen? Ist die Stimmlage dynamisch und ansprechend? Ist das Tempo angemessen? Zeitmanagement (5 Punkte): Wurde der Zeitrahmen (20 Minuten pro Vortrag) eingehalten? Gesamtbewertung: 50 Punkte",
    "description": "Aufgaben Betrachten Sie die auf Blatt 04 definierte Sprache. Ergänzen Sie diese Sprache um Arrays und Pointer. Benutzen Sie dabei die aus C/C++ bekannte Syntax.\nLösen Sie mit dieser erweiterten Sprachdefinition die auf Blatt 04 gestellten Aufgaben.\nAnmerkung: Hier sind nur die syntaktischen Elemente und ihre semantischen Auswirkungen interessant, d.h. (Funktionen/Operatoren für die) dynamische Speicherverwaltung brauchen Sie nicht implementieren!\nVorstellung (Station I der Parcoursprüfung) Stellen Sie Ihre Konzepte und Lösungen im Rahmen eines Vortrags vor. Fokussieren Sie sich dabei auf die Auswirkungen der oben beschriebenen Erweiterung der Sprache auf die Grammatik und die semantische Analyse. Der Vortrag soll 20 Minuten dauern.",
    "tags": [],
    "title": "Blatt 04x: Semantische Analyse (IFM 5.21 CB PO18, 5. Semester)",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/homework/sheet04x.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Praktikum",
    "content": "Aufgaben Betrachten Sie die auf Blatt 05 definierte Sprache.\nErgänzen Sie diese Sprache um passende syntaktische Strukturen, mit denen man die aus anderen Sprachen bekannten for- und while-Schleifen formulieren kann. Bleiben Sie dabei so nah an der Lisp-artigen Sprache wie möglich! Lösen Sie diese Strukturen nach dem Parsen als \"syntactic sugar\" auf und transformieren Sie diese geeignet in einen rekursiven Aufruf einer (beim Traversieren jeweils neu generierten) Hilfsfunktion.\nLösen Sie mit dieser erweiterten Sprachdefinition die auf Blatt 05 gestellten Aufgaben.",
    "description": "Aufgaben Betrachten Sie die auf Blatt 05 definierte Sprache.\nErgänzen Sie diese Sprache um passende syntaktische Strukturen, mit denen man die aus anderen Sprachen bekannten for- und while-Schleifen formulieren kann. Bleiben Sie dabei so nah an der Lisp-artigen Sprache wie möglich! Lösen Sie diese Strukturen nach dem Parsen als \"syntactic sugar\" auf und transformieren Sie diese geeignet in einen rekursiven Aufruf einer (beim Traversieren jeweils neu generierten) Hilfsfunktion.\nLösen Sie mit dieser erweiterten Sprachdefinition die auf Blatt 05 gestellten Aufgaben.",
    "tags": [],
    "title": "Blatt 05x: Interpreter (IFM 5.21 CB PO18, 5. Semester)",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/homework/sheet05x.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25) \u003e Praktikum",
    "content": "Aufgaben Bearbeiten Sie die auf Blatt 06 definierten Aufgaben A6.1 (Token, 1P), A6.2 (Tokenizer, 1P), A6.3 (Reference Counter, 1P) und A6.4 (Smartpointer, 3P).\nStatt der Aufgabe A6.5 (Ringpuffer, 4P) bearbeiten Sie bitte die folgende Aufgabe (4P):\nIn C++ gibt es Pointer und dynamische Speicherverwaltung. Mit Hilfe des Operators new kann Speicher auf dem Heap angefordert werden und man erhält einen Pointer auf den Start des Bereichs, und mit dem Operator delete kann man Speicher wieder freigeben. Mit Hilfe der Smartpointer wurde diese manuelle Freigabe zu einem gewissen Grad automatisiert.\nBauen Sie die dynamische Speicherverwaltung in Java nach:\nModellieren Sie den Heap als Singleton-Datenstruktur.\nDie Datenstruktur kann eine bestimmte maximale Anzahl von allgemeinen Objekten (per Object-Referenz) speichern und soll einen indexbasierten Zugriff auf die Speicherplätze und damit die Objekte erlauben. Die Datenstruktur muss eine interne Buchführung haben, welche der Plätze noch frei sind. Die Datenstruktur muss Methoden analog zu new und delete haben, damit man von außen Platz auf dem simulierten Heap reservieren kann bzw. wieder freigeben kann. Bei new übergibt man eine Object-Referenz und erhält einen Pointer zurück, bei delete übergibt man einen Pointer.\nModellieren Sie Pointer.\nDies ist eine Datenstruktur, die auf ein Objekt im simulierten Heap \"zeigt\", indem sie den Index des Objekts in der Heap-Datenstruktur speichert. Beachten Sie, dass Pointer in C++ typisiert sind (char*, int*, Foo*) und realisieren Sie dies entsprechend. Die Datenstruktur soll zusätzlich eine Methode zum \"Dereferenzieren\" aufweisen, damit man direkt auf das verwiesene Objekt zugreifen kann. Dabei muss das Objekt aus dem \"Heap\" geholt werden und von Object auf den jeweiligen Typ gecasted und zurückgeliefert werden.\nHinweis: Diese Aufgabe ist eine Vorarbeit für das nächste Blatt (Mini-Projekt).\nHinweis: Erinnern Sie sich an Generics in Java: B\u003cE\u003e extends A\u003cE\u003e, aber NICHT C\u003cB\u003e extends C\u003cA\u003e (mit B extends A)! Generics werden hier also nicht helfen. Denkbar wäre eine Vererbungshierarchie und die Überschreibung des Rückgabetyps der Basismethode für die Dereferenzierung (covariant return type) oder ggf. die Modellierung mit Hilfe eines Enums. Für dieses Blatt können Sie sich auf ein paar Beispiele für konkrete Pointertypen beschränken - für das Mini-Projekt (nächstes Blatt) werden die nötigen Klassen dann beim Kompilieren dynamisch durch Ihren eigenen Compiler als Java-Strukturen angelegt.",
    "description": "Aufgaben Bearbeiten Sie die auf Blatt 06 definierten Aufgaben A6.1 (Token, 1P), A6.2 (Tokenizer, 1P), A6.3 (Reference Counter, 1P) und A6.4 (Smartpointer, 3P).\nStatt der Aufgabe A6.5 (Ringpuffer, 4P) bearbeiten Sie bitte die folgende Aufgabe (4P):\nIn C++ gibt es Pointer und dynamische Speicherverwaltung. Mit Hilfe des Operators new kann Speicher auf dem Heap angefordert werden und man erhält einen Pointer auf den Start des Bereichs, und mit dem Operator delete kann man Speicher wieder freigeben. Mit Hilfe der Smartpointer wurde diese manuelle Freigabe zu einem gewissen Grad automatisiert.",
    "tags": [],
    "title": "Blatt 06x: C++ und dyn. Speicherverwaltung (IFM 5.21 CB PO18, 5. Semester)",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/homework/sheet06x.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25)",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/categories.html"
  },
  {
    "breadcrumb": "IFM 3.1 (PO23) / IFM 5.21 (PO18): Compilerbau (Winter 2024/25)",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/elearning/data/FH-Bielefeld/lm_data/lm_1360443/tags.html"
  }
]
